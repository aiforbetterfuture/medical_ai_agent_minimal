# ì½”ë“œ íš¨ìœ¨í™” ë° ê°œì„  ì‚¬í•­ ë¶„ì„

## ğŸ“‹ ê°œìš”

ì „ì²´ ìŠ¤ìºí´ë“œ ì½”ë“œë² ì´ìŠ¤ë¥¼ ê²€í† í•˜ì—¬ ë°œê²¬í•œ ë¹„íš¨ìœ¨ì  ì½”ë“œ, ì•„í‚¤í…ì²˜ ë¬¸ì œ, ì„±ëŠ¥ ê°œì„  ê°€ëŠ¥ ì‚¬í•­ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.

---

## ğŸ”´ ì‹¬ê°í•œ ë¬¸ì œ (ì¦‰ì‹œ ìˆ˜ì • ê¶Œì¥)

### 1. ê·¸ë˜í”„ ì¬ì‚¬ìš© ì—†ìŒ - ì„±ëŠ¥ ì €í•˜

**ìœ„ì¹˜**: `agent/graph.py:89`

**ë¬¸ì œ**:
```python
def run_agent(user_text: str, mode: str = 'ai_agent') -> str:
    # ...
    app = build_agent_graph()  # ë§¤ë²ˆ ê·¸ë˜í”„ ë¹Œë“œ!
    final_state = app.invoke(initial_state)
```

**ì˜í–¥**: 
- ë§¤ ìš”ì²­ë§ˆë‹¤ ê·¸ë˜í”„ ì¬ë¹Œë“œ (ë¶ˆí•„ìš”í•œ ì˜¤ë²„í—¤ë“œ)
- ì´ˆê¸°í™” ì‹œê°„ ì¦ê°€

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# ê·¸ë˜í”„ë¥¼ ëª¨ë“ˆ ë ˆë²¨ì—ì„œ ìºì‹±
_agent_graph_cache = None

def get_agent_graph():
    global _agent_graph_cache
    if _agent_graph_cache is None:
        _agent_graph_cache = build_agent_graph()
    return _agent_graph_cache

def run_agent(user_text: str, mode: str = 'ai_agent') -> str:
    # ...
    app = get_agent_graph()  # ì¬ì‚¬ìš©
    final_state = app.invoke(initial_state)
```

---

### 2. ìƒíƒœì— ê°ì²´ ì €ì¥ - ì§ë ¬í™” ë¬¸ì œ

**ìœ„ì¹˜**: ì—¬ëŸ¬ ë…¸ë“œì—ì„œ `state['slot_extractor']`, `state['llm_client']` ë“± ì €ì¥

**ë¬¸ì œ**:
- LangGraphëŠ” ìƒíƒœë¥¼ ì§ë ¬í™”í•  ìˆ˜ ìˆì–´ì•¼ í•¨
- Python ê°ì²´ëŠ” ì§ë ¬í™”ë˜ì§€ ì•ŠìŒ
- ë©€í‹°í”„ë¡œì„¸ì‹±/ë¶„ì‚° í™˜ê²½ì—ì„œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥

**ì˜í–¥**:
- ìƒíƒœ ì €ì¥/ë³µì› ì‹¤íŒ¨
- ë¶„ì‚° ì‹¤í–‰ ë¶ˆê°€

**ìˆ˜ì • ë°©ì•ˆ**:
- ì „ì—­ ì‹±ê¸€í†¤ ë˜ëŠ” ëª¨ë“ˆ ë ˆë²¨ ìºì‹œ ì‚¬ìš©
- ë˜ëŠ” ë³„ë„ì˜ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ë„ì…

---

### 3. ì„¤ì • íŒŒì¼ ë§¤ë²ˆ ë¡œë“œ - I/O ì˜¤ë²„í—¤ë“œ

**ìœ„ì¹˜**: `core/config.py`ì˜ ëª¨ë“  í•¨ìˆ˜

**ë¬¸ì œ**:
```python
def get_llm_config(config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    if config is None:
        config = load_config()  # ë§¤ë²ˆ íŒŒì¼ ì½ê¸°!
```

**ì˜í–¥**:
- ë§¤ ë…¸ë“œ ì‹¤í–‰ë§ˆë‹¤ YAML íŒŒì¼ ì½ê¸°
- ë¶ˆí•„ìš”í•œ ë””ìŠ¤í¬ I/O

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# ëª¨ë“ˆ ë ˆë²¨ ìºì‹±
_config_cache = None
_llm_config_cache = None
_retrieval_config_cache = None

def load_config(config_path: Optional[str] = None) -> Dict[str, Any]:
    global _config_cache
    if _config_cache is None:
        # íŒŒì¼ ë¡œë“œ
        _config_cache = ...
    return _config_cache
```

---

## ğŸŸ¡ ì¤‘ê°„ ë¬¸ì œ (ì„±ëŠ¥ ê°œì„ )

### 4. BM25 ê²€ìƒ‰ ë¹„íš¨ìœ¨ - ì „ì²´ ì ìˆ˜ ê³„ì‚°

**ìœ„ì¹˜**: `retrieval/hybrid_retriever.py:90`

**ë¬¸ì œ**:
```python
scores = self.bm25_index.get_scores(query_tokens)  # ì „ì²´ ë¬¸ì„œ ì ìˆ˜ ê³„ì‚°
top_indices = sorted(range(len(scores)), ...)[:k]  # ì „ì²´ ì •ë ¬ í›„ kê°œë§Œ ì„ íƒ
```

**ì˜í–¥**:
- ëŒ€ìš©ëŸ‰ ì½”í¼ìŠ¤ì—ì„œ O(n log n) ì •ë ¬
- ë¶ˆí•„ìš”í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# heapqë¥¼ ì‚¬ìš©í•œ ìƒìœ„ kê°œë§Œ ì„ íƒ
import heapq

def search(self, query: str, k: int = 10) -> List[Dict[str, Any]]:
    # ...
    query_tokens = tokenize_ko_en(query)
    scores = self.bm25_index.get_scores(query_tokens)
    
    # ìƒìœ„ kê°œë§Œ ì„ íƒ (O(n log k))
    top_indices = heapq.nlargest(k, range(len(scores)), key=lambda i: scores[i])
    
    results = []
    for rank, idx in enumerate(top_indices, start=1):
        # ...
```

**ì„±ëŠ¥ ê°œì„ **: O(n log n) â†’ O(n log k), ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ

---

### 5. ProfileStoreì˜ ë¹„íš¨ìœ¨ì  ê²€ìƒ‰

**ìœ„ì¹˜**: `memory/profile_store.py:144-149`

**ë¬¸ì œ**:
```python
sbp = next((v for v in reversed(self.ltm.vitals) if str(v.name).upper() == "SBP"), None)
dbp = next((v for v in reversed(self.ltm.vitals) if str(v.name).upper() == "DBP"), None)
```

**ì˜í–¥**:
- ë¦¬ìŠ¤íŠ¸ ì „ì²´ ìˆœíšŒ (O(n))
- ë§¤ë²ˆ ë¬¸ìì—´ ë³€í™˜ ë° ë¹„êµ

**ìˆ˜ì • ë°©ì•ˆ**:
```python
def get_profile_summary(self) -> str:
    # ...
    # ë”•ì…”ë„ˆë¦¬ë¡œ ì¸ë±ì‹± (í•œ ë²ˆë§Œ ìˆœíšŒ)
    vitals_dict = {}
    for v in reversed(self.ltm.vitals):
        name_upper = str(v.name).upper()
        if name_upper not in vitals_dict:
            vitals_dict[name_upper] = v
    
    sbp = vitals_dict.get("SBP")
    dbp = vitals_dict.get("DBP")
    
    # labsë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
    labs_dict = {}
    for l in reversed(self.ltm.labs):
        name_upper = str(l.name).upper()
        if name_upper not in labs_dict:
            labs_dict[name_upper] = l
    
    a1c = labs_dict.get("A1C")
    fpg = labs_dict.get("FPG")
```

---

### 6. ì½”ë“œ ì¤‘ë³µ - ëª¨ë“œ ì²´í¬ ë°˜ë³µ

**ìœ„ì¹˜**: ëª¨ë“  ë…¸ë“œì—ì„œ `state.get('mode') == 'llm'` ì²´í¬

**ë¬¸ì œ**:
- ë™ì¼í•œ ë¡œì§ ë°˜ë³µ
- ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# core/utils.py
def is_llm_mode(state: AgentState) -> bool:
    """LLM ëª¨ë“œ ì—¬ë¶€ í™•ì¸"""
    return state.get('mode') == 'llm'

# ê° ë…¸ë“œì—ì„œ
if is_llm_mode(state):
    return state  # ë˜ëŠ” ì ì ˆí•œ ì²˜ë¦¬
```

---

### 7. LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ë³µ

**ìœ„ì¹˜**: `retrieve_node`, `generate_answer_node`

**ë¬¸ì œ**:
- ë™ì¼í•œ ì´ˆê¸°í™” ë¡œì§ ì¤‘ë³µ
- ìƒíƒœì— ì €ì¥ (ì§ë ¬í™” ë¬¸ì œ)

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# core/llm_client.pyì— ì¶”ê°€
_llm_client_cache = {}

def get_or_create_llm_client(provider: str = 'openai', **kwargs) -> LLMClient:
    """LLM í´ë¼ì´ì–¸íŠ¸ ìºì‹œ ë° ì¬ì‚¬ìš©"""
    cache_key = f"{provider}_{kwargs.get('model', 'default')}"
    if cache_key not in _llm_client_cache:
        _llm_client_cache[cache_key] = get_llm_client(provider, **kwargs)
    return _llm_client_cache[cache_key]

# ë…¸ë“œì—ì„œ
llm_client = get_or_create_llm_client(
    provider=embedding_config.get('provider', 'openai')
)
# stateì— ì €ì¥í•˜ì§€ ì•ŠìŒ
```

---

## ğŸŸ¢ ê²½ë¯¸í•œ ë¬¸ì œ (ì½”ë“œ í’ˆì§ˆ)

### 8. ë¡œê¹… ì‹œìŠ¤í…œ ì—†ìŒ - print ì‚¬ìš©

**ìœ„ì¹˜**: ëª¨ë“  ë…¸ë“œì—ì„œ `print()` ì‚¬ìš©

**ë¬¸ì œ**:
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ë¡œê·¸ ê´€ë¦¬ ì–´ë ¤ì›€
- ë¡œê·¸ ë ˆë²¨ ì œì–´ ë¶ˆê°€

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# core/logger.py
import logging

logger = logging.getLogger('medical_ai_agent')
logger.setLevel(logging.INFO)

# ë…¸ë“œì—ì„œ
logger.info("[Node] retrieve")
logger.warning(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
logger.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
```

---

### 9. ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±

**ìœ„ì¹˜**: ì—¬ëŸ¬ ë…¸ë“œ

**ë¬¸ì œ**:
- ì˜ˆì™¸ ë°œìƒ ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ë§Œ ë°˜í™˜
- ì—ëŸ¬ ì›ì¸ ì¶”ì  ì–´ë ¤ì›€

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# êµ¬ì¡°í™”ëœ ì—ëŸ¬ ì²˜ë¦¬
class AgentError(Exception):
    """Agent ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ì—ëŸ¬"""
    pass

class RetrievalError(AgentError):
    """ê²€ìƒ‰ ê´€ë ¨ ì—ëŸ¬"""
    pass

# ë…¸ë“œì—ì„œ
try:
    # ...
except Exception as e:
    logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=True)
    raise RetrievalError(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") from e
```

---

### 10. ë¶ˆí•„ìš”í•œ ë”•ì…”ë„ˆë¦¬ ë³µì‚¬

**ìœ„ì¹˜**: ì—¬ëŸ¬ ë…¸ë“œì—ì„œ `{**state, ...}` ì‚¬ìš©

**ë¬¸ì œ**:
- ì–•ì€ ë³µì‚¬ë¡œ ì¶©ë¶„í•œë° ì „ì²´ ë”•ì…”ë„ˆë¦¬ ë³µì‚¬
- ë©”ëª¨ë¦¬ ì‚¬ìš© ì¦ê°€

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# LangGraphëŠ” ìƒíƒœë¥¼ ìë™ìœ¼ë¡œ ë³‘í•©í•˜ë¯€ë¡œ ëª…ì‹œì  ë³µì‚¬ ë¶ˆí•„ìš”
# ë‹¨, ìˆ˜ì •í•  í•„ë“œë§Œ ë°˜í™˜
return {
    'slot_out': slot_out  # ìˆ˜ì •ëœ í•„ë“œë§Œ
}
```

**ì°¸ê³ **: LangGraphì˜ `Annotated` íƒ€ì…ì€ ìë™ ë³‘í•©ë˜ë¯€ë¡œ ì „ì²´ ë³µì‚¬ ë¶ˆí•„ìš”

---

### 11. ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” í•¨ìˆ˜

**ìœ„ì¹˜**: `retrieval/rrf_fusion.py:53`

**ë¬¸ì œ**:
```python
def _calculate_rrf_score(rank: int, k: int = 60) -> float:
    """RRF ì ìˆ˜ ê³„ì‚°"""
    return 1.0 / (rank + k)
```

**ì˜í–¥**: ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì½”ë“œ

**ìˆ˜ì • ë°©ì•ˆ**: ì‚­ì œ ë˜ëŠ” ì‹¤ì œ ì‚¬ìš©

---

### 12. í•˜ë“œì½”ë”©ëœ ê°’

**ìœ„ì¹˜**: ì—¬ëŸ¬ ê³³

**ë¬¸ì œ**:
- ë§¤ì§ ë„˜ë²„ ì‚¬ìš© (ì˜ˆ: `k=60`, `quality_score < 0.5`)
- ì„¤ì • íŒŒì¼ë¡œ ê´€ë¦¬ë˜ì§€ ì•ŠìŒ

**ìˆ˜ì • ë°©ì•ˆ**:
```python
# config/model_config.yamlì— ì¶”ê°€
self_refine:
  quality_threshold: 0.5
  max_iterations: 2
  weights:
    length: 0.3
    evidence: 0.4
    personalization: 0.3

# ì½”ë“œì—ì„œ
quality_threshold = config.get('self_refine', {}).get('quality_threshold', 0.5)
```

---

## ğŸ“Š ì„±ëŠ¥ ê°œì„  ì˜ˆìƒ íš¨ê³¼

| ê°œì„  ì‚¬í•­ | í˜„ì¬ | ê°œì„  í›„ | ê°œì„ ìœ¨ |
|----------|------|---------|--------|
| ê·¸ë˜í”„ ë¹Œë“œ | ë§¤ë²ˆ | 1íšŒ | ~50ms ì ˆì•½/ìš”ì²­ |
| ì„¤ì • ë¡œë“œ | ë§¤ë²ˆ | ìºì‹± | ~10ms ì ˆì•½/ìš”ì²­ |
| BM25 ê²€ìƒ‰ | O(n log n) | O(n log k) | ëŒ€ìš©ëŸ‰ì—ì„œ 10-50% |
| ProfileStore ê²€ìƒ‰ | O(n) | O(1) | 90%+ ê°œì„  |

---

## ğŸ› ï¸ ìš°ì„ ìˆœìœ„ë³„ ìˆ˜ì • ê³„íš

### Phase 1: ì¦‰ì‹œ ìˆ˜ì • (ì‹¬ê°í•œ ë¬¸ì œ)
1. âœ… ê·¸ë˜í”„ ì¬ì‚¬ìš© êµ¬í˜„
2. âœ… ì„¤ì • íŒŒì¼ ìºì‹±
3. âœ… ìƒíƒœì—ì„œ ê°ì²´ ì œê±° (ì „ì—­ ìºì‹œë¡œ ì´ë™)

### Phase 2: ì„±ëŠ¥ ê°œì„  (ì¤‘ê°„ ë¬¸ì œ)
4. âœ… BM25 ê²€ìƒ‰ ìµœì í™”
5. âœ… ProfileStore ê²€ìƒ‰ ìµœì í™”
6. âœ… ì½”ë“œ ì¤‘ë³µ ì œê±°

### Phase 3: ì½”ë“œ í’ˆì§ˆ (ê²½ë¯¸í•œ ë¬¸ì œ)
7. âœ… ë¡œê¹… ì‹œìŠ¤í…œ ë„ì…
8. âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 
9. âœ… í•˜ë“œì½”ë”© ê°’ ì„¤ì •í™”

---

## ğŸ’¡ ì¶”ê°€ ê°œì„  ì œì•ˆ

### 13. ë¹„ë™ê¸° ì²˜ë¦¬ ê³ ë ¤

**í˜„ì¬**: ë™ê¸° ì²˜ë¦¬ë¡œ ìˆœì°¨ ì‹¤í–‰

**ê°œì„ **: 
- BM25ì™€ FAISS ê²€ìƒ‰ì„ ë³‘ë ¬ ì‹¤í–‰
- ì„ë² ë”© ìƒì„±ê³¼ ê²€ìƒ‰ ì¤€ë¹„ ë³‘ë ¬í™”

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def retrieve_node_async(state: AgentState) -> AgentState:
    # BM25ì™€ FAISSë¥¼ ë³‘ë ¬ ì‹¤í–‰
    bm25_task = asyncio.to_thread(bm25_retriever.search, query, k)
    faiss_task = asyncio.to_thread(faiss_index.search, query_vector, k)
    
    bm25_results, faiss_results = await asyncio.gather(bm25_task, faiss_task)
    # ...
```

### 14. ë©”ëª¨ë¦¬ ì‚¬ìš© ìµœì í™”

**ë¬¸ì œ**: 
- ê²€ìƒ‰ ê²°ê³¼ ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ë³´ê´€
- ëŒ€ìš©ëŸ‰ ì½”í¼ìŠ¤ì—ì„œ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥

**ê°œì„ **:
- ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ê²°ê³¼ ì²˜ë¦¬
- í•„ìš”ì‹œì—ë§Œ ë¡œë“œ

### 15. íƒ€ì… íŒíŒ… ê°•í™”

**í˜„ì¬**: ì¼ë¶€ íƒ€ì… íŒíŒ… ëˆ„ë½

**ê°œì„ **:
```python
from typing import TypedDict, List, Dict, Any, Optional

def retrieve_node(state: AgentState) -> AgentState:
    # ëª…ì‹œì  íƒ€ì… íŒíŒ…
    retrieved_docs: List[Dict[str, Any]] = hybrid_retriever.search(...)
    return {
        **state,
        'retrieved_docs': retrieved_docs
    }
```

---

## ğŸ“ ìˆ˜ì • ì½”ë“œ ì˜ˆì‹œ

ì£¼ìš” ê°œì„  ì‚¬í•­ì— ëŒ€í•œ ìˆ˜ì • ì½”ë“œëŠ” ë³„ë„ íŒŒì¼ë¡œ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.

**ì‘ì„±ì¼**: 2025-01-XX  
**ë²„ì „**: 1.0


