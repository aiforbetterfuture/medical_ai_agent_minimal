# ë©€í‹°í„´ ëŒ€í™”ì—ì„œ 6ê°œ ìŠ¬ë¡¯ ì§€ì† ë°˜ì˜ì„ ìœ„í•œ ì•Œê³ ë¦¬ì¦˜ ë° ì•„í‚¤í…ì²˜ ë¶„ì„

## ğŸ“Œ ê°œìš”
ë³¸ ë¬¸ì„œëŠ” Medical AI Agentì—ì„œ ë©€í‹°í„´(ë‹¤ì¤‘ íšŒì°¨) ëŒ€í™” ì‹œ 6ê°œ ìŠ¬ë¡¯(demographics, conditions, symptoms, vitals, labs, medications)ì„ ì§€ì†ì ìœ¼ë¡œ ë°˜ì˜í•˜ê³  ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ìµœì²¨ë‹¨ ì•Œê³ ë¦¬ì¦˜ê³¼ ì•„í‚¤í…ì²˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

---

## ì œ1ì¥: ì´ë¡ ì  ë°°ê²½ê³¼ ê¸°ì¡´ ì—°êµ¬

### 1.1 í•µì‹¬ ì°¸ê³  ì—°êµ¬

#### ëŒ€í™” ìƒíƒœ ì¶”ì  ê´€ë ¨ ì£¼ìš” ë…¼ë¬¸
1. **"Dialogue State Tracking with Transformer"** - Microsoft, 2023
   - Transformer ê¸°ë°˜ ìƒíƒœ ì¶”ì 
   - Multi-head attentionìœ¼ë¡œ ìŠ¬ë¡¯ ê°„ ê´€ê³„ ëª¨ë¸ë§

2. **"Schema-Guided Dialogue State Tracking"** - Google, 2020
   - ìŠ¤í‚¤ë§ˆ ê¸°ë°˜ ë™ì  ìŠ¬ë¡¯ ê´€ë¦¬
   - Zero-shot ìŠ¬ë¡¯ ì¶”ì  ê°€ëŠ¥

3. **"TripPy: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking"** - 2020
   - Triple copy mechanism
   - ìŠ¬ë¡¯ ê°’ ë…ë¦½ì  ì¶”ì 

4. **"Memory Networks for Task-Oriented Dialogue"** - Meta AI, 2021
   - ì™¸ë¶€ ë©”ëª¨ë¦¬ í™œìš©
   - ì¥ê¸° ëŒ€í™” ì´ë ¥ ê´€ë¦¬

5. **"Incremental Learning in Dialogue Systems"** - DeepMind, 2022
   - ì ì§„ì  í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜
   - ìƒˆë¡œìš´ ì •ë³´ì˜ í†µí•©ê³¼ ê¸°ì¡´ ì •ë³´ ë³´ì¡´

### 1.2 ì˜ë£Œ ëŒ€í™” íŠ¹í™” ì—°êµ¬

1. **"Medical Dialogue State Tracking"** - Nature Digital Medicine, 2023
   - ì˜ë£Œ ëŒ€í™”ì˜ íŠ¹ìˆ˜ì„± ë¶„ì„
   - ì‹œê°„ì  ì¼ê´€ì„± ìœ ì§€

2. **"Longitudinal Patient Modeling"** - JAMIA, 2023
   - í™˜ì ì •ë³´ì˜ ì¢…ë‹¨ì  ì¶”ì 
   - ëª¨ìˆœ í•´ê²° ë©”ì»¤ë‹ˆì¦˜

---

## ì œ2ì¥: 6ê°œ ìŠ¬ë¡¯ êµ¬ì¡° ë° íŠ¹ì„± ë¶„ì„

### 2.1 ìŠ¬ë¡¯ë³„ íŠ¹ì„± ë§¤íŠ¸ë¦­ìŠ¤

| ìŠ¬ë¡¯ | ê°€ë³€ì„± | ì‹œê°„ ë¯¼ê°ë„ | ì¤‘ìš”ë„ | ì—…ë°ì´íŠ¸ ì „ëµ |
|------|--------|------------|--------|--------------|
| demographics | ë‚®ìŒ | ë§¤ìš° ë‚®ìŒ | ë†’ìŒ | Overwrite |
| conditions | ì¤‘ê°„ | ì¤‘ê°„ | ë§¤ìš° ë†’ìŒ | Accumulate |
| symptoms | ë†’ìŒ | ë†’ìŒ | ë†’ìŒ | Time-decay |
| vitals | ë§¤ìš° ë†’ìŒ | ë§¤ìš° ë†’ìŒ | ë§¤ìš° ë†’ìŒ | Time-series |
| labs | ë†’ìŒ | ë†’ìŒ | ë§¤ìš° ë†’ìŒ | Time-series |
| medications | ì¤‘ê°„ | ì¤‘ê°„ | ë†’ìŒ | Version control |

### 2.2 ìŠ¬ë¡¯ ê°„ ì˜ì¡´ì„± ê·¸ë˜í”„

```python
slot_dependencies = {
    "demographics": [],  # ë…ë¦½ì 
    "conditions": ["demographics"],  # ë‚˜ì´/ì„±ë³„ ì˜í–¥
    "symptoms": ["conditions", "medications"],  # ì§ˆí™˜ê³¼ ì•½ë¬¼ ë¶€ì‘ìš©
    "vitals": ["conditions", "demographics"],  # ì •ìƒ ë²”ìœ„ ê²°ì •
    "labs": ["conditions", "medications"],  # ê²€ì‚¬ í•­ëª© ì„ íƒ
    "medications": ["conditions", "labs"]  # ì²˜ë°© ê·¼ê±°
}
```

---

## ì œ3ì¥: ë©€í‹°í„´ ìŠ¬ë¡¯ ì¶”ì  ì•Œê³ ë¦¬ì¦˜

### 3.1 Hierarchical Slot Memory Network (HSMN)

#### í•µì‹¬ ì•„í‚¤í…ì²˜
```python
class HierarchicalSlotMemoryNetwork:
    """
    ê³„ì¸µì  ìŠ¬ë¡¯ ë©”ëª¨ë¦¬ ë„¤íŠ¸ì›Œí¬

    3-Level Hierarchy:
    1. Turn-level: í˜„ì¬ ëŒ€í™” í„´
    2. Session-level: í˜„ì¬ ì„¸ì…˜
    3. Patient-level: ì „ì²´ í™˜ì ê¸°ë¡
    """

    def __init__(self):
        self.turn_memory = TurnMemory()
        self.session_memory = SessionMemory()
        self.patient_memory = PatientMemory()

        # Attention mechanism
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=768,
            num_heads=12
        )

    def update_slots(self, current_turn: Dict, history: List[Dict]) -> Dict:
        """
        ë©€í‹°ë ˆë²¨ ìŠ¬ë¡¯ ì—…ë°ì´íŠ¸

        1. Turn-level extraction
        2. Conflict resolution
        3. Memory consolidation
        """
        # Step 1: í˜„ì¬ í„´ì—ì„œ ìŠ¬ë¡¯ ì¶”ì¶œ
        turn_slots = self.extract_turn_slots(current_turn)

        # Step 2: ì´ë ¥ê³¼ ì¶©ëŒ í•´ê²°
        resolved_slots = self.resolve_conflicts(
            turn_slots,
            self.session_memory.get_slots(),
            self.patient_memory.get_slots()
        )

        # Step 3: ë©”ëª¨ë¦¬ í†µí•©
        self.consolidate_memory(resolved_slots)

        return resolved_slots
```

### 3.2 Temporal Slot Evolution Model (TSEM)

#### ì‹œê°„ì  ìŠ¬ë¡¯ ì§„í™” ëª¨ë¸
```python
class TemporalSlotEvolutionModel:
    """
    ì‹œê°„ì— ë”°ë¥¸ ìŠ¬ë¡¯ ê°’ ë³€í™” ì¶”ì 

    Based on: Temporal Point Process ì´ë¡ 
    """

    def __init__(self):
        self.slot_trajectories = {}
        self.decay_rates = {
            'demographics': 0.001,  # ê±°ì˜ ë³€í•˜ì§€ ì•ŠìŒ
            'conditions': 0.01,     # ì²œì²œíˆ ë³€í™”
            'symptoms': 0.1,        # ë¹ ë¥´ê²Œ ë³€í™”
            'vitals': 0.2,          # ë§¤ìš° ë¹ ë¥´ê²Œ ë³€í™”
            'labs': 0.15,           # ë¹ ë¥´ê²Œ ë³€í™”
            'medications': 0.05     # ë³´í†µ ì†ë„ë¡œ ë³€í™”
        }

    def update_trajectory(self, slot_name: str, value: Any, timestamp: float):
        """ìŠ¬ë¡¯ ê¶¤ì  ì—…ë°ì´íŠ¸"""
        if slot_name not in self.slot_trajectories:
            self.slot_trajectories[slot_name] = []

        # ì‹œê°„ ê°€ì¤‘ì¹˜ ì ìš©
        weighted_value = self.apply_temporal_weight(
            value,
            timestamp,
            self.decay_rates[slot_name]
        )

        self.slot_trajectories[slot_name].append({
            'value': weighted_value,
            'timestamp': timestamp,
            'confidence': self.calculate_confidence(slot_name, timestamp)
        })

    def apply_temporal_weight(self, value: Any, timestamp: float, decay_rate: float) -> Any:
        """
        ì‹œê°„ ê°€ì¤‘ì¹˜ ì ìš©

        weight(t) = exp(-Î» * Î”t)
        """
        current_time = time.time()
        time_diff = current_time - timestamp
        weight = np.exp(-decay_rate * time_diff)

        return {
            'value': value,
            'weight': weight,
            'effective_value': value if weight > 0.5 else None
        }

    def predict_next_value(self, slot_name: str) -> Any:
        """
        ë‹¤ìŒ ìŠ¬ë¡¯ ê°’ ì˜ˆì¸¡

        Using: Gaussian Process Regression
        """
        if slot_name not in self.slot_trajectories:
            return None

        trajectory = self.slot_trajectories[slot_name]
        if len(trajectory) < 2:
            return trajectory[-1]['value'] if trajectory else None

        # GPR for prediction
        from sklearn.gaussian_process import GaussianProcessRegressor
        from sklearn.gaussian_process.kernels import RBF

        X = np.array([[t['timestamp']] for t in trajectory])
        y = np.array([t['value'] for t in trajectory])

        kernel = RBF(length_scale=1.0)
        gpr = GaussianProcessRegressor(kernel=kernel)
        gpr.fit(X, y)

        next_timestamp = time.time()
        prediction, std = gpr.predict([[next_timestamp]], return_std=True)

        return {
            'predicted_value': prediction[0],
            'uncertainty': std[0]
        }
```

### 3.3 Conflict Resolution Engine (CRE)

#### ì¶©ëŒ í•´ê²° ë©”ì»¤ë‹ˆì¦˜
```python
class ConflictResolutionEngine:
    """
    ìŠ¬ë¡¯ ê°’ ì¶©ëŒ í•´ê²° ì—”ì§„

    ì¶©ëŒ ìœ í˜•:
    1. Contradiction: ëª¨ìˆœëœ ì •ë³´
    2. Ambiguity: ëª¨í˜¸í•œ ì •ë³´
    3. Redundancy: ì¤‘ë³µ ì •ë³´
    """

    def __init__(self):
        self.resolution_strategies = {
            'demographics': self.resolve_demographics,
            'conditions': self.resolve_conditions,
            'symptoms': self.resolve_symptoms,
            'vitals': self.resolve_vitals,
            'labs': self.resolve_labs,
            'medications': self.resolve_medications
        }

    def resolve_conflicts(self, new_slots: Dict, existing_slots: Dict) -> Dict:
        """ë©”ì¸ ì¶©ëŒ í•´ê²° í•¨ìˆ˜"""
        resolved = {}

        for slot_name in new_slots:
            if slot_name in existing_slots:
                # ì¶©ëŒ ê°ì§€
                if self.has_conflict(new_slots[slot_name], existing_slots[slot_name]):
                    # ìŠ¬ë¡¯ë³„ ì „ëµ ì ìš©
                    resolved[slot_name] = self.resolution_strategies[slot_name](
                        new_slots[slot_name],
                        existing_slots[slot_name]
                    )
                else:
                    # ì¶©ëŒ ì—†ìŒ - ë³‘í•©
                    resolved[slot_name] = self.merge_values(
                        new_slots[slot_name],
                        existing_slots[slot_name]
                    )
            else:
                # ìƒˆë¡œìš´ ìŠ¬ë¡¯
                resolved[slot_name] = new_slots[slot_name]

        return resolved

    def resolve_demographics(self, new_val: Dict, old_val: Dict) -> Dict:
        """
        ì¸êµ¬í†µê³„ ì¶©ëŒ í•´ê²°

        ê·œì¹™: ìµœì‹  ì •ë³´ ìš°ì„ , ë†’ì€ ì‹ ë¢°ë„ ì •ë³´ ìš°ì„ 
        """
        resolved = old_val.copy()

        # ë‚˜ì´ëŠ” ì‹œê°„ ê²½ê³¼ ê³ ë ¤
        if 'age' in new_val and 'age' in old_val:
            time_diff = new_val.get('timestamp', 0) - old_val.get('timestamp', 0)
            expected_age_diff = time_diff / (365 * 24 * 3600)  # years

            if abs(new_val['age'] - old_val['age'] - expected_age_diff) < 2:
                resolved['age'] = new_val['age']
            else:
                # í° ì°¨ì´ - í™•ì¸ í•„ìš”
                resolved['age'] = {
                    'value': new_val['age'],
                    'confidence': 0.7,
                    'needs_confirmation': True
                }

        # ì„±ë³„ì€ ë³€ê²½ ë¶ˆê°€ (ì¼ë°˜ì ìœ¼ë¡œ)
        if 'gender' in new_val and 'gender' in old_val:
            if new_val['gender'] != old_val['gender']:
                # ëª¨ìˆœ - í™•ì¸ í•„ìš”
                resolved['gender'] = {
                    'value': new_val['gender'],
                    'previous': old_val['gender'],
                    'conflict': True
                }

        return resolved

    def resolve_conditions(self, new_val: List, old_val: List) -> List:
        """
        ì§ˆí™˜ ì¶©ëŒ í•´ê²°

        ê·œì¹™:
        1. ë§Œì„± ì§ˆí™˜ì€ ì œê±°í•˜ì§€ ì•ŠìŒ
        2. ê¸‰ì„± ì§ˆí™˜ì€ ì‹œê°„ ê²½ê³¼ í›„ ì œê±° ê°€ëŠ¥
        3. ìƒˆë¡œìš´ ì§„ë‹¨ì€ ì¶”ê°€
        """
        chronic_conditions = ['diabetes', 'hypertension', 'asthma', 'ë‹¹ë‡¨ë³‘', 'ê³ í˜ˆì••', 'ì²œì‹']
        resolved = []

        # ê¸°ì¡´ ë§Œì„± ì§ˆí™˜ ìœ ì§€
        for condition in old_val:
            if any(chronic in condition['name'].lower() for chronic in chronic_conditions):
                resolved.append(condition)
            elif self.is_still_active(condition):
                resolved.append(condition)

        # ìƒˆë¡œìš´ ì§„ë‹¨ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
        existing_names = {c['name'].lower() for c in resolved}
        for condition in new_val:
            if condition['name'].lower() not in existing_names:
                resolved.append(condition)

        return resolved

    def resolve_symptoms(self, new_val: List, old_val: List) -> List:
        """
        ì¦ìƒ ì¶©ëŒ í•´ê²°

        ê·œì¹™:
        1. ë¶€ì • í‘œí˜„ ìš°ì„  ("ë‘í†µ ì—†ìŒ" > "ë‘í†µ")
        2. ì‹œê°„ ê°€ì¤‘ì¹˜ ì ìš©
        3. ì‹¬ê°ë„ ë³€í™” ì¶”ì 
        """
        resolved = []
        symptom_map = {}

        # ê¸°ì¡´ ì¦ìƒ ë§¤í•‘
        for symptom in old_val:
            key = symptom['name'].lower()
            symptom_map[key] = symptom

        # ìƒˆë¡œìš´ ì¦ìƒ ì²˜ë¦¬
        for symptom in new_val:
            key = symptom['name'].lower()

            if key in symptom_map:
                # ê¸°ì¡´ ì¦ìƒê³¼ ë¹„êµ
                old_symptom = symptom_map[key]

                # ë¶€ì • í‘œí˜„ ì²´í¬
                if symptom.get('negated', False):
                    # ì¦ìƒ ì œê±°
                    del symptom_map[key]
                else:
                    # ì‹¬ê°ë„ ì—…ë°ì´íŠ¸
                    symptom_map[key] = self.merge_symptom_severity(symptom, old_symptom)
            else:
                # ìƒˆë¡œìš´ ì¦ìƒ
                symptom_map[key] = symptom

        resolved = list(symptom_map.values())
        return resolved

    def resolve_vitals(self, new_val: Dict, old_val: Dict) -> Dict:
        """
        ìƒì²´ ì‹ í˜¸ ì¶©ëŒ í•´ê²°

        ê·œì¹™:
        1. ì‹œê³„ì—´ ë°ì´í„°ë¡œ ê´€ë¦¬
        2. ì´ìƒì¹˜ íƒì§€
        3. íŠ¸ë Œë“œ ë¶„ì„
        """
        resolved = {}

        for vital_name in set(new_val.keys()) | set(old_val.keys()):
            if vital_name in new_val and vital_name in old_val:
                # ì‹œê³„ì—´ ë°ì´í„° êµ¬ì„±
                time_series = old_val.get(vital_name, {}).get('history', [])
                time_series.append({
                    'value': new_val[vital_name],
                    'timestamp': time.time()
                })

                # ì´ìƒì¹˜ íƒì§€
                if self.is_outlier(new_val[vital_name], time_series):
                    resolved[vital_name] = {
                        'value': new_val[vital_name],
                        'outlier': True,
                        'needs_confirmation': True,
                        'history': time_series[-10:]  # ìµœê·¼ 10ê°œ
                    }
                else:
                    resolved[vital_name] = {
                        'value': new_val[vital_name],
                        'trend': self.calculate_trend(time_series),
                        'history': time_series[-10:]
                    }
            elif vital_name in new_val:
                resolved[vital_name] = {
                    'value': new_val[vital_name],
                    'history': [{'value': new_val[vital_name], 'timestamp': time.time()}]
                }
            else:
                resolved[vital_name] = old_val[vital_name]

        return resolved
```

---

## ì œ4ì¥: ê³ ê¸‰ ë©”ëª¨ë¦¬ ê´€ë¦¬ ì•„í‚¤í…ì²˜

### 4.1 Episodic Buffer Architecture (EBA)

```python
class EpisodicBufferArchitecture:
    """
    ì—í”¼ì†Œë“œ ë²„í¼ ì•„í‚¤í…ì²˜

    Based on: Baddeley's Working Memory Model
    """

    def __init__(self, buffer_size: int = 100):
        self.phonological_loop = []  # ì–¸ì–´ì  ì •ë³´ (ëŒ€í™” ë‚´ìš©)
        self.visuospatial_sketchpad = []  # ì‹œê°ì  ì •ë³´ (ê²€ì‚¬ ê²°ê³¼)
        self.central_executive = CentralExecutive()  # í†µí•© ì²˜ë¦¬
        self.episodic_buffer = deque(maxlen=buffer_size)  # í†µí•© ë²„í¼

    def process_turn(self, turn_data: Dict) -> Dict:
        """ëŒ€í™” í„´ ì²˜ë¦¬"""
        # 1. ì–¸ì–´ ì •ë³´ ì²˜ë¦¬
        linguistic_features = self.extract_linguistic_features(turn_data['text'])
        self.phonological_loop.append(linguistic_features)

        # 2. ìˆ˜ì¹˜/ì‹œê° ì •ë³´ ì²˜ë¦¬
        numerical_features = self.extract_numerical_features(turn_data['text'])
        self.visuospatial_sketchpad.append(numerical_features)

        # 3. ì¤‘ì•™ ì§‘í–‰ê¸°ë¡œ í†µí•©
        integrated = self.central_executive.integrate(
            linguistic_features,
            numerical_features,
            self.episodic_buffer
        )

        # 4. ì—í”¼ì†Œë“œ ë²„í¼ì— ì €ì¥
        self.episodic_buffer.append({
            'turn_id': turn_data['turn_id'],
            'integrated_representation': integrated,
            'timestamp': time.time()
        })

        return integrated

    def retrieve_relevant_episodes(self, query: str, k: int = 5) -> List[Dict]:
        """
        ê´€ë ¨ ì—í”¼ì†Œë“œ ê²€ìƒ‰

        Using: Attention mechanism
        """
        query_embedding = self.encode(query)

        scores = []
        for episode in self.episodic_buffer:
            episode_embedding = episode['integrated_representation']

            # Attention score
            score = self.attention_score(query_embedding, episode_embedding)
            scores.append((score, episode))

        # Top-k episodes
        scores.sort(reverse=True, key=lambda x: x[0])
        return [episode for _, episode in scores[:k]]

    def attention_score(self, query: np.array, key: np.array) -> float:
        """
        Scaled dot-product attention

        score = (QÂ·K) / sqrt(d_k)
        """
        d_k = query.shape[-1]
        score = np.dot(query, key) / np.sqrt(d_k)
        return float(score)
```

### 4.2 Graph-based Slot Memory (GSM)

```python
class GraphBasedSlotMemory:
    """
    ê·¸ë˜í”„ ê¸°ë°˜ ìŠ¬ë¡¯ ë©”ëª¨ë¦¬

    Using: Neo4j or NetworkX
    """

    def __init__(self):
        self.graph = nx.DiGraph()
        self.node_counter = 0

    def add_slot_node(self, slot_type: str, value: Any, metadata: Dict):
        """ìŠ¬ë¡¯ ë…¸ë“œ ì¶”ê°€"""
        node_id = f"{slot_type}_{self.node_counter}"
        self.node_counter += 1

        self.graph.add_node(
            node_id,
            type=slot_type,
            value=value,
            timestamp=time.time(),
            **metadata
        )

        # ê´€ê³„ ì¶”ê°€
        self.add_relationships(node_id, slot_type)

        return node_id

    def add_relationships(self, node_id: str, slot_type: str):
        """ìŠ¬ë¡¯ ê°„ ê´€ê³„ ì¶”ê°€"""
        # ì‹œê°„ì  ê´€ê³„
        prev_nodes = [n for n in self.graph.nodes()
                     if self.graph.nodes[n]['type'] == slot_type
                     and n != node_id]

        if prev_nodes:
            latest = max(prev_nodes,
                        key=lambda n: self.graph.nodes[n]['timestamp'])
            self.graph.add_edge(latest, node_id, relation='temporal_next')

        # ì¸ê³¼ ê´€ê³„
        if slot_type == 'symptoms':
            condition_nodes = [n for n in self.graph.nodes()
                             if self.graph.nodes[n]['type'] == 'conditions']
            for cond_node in condition_nodes:
                if self.is_causally_related(node_id, cond_node):
                    self.graph.add_edge(cond_node, node_id, relation='causes')

        # ì˜ì¡´ ê´€ê³„
        if slot_type == 'medications':
            condition_nodes = [n for n in self.graph.nodes()
                             if self.graph.nodes[n]['type'] == 'conditions']
            for cond_node in condition_nodes:
                if self.is_treatment_for(node_id, cond_node):
                    self.graph.add_edge(node_id, cond_node, relation='treats')

    def query_graph(self, query_type: str, **kwargs) -> List[Dict]:
        """ê·¸ë˜í”„ ì¿¼ë¦¬"""
        if query_type == 'temporal_sequence':
            # ì‹œê°„ ìˆœì„œëŒ€ë¡œ ìŠ¬ë¡¯ ì¶”ì¶œ
            slot_type = kwargs.get('slot_type')
            nodes = [n for n in self.graph.nodes()
                    if self.graph.nodes[n]['type'] == slot_type]
            nodes.sort(key=lambda n: self.graph.nodes[n]['timestamp'])
            return [self.graph.nodes[n] for n in nodes]

        elif query_type == 'causal_chain':
            # ì¸ê³¼ ê´€ê³„ ì²´ì¸ ì¶”ì¶œ
            start_node = kwargs.get('start_node')
            chain = []

            def dfs(node, visited):
                if node in visited:
                    return
                visited.add(node)
                chain.append(self.graph.nodes[node])

                for successor in self.graph.successors(node):
                    if self.graph[node][successor].get('relation') == 'causes':
                        dfs(successor, visited)

            dfs(start_node, set())
            return chain

        elif query_type == 'related_slots':
            # ê´€ë ¨ ìŠ¬ë¡¯ ì¶”ì¶œ
            center_node = kwargs.get('node')
            radius = kwargs.get('radius', 2)

            subgraph = nx.ego_graph(self.graph, center_node, radius=radius)
            return [self.graph.nodes[n] for n in subgraph.nodes()]
```

### 4.3 Transformer-based Slot Tracker (TST)

```python
class TransformerSlotTracker:
    """
    Transformer ê¸°ë°˜ ìŠ¬ë¡¯ ì¶”ì ê¸°

    Based on: BERT-DST architecture
    """

    def __init__(self, hidden_size: int = 768, num_heads: int = 12):
        self.hidden_size = hidden_size
        self.num_heads = num_heads

        # Transformer encoder
        self.encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=hidden_size,
                nhead=num_heads,
                dim_feedforward=3072,
                dropout=0.1
            ),
            num_layers=6
        )

        # Slot-specific heads
        self.slot_heads = nn.ModuleDict({
            'demographics': nn.Linear(hidden_size, 256),
            'conditions': nn.Linear(hidden_size, 512),
            'symptoms': nn.Linear(hidden_size, 512),
            'vitals': nn.Linear(hidden_size, 256),
            'labs': nn.Linear(hidden_size, 256),
            'medications': nn.Linear(hidden_size, 512)
        })

        # Memory bank
        self.memory_bank = nn.Parameter(torch.randn(100, hidden_size))

    def forward(self, dialogue_history: List[str], current_turn: str) -> Dict:
        """ìŠ¬ë¡¯ ì¶”ì  ìˆ˜í–‰"""
        # 1. ì¸ì½”ë”©
        history_encodings = self.encode_dialogue(dialogue_history)
        current_encoding = self.encode_turn(current_turn)

        # 2. Attention with memory
        attended_memory = self.attend_to_memory(
            current_encoding,
            self.memory_bank
        )

        # 3. í†µí•©
        integrated = torch.cat([
            history_encodings,
            current_encoding,
            attended_memory
        ], dim=1)

        # 4. Transformer encoding
        encoded = self.encoder(integrated)

        # 5. ìŠ¬ë¡¯ë³„ ì˜ˆì¸¡
        slot_predictions = {}
        for slot_name, head in self.slot_heads.items():
            slot_predictions[slot_name] = head(encoded)

        return self.decode_slots(slot_predictions)

    def attend_to_memory(self, query: torch.Tensor, memory: torch.Tensor) -> torch.Tensor:
        """
        ë©”ëª¨ë¦¬ ë±…í¬ attention

        Using: Multi-head attention
        """
        attention = nn.MultiheadAttention(
            embed_dim=self.hidden_size,
            num_heads=self.num_heads
        )

        attended, attention_weights = attention(
            query.unsqueeze(0),
            memory.unsqueeze(0),
            memory.unsqueeze(0)
        )

        return attended.squeeze(0)

    def update_memory(self, new_info: torch.Tensor):
        """ë©”ëª¨ë¦¬ ë±…í¬ ì—…ë°ì´íŠ¸"""
        # Gated update mechanism
        gate = torch.sigmoid(self.memory_gate(new_info))
        self.memory_bank.data = gate * self.memory_bank.data + (1 - gate) * new_info
```

---

## ì œ5ì¥: ì‹¤ì „ êµ¬í˜„ ì „ëµ

### 5.1 Incremental Slot Update Pipeline

```python
class IncrementalSlotUpdatePipeline:
    """
    ì ì§„ì  ìŠ¬ë¡¯ ì—…ë°ì´íŠ¸ íŒŒì´í”„ë¼ì¸
    """

    def __init__(self):
        self.slot_tracker = TransformerSlotTracker()
        self.conflict_resolver = ConflictResolutionEngine()
        self.memory_manager = GraphBasedSlotMemory()
        self.buffer = EpisodicBufferArchitecture()

    def process_dialogue_turn(self, turn: Dict, state: AgentState) -> AgentState:
        """
        ëŒ€í™” í„´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

        1. ìŠ¬ë¡¯ ì¶”ì¶œ
        2. ì¶©ëŒ í•´ê²°
        3. ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸
        4. ìƒíƒœ ë°˜ì˜
        """
        # 1. í˜„ì¬ í„´ì—ì„œ ìŠ¬ë¡¯ ì¶”ì¶œ
        current_slots = self.extract_slots(turn['text'])

        # 2. ì´ì „ ìŠ¬ë¡¯ê³¼ ë¹„êµ ë° ì¶©ëŒ í•´ê²°
        previous_slots = state.get('accumulated_slots', {})
        resolved_slots = self.conflict_resolver.resolve_conflicts(
            current_slots,
            previous_slots
        )

        # 3. ê·¸ë˜í”„ ë©”ëª¨ë¦¬ì— ì €ì¥
        for slot_type, value in resolved_slots.items():
            self.memory_manager.add_slot_node(slot_type, value, {
                'turn_id': turn['turn_id'],
                'confidence': self.calculate_confidence(value)
            })

        # 4. ì—í”¼ì†Œë“œ ë²„í¼ ì—…ë°ì´íŠ¸
        episode = self.buffer.process_turn(turn)

        # 5. ìƒíƒœ ì—…ë°ì´íŠ¸
        updated_state = {
            **state,
            'accumulated_slots': resolved_slots,
            'slot_graph': self.memory_manager.graph,
            'episodic_buffer': self.buffer.episodic_buffer,
            'last_update_turn': turn['turn_id']
        }

        return updated_state

    def generate_slot_aware_response(self, query: str, state: AgentState) -> str:
        """
        ìŠ¬ë¡¯ ì¸ì‹ ì‘ë‹µ ìƒì„±

        ìŠ¬ë¡¯ ì •ë³´ë¥¼ í™œìš©í•œ ë§ì¶¤í˜• ì‘ë‹µ
        """
        # ê´€ë ¨ ìŠ¬ë¡¯ ì¶”ì¶œ
        relevant_slots = self.get_relevant_slots(query, state)

        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self.build_slot_aware_prompt(query, relevant_slots)

        # LLM í˜¸ì¶œ
        response = self.llm_client.generate(prompt)

        # ìŠ¬ë¡¯ ì°¸ì¡° í‘œì‹œ
        response = self.mark_slot_references(response, relevant_slots)

        return response
```

### 5.2 Active Learning for Slot Disambiguation

```python
class ActiveSlotDisambiguation:
    """
    ëŠ¥ë™ì  ìŠ¬ë¡¯ ëª…í™•í™”

    ë¶ˆí™•ì‹¤í•œ ìŠ¬ë¡¯ì— ëŒ€í•´ ì‚¬ìš©ìì—ê²Œ í™•ì¸ ìš”ì²­
    """

    def __init__(self, uncertainty_threshold: float = 0.3):
        self.uncertainty_threshold = uncertainty_threshold
        self.clarification_templates = {
            'demographics': "ì œê°€ ì˜¬ë°”ë¥´ê²Œ ì´í•´í–ˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤. {field}ì´(ê°€) {value}ì´(ê°€) ë§ë‚˜ìš”?",
            'conditions': "ë§ì”€í•˜ì‹  {value}ì€(ëŠ”) í˜„ì¬ ì§„ë‹¨ë°›ì€ ì§ˆí™˜ì¸ê°€ìš”, ì•„ë‹ˆë©´ ê³¼ê±° ë³‘ë ¥ì¸ê°€ìš”?",
            'symptoms': "{value} ì¦ìƒì´ ì–¸ì œë¶€í„° ì‹œì‘ë˜ì—ˆë‚˜ìš”? ê·¸ë¦¬ê³  ì§€ê¸ˆë„ ê³„ì†ë˜ê³  ìˆë‚˜ìš”?",
            'vitals': "ì¸¡ì •í•˜ì‹  {field}ì´(ê°€) {value}{unit}ì´(ê°€) ë§ë‚˜ìš”? ì–¸ì œ ì¸¡ì •í•˜ì‹  ê°’ì¸ê°€ìš”?",
            'labs': "{field} ê²€ì‚¬ ê²°ê³¼ê°€ {value}{unit}ì´(ê°€) ë§ë‚˜ìš”? ê²€ì‚¬ ë‚ ì§œë¥¼ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?",
            'medications': "{value}ì„(ë¥¼) í˜„ì¬ ë³µìš© ì¤‘ì´ì‹ ê°€ìš”? ìš©ëŸ‰ê³¼ ë¹ˆë„ë¥¼ í™•ì¸í•´ ì£¼ì‹œê² ì–´ìš”?"
        }

    def identify_uncertain_slots(self, slots: Dict) -> List[Tuple[str, Any, float]]:
        """ë¶ˆí™•ì‹¤í•œ ìŠ¬ë¡¯ ì‹ë³„"""
        uncertain = []

        for slot_type, values in slots.items():
            if isinstance(values, list):
                for value in values:
                    uncertainty = self.calculate_uncertainty(value)
                    if uncertainty > self.uncertainty_threshold:
                        uncertain.append((slot_type, value, uncertainty))
            else:
                uncertainty = self.calculate_uncertainty(values)
                if uncertainty > self.uncertainty_threshold:
                    uncertain.append((slot_type, values, uncertainty))

        # ë¶ˆí™•ì‹¤ì„± ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        uncertain.sort(key=lambda x: x[2], reverse=True)

        return uncertain

    def generate_clarification_question(self, uncertain_slot: Tuple) -> str:
        """ëª…í™•í™” ì§ˆë¬¸ ìƒì„±"""
        slot_type, value, uncertainty = uncertain_slot

        template = self.clarification_templates.get(slot_type)
        if template:
            question = template.format(
                field=value.get('name', 'í•­ëª©'),
                value=value.get('value', 'ê°’'),
                unit=value.get('unit', '')
            )
        else:
            question = f"'{value}'ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì‹œê² ì–´ìš”?"

        return question

    def update_with_clarification(self, original_slot: Dict,
                                 clarification: str) -> Dict:
        """ëª…í™•í™” ì •ë³´ë¡œ ìŠ¬ë¡¯ ì—…ë°ì´íŠ¸"""
        updated_slot = original_slot.copy()

        # ëª…í™•í™” ì •ë³´ íŒŒì‹±
        clarified_info = self.parse_clarification(clarification)

        # ì‹ ë¢°ë„ í–¥ìƒ
        updated_slot['confidence'] = min(1.0,
                                        original_slot.get('confidence', 0.5) + 0.3)

        # ì •ë³´ ì—…ë°ì´íŠ¸
        updated_slot.update(clarified_info)

        # ëª…í™•í™” ì´ë ¥ ì €ì¥
        if 'clarification_history' not in updated_slot:
            updated_slot['clarification_history'] = []

        updated_slot['clarification_history'].append({
            'timestamp': time.time(),
            'original': original_slot,
            'clarification': clarification,
            'clarified_info': clarified_info
        })

        return updated_slot
```

### 5.3 Context-Aware Slot Projection

```python
class ContextAwareSlotProjection:
    """
    ë¬¸ë§¥ ì¸ì‹ ìŠ¬ë¡¯ íˆ¬ì˜

    ë¯¸ë˜ ëŒ€í™”ë¥¼ ìœ„í•œ ìŠ¬ë¡¯ ì˜ˆì¸¡
    """

    def __init__(self):
        self.projection_model = self.build_projection_model()
        self.context_encoder = ContextEncoder()

    def build_projection_model(self):
        """LSTM ê¸°ë°˜ íˆ¬ì˜ ëª¨ë¸"""
        return nn.LSTM(
            input_size=768,
            hidden_size=256,
            num_layers=2,
            bidirectional=True,
            batch_first=True
        )

    def project_future_slots(self, current_slots: Dict,
                            context: str,
                            horizon: int = 3) -> List[Dict]:
        """
        ë¯¸ë˜ ìŠ¬ë¡¯ ì˜ˆì¸¡

        horizon: ì˜ˆì¸¡í•  ëŒ€í™” í„´ ìˆ˜
        """
        # í˜„ì¬ ìƒíƒœ ì¸ì½”ë”©
        current_encoding = self.encode_current_state(current_slots, context)

        # LSTMìœ¼ë¡œ ë¯¸ë˜ ìƒíƒœ ì˜ˆì¸¡
        future_states = []
        hidden = None

        for t in range(horizon):
            output, hidden = self.projection_model(current_encoding, hidden)

            # ìŠ¬ë¡¯ë³„ ì˜ˆì¸¡
            projected_slots = self.decode_to_slots(output)

            # í™•ë¥ ì  ìƒ˜í”Œë§
            sampled_slots = self.probabilistic_sampling(projected_slots)

            future_states.append({
                'turn': t + 1,
                'projected_slots': sampled_slots,
                'confidence': self.calculate_projection_confidence(t)
            })

            # ë‹¤ìŒ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©
            current_encoding = self.encode_current_state(sampled_slots, "")

        return future_states

    def suggest_proactive_questions(self, projected_slots: List[Dict]) -> List[str]:
        """
        ì˜ˆì¸¡ ê¸°ë°˜ ì„ ì œì  ì§ˆë¬¸ ìƒì„±

        ì˜ˆì¸¡ëœ ìŠ¬ë¡¯ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë¯¸ë¦¬ ë¬¼ì–´ë³¼ ì§ˆë¬¸
        """
        questions = []

        for projection in projected_slots:
            slots = projection['projected_slots']

            # ë¹„ì–´ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ëŠ” ì¤‘ìš” ìŠ¬ë¡¯
            empty_critical_slots = self.identify_empty_critical_slots(slots)

            for slot_type in empty_critical_slots:
                question = self.generate_proactive_question(slot_type)
                questions.append({
                    'question': question,
                    'slot_type': slot_type,
                    'priority': self.calculate_priority(slot_type),
                    'expected_turn': projection['turn']
                })

        # ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
        questions.sort(key=lambda x: x['priority'], reverse=True)

        return questions[:3]  # Top 3 questions
```

---

## ì œ6ì¥: í‰ê°€ ë©”íŠ¸ë¦­ ë° ì‹¤í—˜

### 6.1 ìŠ¬ë¡¯ ì¶”ì  ì„±ëŠ¥ ë©”íŠ¸ë¦­

```python
class SlotTrackingMetrics:
    """ìŠ¬ë¡¯ ì¶”ì  ì„±ëŠ¥ í‰ê°€"""

    def joint_goal_accuracy(self, predicted: Dict, ground_truth: Dict) -> float:
        """
        Joint Goal Accuracy

        ëª¨ë“  ìŠ¬ë¡¯ì´ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë¹„ìœ¨
        """
        if predicted == ground_truth:
            return 1.0
        return 0.0

    def slot_accuracy(self, predicted: Dict, ground_truth: Dict) -> Dict[str, float]:
        """ìŠ¬ë¡¯ë³„ ì •í™•ë„"""
        accuracies = {}

        for slot_type in ground_truth:
            if slot_type in predicted:
                if predicted[slot_type] == ground_truth[slot_type]:
                    accuracies[slot_type] = 1.0
                else:
                    # ë¶€ë¶„ ì¼ì¹˜ ì ìˆ˜
                    accuracies[slot_type] = self.partial_match_score(
                        predicted[slot_type],
                        ground_truth[slot_type]
                    )
            else:
                accuracies[slot_type] = 0.0

        return accuracies

    def temporal_consistency(self, slot_history: List[Dict]) -> float:
        """
        ì‹œê°„ì  ì¼ê´€ì„±

        ìŠ¬ë¡¯ ê°’ì´ ì‹œê°„ì— ë”°ë¼ ì–¼ë§ˆë‚˜ ì¼ê´€ë˜ê²Œ ìœ ì§€ë˜ëŠ”ê°€
        """
        if len(slot_history) < 2:
            return 1.0

        consistency_scores = []

        for i in range(1, len(slot_history)):
            prev_slots = slot_history[i-1]
            curr_slots = slot_history[i]

            # ë³€ê²½ë˜ì§€ ì•Šì•„ì•¼ í•  ìŠ¬ë¡¯ ì²´í¬
            static_slots = ['demographics']
            for slot_type in static_slots:
                if slot_type in prev_slots and slot_type in curr_slots:
                    if prev_slots[slot_type] == curr_slots[slot_type]:
                        consistency_scores.append(1.0)
                    else:
                        consistency_scores.append(0.0)

        return np.mean(consistency_scores) if consistency_scores else 1.0
```

### 6.2 ì‹¤í—˜ ì„¤ê³„

```python
class MultiTurnSlotExperiment:
    """ë©€í‹°í„´ ìŠ¬ë¡¯ ì¶”ì  ì‹¤í—˜"""

    def __init__(self):
        self.test_scenarios = self.load_test_scenarios()
        self.baseline_systems = {
            'rule_based': RuleBasedSlotTracker(),
            'lstm_based': LSTMSlotTracker(),
            'bert_dst': BERTDSTSlotTracker()
        }
        self.our_system = HierarchicalSlotMemoryNetwork()

    def run_experiment(self):
        """ì‹¤í—˜ ì‹¤í–‰"""
        results = {}

        for scenario in self.test_scenarios:
            scenario_results = {}

            # ê° ì‹œìŠ¤í…œ í‰ê°€
            for system_name, system in {**self.baseline_systems,
                                       'ours': self.our_system}.items():
                metrics = self.evaluate_system(system, scenario)
                scenario_results[system_name] = metrics

            results[scenario['id']] = scenario_results

        return self.analyze_results(results)

    def evaluate_system(self, system, scenario):
        """ì‹œìŠ¤í…œ í‰ê°€"""
        dialogue = scenario['dialogue']
        ground_truth = scenario['ground_truth_slots']

        predicted_slots = {}
        slot_history = []

        for turn in dialogue:
            # ìŠ¬ë¡¯ ì¶”ì 
            predicted = system.track_slots(turn, slot_history)
            predicted_slots[turn['id']] = predicted
            slot_history.append(predicted)

        # ë©”íŠ¸ë¦­ ê³„ì‚°
        metrics = {
            'joint_accuracy': self.calculate_joint_accuracy(
                predicted_slots,
                ground_truth
            ),
            'slot_accuracy': self.calculate_slot_accuracy(
                predicted_slots,
                ground_truth
            ),
            'temporal_consistency': self.calculate_temporal_consistency(
                slot_history
            ),
            'latency': self.measure_latency(system, dialogue)
        }

        return metrics
```

---

## ì œ7ì¥: ì‹¤ì „ ì ìš© ë° ìµœì í™”

### 7.1 Production ë°°í¬ ì „ëµ

```python
class ProductionSlotTracker:
    """í”„ë¡œë•ì…˜ í™˜ê²½ ìŠ¬ë¡¯ ì¶”ì ê¸°"""

    def __init__(self):
        self.primary_tracker = OptimizedHSMN()  # ìµœì í™”ëœ HSMN
        self.fallback_tracker = RuleBasedTracker()  # Fallback
        self.cache = SlotCache()
        self.monitor = PerformanceMonitor()

    async def track_slots_async(self, turn: Dict, state: Dict) -> Dict:
        """ë¹„ë™ê¸° ìŠ¬ë¡¯ ì¶”ì """
        # ìºì‹œ í™•ì¸
        cache_key = self.generate_cache_key(turn, state)
        if cached := await self.cache.get(cache_key):
            return cached

        try:
            # Primary tracker
            result = await asyncio.wait_for(
                self.primary_tracker.track(turn, state),
                timeout=0.5  # 500ms timeout
            )
        except asyncio.TimeoutError:
            # Fallback
            self.monitor.log_timeout()
            result = await self.fallback_tracker.track(turn, state)

        # ìºì‹œ ì €ì¥
        await self.cache.set(cache_key, result)

        return result
```

### 7.2 ìµœì í™” ê¸°ë²•

```python
class OptimizedHSMN(HierarchicalSlotMemoryNetwork):
    """ìµœì í™”ëœ HSMN"""

    def __init__(self):
        super().__init__()

        # Quantization for faster inference
        self.quantized_model = torch.quantization.quantize_dynamic(
            self.model,
            {torch.nn.Linear, torch.nn.LSTM},
            dtype=torch.qint8
        )

        # Pruning
        self.pruned_model = self.prune_model(sparsity=0.5)

        # ONNX conversion
        self.onnx_model = self.convert_to_onnx()

    def optimized_inference(self, input_data):
        """ìµœì í™”ëœ ì¶”ë¡ """
        # Batching
        if len(input_data) > 1:
            return self.batch_inference(input_data)

        # Single inference with optimization
        with torch.no_grad():
            with torch.jit.optimized_execution(True):
                output = self.quantized_model(input_data)

        return output
```

---

## ê²°ë¡ 

### í•µì‹¬ í˜ì‹ 

ë©€í‹°í„´ ëŒ€í™”ì—ì„œ 6ê°œ ìŠ¬ë¡¯ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ í•µì‹¬ í˜ì‹ :

1. **Hierarchical Slot Memory Network (HSMN)**
   - Turn, Session, Patient ë ˆë²¨ ê³„ì¸µì  ë©”ëª¨ë¦¬
   - Cross-attention ê¸°ë°˜ ì •ë³´ í†µí•©

2. **Temporal Slot Evolution Model (TSEM)**
   - ì‹œê°„ì  ê°€ì¤‘ì¹˜ì™€ decay rate
   - Gaussian Process ê¸°ë°˜ ì˜ˆì¸¡

3. **Conflict Resolution Engine (CRE)**
   - ìŠ¬ë¡¯ë³„ ë§ì¶¤ ì¶©ëŒ í•´ê²° ì „ëµ
   - ì˜ë£Œ ë„ë©”ì¸ íŠ¹í™” ê·œì¹™

4. **Graph-based Slot Memory (GSM)**
   - ìŠ¬ë¡¯ ê°„ ê´€ê³„ ê·¸ë˜í”„
   - ì¸ê³¼ê´€ê³„ ë° ì‹œê°„ì  ê´€ê³„ ëª¨ë¸ë§

5. **Active Slot Disambiguation**
   - ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ëŠ¥ë™ì  ì§ˆë¬¸
   - ì‚¬ìš©ì í”¼ë“œë°± í†µí•©

### ì„±ëŠ¥ í–¥ìƒ ì˜ˆìƒì¹˜

- **ìŠ¬ë¡¯ ì¶”ì  ì •í™•ë„**: 85% â†’ 94% (9%p í–¥ìƒ)
- **ì‹œê°„ì  ì¼ê´€ì„±**: 72% â†’ 89% (17%p í–¥ìƒ)
- **ì¶©ëŒ í•´ê²°ë¥ **: 68% â†’ 91% (23%p í–¥ìƒ)
- **ì‘ë‹µ ì‹œê°„**: 800ms â†’ 350ms (56% ë‹¨ì¶•)

### êµ¬í˜„ ë¡œë“œë§µ

1. **Week 1-2**: ê¸°ë³¸ HSMN êµ¬í˜„
2. **Week 3-4**: Conflict Resolution í†µí•©
3. **Week 5-6**: Graph Memory êµ¬ì¶•
4. **Week 7-8**: ìµœì í™” ë° í…ŒìŠ¤íŠ¸
5. **Week 9-10**: Production ë°°í¬

### í–¥í›„ ì—°êµ¬ ë°©í–¥

1. **Continual Learning**: ì§€ì†ì  í•™ìŠµìœ¼ë¡œ ìŠ¬ë¡¯ ì¶”ì  ê°œì„ 
2. **Cross-lingual Slot Tracking**: ë‹¤êµ­ì–´ ìŠ¬ë¡¯ ì¶”ì 
3. **Multimodal Slot Integration**: í…ìŠ¤íŠ¸ + ìŒì„± + ì´ë¯¸ì§€
4. **Federated Slot Learning**: ë¶„ì‚° í™˜ê²½ì—ì„œ í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ í•™ìŠµ

---

*ì‘ì„±ì¼: 2024ë…„ 12ì›” 4ì¼*
*ë²„ì „: 1.0*