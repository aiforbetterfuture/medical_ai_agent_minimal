"""
ë‹¨ì¼ Ablation í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

Usage:
    python experiments/run_ablation_single.py

ì»¤ìŠ¤í„°ë§ˆì´ì§•:
    - ABLATION_NAME: ì‹¤í—˜ ì´ë¦„
    - FEATURE_CONFIG: í…ŒìŠ¤íŠ¸í•  feature flags
    - TEST_QUERIES: í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ëª©ë¡
"""
import json
import sys
from pathlib import Path
from datetime import datetime
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agent.graph import run_agent

# ============================================================
# ì„¤ì • ì„¹ì…˜ (ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”)
# ============================================================

ABLATION_NAME = "self_refine_off"  # ì‹¤í—˜ ì´ë¦„ (íŒŒì¼ëª…ì— ì‚¬ìš©ë¨)

# Feature flags ì„¤ì • (í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì€ ì„¤ì •)
FEATURE_CONFIG = {
    'self_refine_enabled': False,  # â­ ì£¼ìš” í…ŒìŠ¤íŠ¸ ë³€ìˆ˜
    'retrieval_mode': 'hybrid',
    'active_retrieval_enabled': False,
    'response_cache_enabled': False,  # ìºì‹œ ë¹„í™œì„±í™” (ìˆœìˆ˜ ì„±ëŠ¥ ì¸¡ì •)
}

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ëª©ë¡
TEST_QUERIES = [
    "ë‹¹ë‡¨ë³‘ í™˜ìì—ê²Œ ë©”íŠ¸í¬ë¥´ë¯¼ì˜ ë¶€ì‘ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ê³ í˜ˆì•• í™˜ìì˜ ì‹ì´ìš”ë²•ì€ ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
    "ì•„ìŠ¤í”¼ë¦°ì„ ë³µìš©í•˜ëŠ” í™˜ìê°€ í”¼í•´ì•¼ í•  ìŒì‹ì€?",
    "ì„ì‹  ì¤‘ ë³µìš© ê°€ëŠ¥í•œ ì§„í†µì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
    "ê°„ ì§ˆí™˜ í™˜ìì—ê²Œ ê¸ˆê¸°ì¸ ì•½ë¬¼ì€?",
]

# ============================================================
# ì‹¤í–‰ ì„¹ì…˜
# ============================================================

def main():
    print("=" * 80)
    print(f"Ablation Test: {ABLATION_NAME}")
    print("=" * 80)
    print(f"Feature Config: {json.dumps(FEATURE_CONFIG, indent=2)}")
    print(f"Test Queries: {len(TEST_QUERIES)}ê°œ")
    print("=" * 80)
    print()

    results = []
    total_start_time = time.time()

    for i, query in enumerate(TEST_QUERIES, 1):
        print(f"[{i}/{len(TEST_QUERIES)}] ì‹¤í–‰ ì¤‘: {query[:50]}...")

        query_start_time = time.time()

        try:
            result = run_agent(
                user_text=query,
                mode="ai_agent",
                feature_overrides=FEATURE_CONFIG,
                return_state=True
            )

            query_elapsed = time.time() - query_start_time

            # ë©”íŠ¸ë¦­ ì¶”ì¶œ
            metrics = {
                'query_id': i,
                'query': query,
                'answer': result.get('answer', ''),
                'quality_score': result.get('quality_score', 0.0),
                'iteration_count': result.get('iteration_count', 0),
                'num_docs': len(result.get('retrieved_docs', [])),
                'cache_hit': result.get('cache_hit', False),
                'elapsed_sec': query_elapsed,
                'total_tokens': result.get('total_tokens', 0),
                'estimated_cost_usd': result.get('estimated_cost_usd', 0.0),
            }

            results.append(metrics)

            print(f"  âœ“ í’ˆì§ˆ: {metrics['quality_score']:.3f}, "
                  f"ë°˜ë³µ: {metrics['iteration_count']}, "
                  f"ë¬¸ì„œ: {metrics['num_docs']}, "
                  f"ì‹œê°„: {metrics['elapsed_sec']:.1f}s")

        except Exception as e:
            print(f"  âœ— ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            results.append({
                'query_id': i,
                'query': query,
                'error': str(e),
                'elapsed_sec': time.time() - query_start_time,
            })

        print()

    total_elapsed = time.time() - total_start_time

    # ============================================================
    # í†µê³„ ìš”ì•½
    # ============================================================
    successful_results = [r for r in results if 'error' not in r]

    if successful_results:
        summary = {
            'total_queries': len(TEST_QUERIES),
            'successful': len(successful_results),
            'failed': len(results) - len(successful_results),
            'avg_quality': sum(r['quality_score'] for r in successful_results) / len(successful_results),
            'avg_iterations': sum(r['iteration_count'] for r in successful_results) / len(successful_results),
            'avg_docs': sum(r['num_docs'] for r in successful_results) / len(successful_results),
            'avg_time_sec': sum(r['elapsed_sec'] for r in successful_results) / len(successful_results),
            'total_time_sec': total_elapsed,
            'total_tokens': sum(r.get('total_tokens', 0) for r in successful_results),
            'total_cost_usd': sum(r.get('estimated_cost_usd', 0.0) for r in successful_results),
            'cache_hit_rate': sum(r['cache_hit'] for r in successful_results) / len(successful_results) if successful_results else 0.0,
        }

        print("=" * 80)
        print("í†µê³„ ìš”ì•½")
        print("=" * 80)
        print(f"ì„±ê³µ/ì „ì²´: {summary['successful']}/{summary['total_queries']}")
        print(f"í‰ê·  í’ˆì§ˆ ì ìˆ˜: {summary['avg_quality']:.3f}")
        print(f"í‰ê·  ë°˜ë³µ íšŸìˆ˜: {summary['avg_iterations']:.2f}")
        print(f"í‰ê·  ê²€ìƒ‰ ë¬¸ì„œ: {summary['avg_docs']:.1f}")
        print(f"í‰ê·  ì‹¤í–‰ ì‹œê°„: {summary['avg_time_sec']:.2f}ì´ˆ")
        print(f"ì´ ì‹¤í–‰ ì‹œê°„: {summary['total_time_sec']:.1f}ì´ˆ")
        print(f"ì´ í† í° ì‚¬ìš©: {summary['total_tokens']:,}")
        print(f"ì´ ì˜ˆìƒ ë¹„ìš©: ${summary['total_cost_usd']:.4f}")
        print(f"ìºì‹œ íˆíŠ¸ìœ¨: {summary['cache_hit_rate']:.1%}")
        print("=" * 80)
    else:
        summary = {'error': 'ëª¨ë“  ì¿¼ë¦¬ ì‹¤íŒ¨'}
        print("\nâš ï¸ ëª¨ë“  ì¿¼ë¦¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    # ============================================================
    # ê²°ê³¼ ì €ì¥
    # ============================================================
    output_dir = project_root / "runs" / f"ablation_{ABLATION_NAME}"
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"results_{timestamp}.json"

    output_data = {
        'ablation_name': ABLATION_NAME,
        'feature_config': FEATURE_CONFIG,
        'timestamp': datetime.now().isoformat(),
        'num_queries': len(TEST_QUERIES),
        'results': results,
        'summary': summary,
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ê²°ê³¼ ì €ì¥ë¨: {output_file}")
    print(f"   ë””ë ‰í† ë¦¬: {output_dir}")

    # ê°„ë‹¨í•œ CSVë„ ì €ì¥ (ì—‘ì…€ë¡œ ì—´ê¸° ì‰½ê²Œ)
    if successful_results:
        csv_file = output_dir / f"results_{timestamp}.csv"
        with open(csv_file, 'w', encoding='utf-8-sig') as f:
            # Header
            f.write("ID,Query,Quality,Iterations,Docs,Time(s),Tokens,Cost($)\n")
            # Rows
            for r in successful_results:
                f.write(f"{r['query_id']},"
                       f"\"{r['query']}\","
                       f"{r['quality_score']:.3f},"
                       f"{r['iteration_count']},"
                       f"{r['num_docs']},"
                       f"{r['elapsed_sec']:.2f},"
                       f"{r.get('total_tokens', 0)},"
                       f"{r.get('estimated_cost_usd', 0.0):.6f}\n")
        print(f"   CSV íŒŒì¼: {csv_file}")

    print("\nì‹¤í—˜ ì™„ë£Œ! ğŸ‰")


if __name__ == "__main__":
    main()