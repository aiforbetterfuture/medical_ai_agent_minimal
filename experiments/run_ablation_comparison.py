"""
ë‹¤ì¤‘ Ablation í”„ë¡œíŒŒì¼ ë¹„êµ ì‹¤í—˜

ì—¬ëŸ¬ í”„ë¡œíŒŒì¼ì„ ë™ì¼í•œ ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì„±ëŠ¥ ë¹„êµ

Usage:
    python experiments/run_ablation_comparison.py
"""
import json
import sys
from pathlib import Path
from datetime import datetime
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from agent.graph import run_agent
from config.ablation_config import ABLATION_PROFILES, get_ablation_profile

# ============================================================
# ì„¤ì • ì„¹ì…˜
# ============================================================

# ë¹„êµí•  í”„ë¡œíŒŒì¼ ëª©ë¡ (config/ablation_config.py ì°¸ì¡°)
PROFILES_TO_TEST = [
    "baseline",
    "self_refine_heuristic",
    "self_refine_llm_quality",
    "self_refine_dynamic_query",
    "full_context_engineering",
]

# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ (ë¹ ë¥¸ ë¹„êµë¥¼ ìœ„í•´ ì ì€ ìˆ˜ ì‚¬ìš©)
TEST_QUERIES = [
    "ë‹¹ë‡¨ë³‘ í™˜ìì—ê²Œ ë©”íŠ¸í¬ë¥´ë¯¼ì˜ ë¶€ì‘ìš©ì€?",
    "ê³ í˜ˆì•• í™˜ìì˜ ì‹ì´ìš”ë²•ì€?",
    "ì•„ìŠ¤í”¼ë¦° ë³µìš© ì‹œ í”¼í•´ì•¼ í•  ìŒì‹ì€?",
    "ì„ì‹  ì¤‘ ë³µìš© ê°€ëŠ¥í•œ ì§„í†µì œëŠ”?",
    "ê°„ ì§ˆí™˜ í™˜ìì—ê²Œ ê¸ˆê¸°ì¸ ì•½ë¬¼ì€?",
]

# ============================================================
# ì‹¤í–‰ ì„¹ì…˜
# ============================================================

def main():
    print("=" * 80)
    print("Ablation Study - í”„ë¡œíŒŒì¼ ë¹„êµ ì‹¤í—˜")
    print("=" * 80)
    print(f"ë¹„êµ í”„ë¡œíŒŒì¼ ìˆ˜: {len(PROFILES_TO_TEST)}")
    print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìˆ˜: {len(TEST_QUERIES)}")
    print(f"ì´ ì‹¤í–‰ íšŸìˆ˜: {len(PROFILES_TO_TEST) * len(TEST_QUERIES)}")
    print("=" * 80)
    print()

    # í”„ë¡œíŒŒì¼ë³„ ê²°ê³¼ ì €ì¥
    all_results = {}

    # ê° í”„ë¡œíŒŒì¼ í…ŒìŠ¤íŠ¸
    for profile_idx, profile_name in enumerate(PROFILES_TO_TEST, 1):
        print(f"\n{'='*80}")
        print(f"[{profile_idx}/{len(PROFILES_TO_TEST)}] í”„ë¡œíŒŒì¼: {profile_name}")
        print(f"{'='*80}")

        # í”„ë¡œíŒŒì¼ ë¡œë“œ
        try:
            features = get_ablation_profile(profile_name)
            print(f"ì„¤ëª…: {ABLATION_PROFILES[profile_name]['description']}")
        except ValueError as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            continue

        # ìºì‹œ ë¹„í™œì„±í™” (ìˆœìˆ˜ ì„±ëŠ¥ ì¸¡ì •)
        features['response_cache_enabled'] = False

        profile_results = []

        # ê° ì¿¼ë¦¬ ì‹¤í–‰
        for query_idx, query in enumerate(TEST_QUERIES, 1):
            print(f"  [{query_idx}/{len(TEST_QUERIES)}] {query[:40]}...")

            query_start = time.time()

            try:
                result = run_agent(
                    user_text=query,
                    mode="ai_agent",
                    feature_overrides=features,
                    return_state=True
                )

                query_elapsed = time.time() - query_start

                metrics = {
                    'query_id': query_idx,
                    'query': query,
                    'quality_score': result.get('quality_score', 0.0),
                    'iteration_count': result.get('iteration_count', 0),
                    'num_docs': len(result.get('retrieved_docs', [])),
                    'elapsed_sec': query_elapsed,
                    'total_tokens': result.get('total_tokens', 0),
                    'estimated_cost_usd': result.get('estimated_cost_usd', 0.0),
                }

                profile_results.append(metrics)

                print(f"    âœ“ Q={metrics['quality_score']:.3f}, "
                      f"Iter={metrics['iteration_count']}, "
                      f"Docs={metrics['num_docs']}, "
                      f"Time={metrics['elapsed_sec']:.1f}s")

            except Exception as e:
                print(f"    âœ— ì˜¤ë¥˜: {str(e)}")
                profile_results.append({
                    'query_id': query_idx,
                    'query': query,
                    'error': str(e),
                })

        # í”„ë¡œíŒŒì¼ë³„ í†µê³„ ê³„ì‚°
        successful = [r for r in profile_results if 'error' not in r]

        if successful:
            summary = {
                'total_queries': len(TEST_QUERIES),
                'successful': len(successful),
                'avg_quality': sum(r['quality_score'] for r in successful) / len(successful),
                'avg_iterations': sum(r['iteration_count'] for r in successful) / len(successful),
                'avg_docs': sum(r['num_docs'] for r in successful) / len(successful),
                'avg_time_sec': sum(r['elapsed_sec'] for r in successful) / len(successful),
                'total_tokens': sum(r.get('total_tokens', 0) for r in successful),
                'total_cost_usd': sum(r.get('estimated_cost_usd', 0.0) for r in successful),
            }

            all_results[profile_name] = {
                'description': ABLATION_PROFILES[profile_name]['description'],
                'feature_config': features,
                'results': profile_results,
                'summary': summary,
            }

            print(f"\n  ğŸ“Š ìš”ì•½: Q={summary['avg_quality']:.3f}, "
                  f"Iter={summary['avg_iterations']:.1f}, "
                  f"Docs={summary['avg_docs']:.1f}, "
                  f"Time={summary['avg_time_sec']:.1f}s")
        else:
            print(f"\n  âš ï¸ ëª¨ë“  ì¿¼ë¦¬ ì‹¤íŒ¨")
            all_results[profile_name] = {
                'description': ABLATION_PROFILES[profile_name]['description'],
                'feature_config': features,
                'results': profile_results,
                'summary': {'error': 'ëª¨ë“  ì¿¼ë¦¬ ì‹¤íŒ¨'},
            }

    # ============================================================
    # ì „ì²´ ë¹„êµ í…Œì´ë¸” ì¶œë ¥
    # ============================================================
    print(f"\n\n{'='*80}")
    print("ì „ì²´ ë¹„êµ ê²°ê³¼")
    print(f"{'='*80}")

    # í—¤ë”
    print(f"{'í”„ë¡œíŒŒì¼':<30} {'í’ˆì§ˆ':>8} {'ë°˜ë³µ':>6} {'ë¬¸ì„œ':>6} {'ì‹œê°„(s)':>8} {'ë¹„ìš©($)':>10}")
    print(f"{'-'*80}")

    # ê° í”„ë¡œíŒŒì¼ í†µê³„
    for profile_name in PROFILES_TO_TEST:
        if profile_name not in all_results:
            continue

        data = all_results[profile_name]
        if 'error' in data['summary']:
            print(f"{profile_name:<30} {'ERROR'}")
            continue

        s = data['summary']
        print(f"{profile_name:<30} "
              f"{s['avg_quality']:>8.3f} "
              f"{s['avg_iterations']:>6.1f} "
              f"{s['avg_docs']:>6.1f} "
              f"{s['avg_time_sec']:>8.1f} "
              f"{s['total_cost_usd']:>10.6f}")

    print(f"{'='*80}")

    # ============================================================
    # ê²°ê³¼ ì €ì¥
    # ============================================================
    output_dir = project_root / "runs" / "ablation_comparison"
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"comparison_{timestamp}.json"

    output_data = {
        'experiment_type': 'ablation_comparison',
        'timestamp': datetime.now().isoformat(),
        'profiles_tested': PROFILES_TO_TEST,
        'num_queries': len(TEST_QUERIES),
        'test_queries': TEST_QUERIES,
        'results': all_results,
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")

    # CSV ìš”ì•½ ì €ì¥
    csv_file = output_dir / f"summary_{timestamp}.csv"
    with open(csv_file, 'w', encoding='utf-8-sig') as f:
        f.write("Profile,Description,Avg_Quality,Avg_Iterations,Avg_Docs,Avg_Time_Sec,Total_Cost_USD\n")

        for profile_name in PROFILES_TO_TEST:
            if profile_name not in all_results:
                continue
            data = all_results[profile_name]
            if 'error' in data['summary']:
                continue

            s = data['summary']
            desc = data['description'].replace(',', ';')  # CSV ì•ˆì „

            f.write(f"{profile_name},"
                   f"\"{desc}\","
                   f"{s['avg_quality']:.4f},"
                   f"{s['avg_iterations']:.2f},"
                   f"{s['avg_docs']:.2f},"
                   f"{s['avg_time_sec']:.2f},"
                   f"{s['total_cost_usd']:.6f}\n")

    print(f"   CSV ìš”ì•½: {csv_file}")

    print("\nì‹¤í—˜ ì™„ë£Œ! ğŸ‰")
    print(f"ì´ {len(all_results)}ê°œ í”„ë¡œíŒŒì¼ ë¹„êµ ì™„ë£Œ")


if __name__ == "__main__":
    main()