"""
Active Retrieval í†µí•© í…ŒìŠ¤íŠ¸

ì´ í…ŒìŠ¤íŠ¸ëŠ” Active Retrieval ì‹œìŠ¤í…œì˜ ë¬´ê²°ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def test_classify_intent_module():
    """classify_intent ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    try:
        from agent.nodes.classify_intent import classify_intent_node, IntentClassifier
        print("âœ“ classify_intent module imported successfully")
        return True
    except Exception as e:
        print(f"âœ— Failed to import classify_intent: {e}")
        return False


def test_intent_classifier_basic():
    """IntentClassifier ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸"""
    try:
        from agent.nodes.classify_intent import IntentClassifier

        feature_flags = {
            'active_retrieval_enabled': True,
            'simple_query_k': 3,
            'moderate_query_k': 8,
            'complex_query_k': 15
        }

        classifier = IntentClassifier(feature_flags)

        # Test 1: ì¸ì‚¬ ê°ì§€
        needs, k, complexity = classifier.classify("ì•ˆë…•í•˜ì„¸ìš”", {})
        assert not needs, "Greeting should not need retrieval"
        assert k == 0, "Greeting should have k=0"
        print("âœ“ Greeting detection works")

        # Test 2: ê°„ë‹¨í•œ ì§ˆë¬¸
        needs, k, complexity = classifier.classify(
            "ì •ìƒ í˜ˆì••ì€?",
            {'vitals': [{'name': 'í˜ˆì••'}]}
        )
        assert needs, "Medical question should need retrieval"
        assert k == 3, f"Simple query should have k=3, got {k}"
        assert complexity == "simple", f"Should be simple, got {complexity}"
        print("âœ“ Simple query classification works")

        # Test 3: ë³µì¡í•œ ì§ˆë¬¸
        needs, k, complexity = classifier.classify(
            "65ì„¸ ë‚¨ì„±, ë‹¹ë‡¨ë³‘, ê³ í˜ˆì•• í™˜ìì…ë‹ˆë‹¤. ë‘í†µ, ì–´ì§€ëŸ¬ì›€, ê°€ìŠ´ ë‹µë‹µí•¨ì´ ìˆìŠµë‹ˆë‹¤.",
            {
                'conditions': [{'name': 'ë‹¹ë‡¨ë³‘'}, {'name': 'ê³ í˜ˆì••'}],
                'symptoms': [{'name': 'ë‘í†µ'}, {'name': 'ì–´ì§€ëŸ¬ì›€'}, {'name': 'ê°€ìŠ´ ë‹µë‹µí•¨'}]
            }
        )
        assert needs, "Complex medical question should need retrieval"
        assert k == 15, f"Complex query should have k=15, got {k}"
        assert complexity == "complex", f"Should be complex, got {complexity}"
        print("âœ“ Complex query classification works")

        return True

    except AssertionError as e:
        print(f"âœ— Assertion failed: {e}")
        return False
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_metrics_collection():
    """ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    try:
        from agent.metrics.ablation_metrics import AblationMetrics, QueryMetrics

        # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° ìƒì„±
        metrics = AblationMetrics(experiment_name="test_experiment")

        # ê°€ì§œ ìƒíƒœ ìƒì„±
        fake_state = {
            'user_text': "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
            'needs_retrieval': True,
            'dynamic_k': 8,
            'query_complexity': "moderate",
            'classification_time_ms': 5.0,
            'retrieved_docs': [{'text': 'doc1'}, {'text': 'doc2'}],
            'answer': "í…ŒìŠ¤íŠ¸ ë‹µë³€ì…ë‹ˆë‹¤.",
            'quality_score': 0.8,
            'iteration_count': 0,
            'token_plan': {},
            'system_prompt': "System",
            'user_prompt': "User",
            'context_prompt': "Context"
        }

        # ì¿¼ë¦¬ ê¸°ë¡
        qm = metrics.record_query(fake_state, start_time=0.0, end_time=1.0)

        assert qm.query_text == "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸"
        assert qm.dynamic_k == 8
        assert qm.query_complexity == "moderate"
        print("âœ“ Metrics collection works")

        # í†µê³„ ê³„ì‚°
        stats = metrics.calculate_statistics()
        assert stats['total_queries'] == 1
        assert 'avg_latency_ms' in stats
        print("âœ“ Statistics calculation works")

        return True

    except AssertionError as e:
        print(f"âœ— Assertion failed: {e}")
        return False
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_state_fields():
    """AgentState í•„ë“œ ì¶”ê°€ í™•ì¸"""
    try:
        from agent.state import AgentState

        # TypedDictëŠ” ëŸ°íƒ€ì„ì— íƒ€ì… ì²´í¬ë¥¼ í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
        # __annotations__ë¡œ í•„ë“œ ì¡´ì¬ í™•ì¸
        annotations = AgentState.__annotations__

        required_fields = [
            'dynamic_k',
            'query_complexity',
            'classification_skipped',
            'classification_time_ms',
            'classification_error',
            'intent_classifier'
        ]

        for field in required_fields:
            assert field in annotations, f"Field {field} not found in AgentState"

        print("âœ“ AgentState has all required fields")
        return True

    except AssertionError as e:
        print(f"âœ— Assertion failed: {e}")
        return False
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        return False


def test_graph_integration():
    """ê·¸ë˜í”„ í†µí•© í…ŒìŠ¤íŠ¸"""
    try:
        from agent.graph import build_agent_graph

        # ê·¸ë˜í”„ ë¹Œë“œ
        app = build_agent_graph()

        # ë…¸ë“œ ì¡´ì¬ í™•ì¸
        assert 'classify_intent' in str(app.get_graph()), "classify_intent node not found"
        print("âœ“ Graph includes classify_intent node")

        return True

    except AssertionError as e:
        print(f"âœ— Assertion failed: {e}")
        return False
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_retrieve_dynamic_k():
    """retrieve_nodeì˜ dynamic_k ì§€ì› í…ŒìŠ¤íŠ¸"""
    try:
        # retrieve.py íŒŒì¼ ì½ê¸°
        retrieve_path = project_root / "agent" / "nodes" / "retrieve.py"
        with open(retrieve_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # dynamic_k ê´€ë ¨ ì½”ë“œ ì¡´ì¬ í™•ì¸
        assert "dynamic_k = state.get('dynamic_k')" in content, "dynamic_k retrieval not found"
        assert "if dynamic_k is not None" in content, "dynamic_k check not found"
        print("âœ“ retrieve_node supports dynamic_k")

        return True

    except AssertionError as e:
        print(f"âœ— Assertion failed: {e}")
        return False
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        return False


def test_feature_flags():
    """Feature flags ê¸°ë³¸ê°’ í…ŒìŠ¤íŠ¸"""
    try:
        from agent.graph import run_agent

        # Active Retrieval ë¹„í™œì„±í™” (ê¸°ë³¸ê°’)
        state_off = run_agent(
            user_text="ì•ˆë…•í•˜ì„¸ìš”",
            mode='ai_agent',
            return_state=True
        )

        # classification_skippedê°€ Trueì—¬ì•¼ í•¨ (ë¹„í™œì„±í™” ì‹œ)
        assert state_off.get('classification_skipped') is not False, \
            "Active Retrieval should be disabled by default"
        print("âœ“ Feature flag defaults are safe (disabled)")

        return True

    except AssertionError as e:
        print(f"âœ— Assertion failed: {e}")
        return False
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_end_to_end_with_active_retrieval():
    """End-to-end í…ŒìŠ¤íŠ¸ (Active Retrieval í™œì„±í™”)"""
    try:
        from agent.graph import run_agent

        # Test 1: ì¸ì‚¬ (ê²€ìƒ‰ ìŠ¤í‚µ)
        state1 = run_agent(
            user_text="ì•ˆë…•í•˜ì„¸ìš”",
            mode='ai_agent',
            feature_overrides={'active_retrieval_enabled': True},
            return_state=True
        )

        needs_retrieval1 = state1.get('needs_retrieval')
        assert needs_retrieval1 is False, f"Greeting should not need retrieval, got {needs_retrieval1}"
        print("âœ“ End-to-end: Greeting skips retrieval")

        # Test 2: ì˜ë£Œ ì§ˆë¬¸ (ê²€ìƒ‰ ì‹¤í–‰)
        state2 = run_agent(
            user_text="ì •ìƒ í˜ˆì•• ë²”ìœ„ëŠ”?",
            mode='ai_agent',
            feature_overrides={'active_retrieval_enabled': True},
            return_state=True
        )

        needs_retrieval2 = state2.get('needs_retrieval')
        dynamic_k2 = state2.get('dynamic_k')
        assert needs_retrieval2 is True, "Medical question should need retrieval"
        assert dynamic_k2 is not None, "dynamic_k should be set"
        print(f"âœ“ End-to-end: Medical question uses retrieval (k={dynamic_k2})")

        return True

    except AssertionError as e:
        print(f"âœ— Assertion failed: {e}")
        return False
    except Exception as e:
        print(f"âœ— Test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_error_handling():
    """ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    try:
        from agent.nodes.classify_intent import IntentClassifier

        feature_flags = {'active_retrieval_enabled': True}
        classifier = IntentClassifier(feature_flags)

        # None ì…ë ¥ ì‹œ ì—ëŸ¬ ì²˜ë¦¬
        try:
            needs, k, complexity = classifier.classify(None, {})
            # ì—ëŸ¬ê°€ ë°œìƒí•´ì•¼ í•˜ì§€ë§Œ, fallbackìœ¼ë¡œ ê¸°ë³¸ê°’ ë°˜í™˜
            assert k >= 0, "Should return non-negative k"
            print("âœ“ Error handling works (None input)")
        except Exception:
            # ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ê´œì°®ìŒ (ì—ëŸ¬ ì²˜ë¦¬ê°€ ìˆë‹¤ë©´)
            print("âœ“ Error handling works (exception caught)")

        return True

    except Exception as e:
        print(f"âœ— Test failed: {e}")
        return False


def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    tests = [
        ("Module Import", test_classify_intent_module),
        ("Intent Classifier Basic", test_intent_classifier_basic),
        ("Metrics Collection", test_metrics_collection),
        ("State Fields", test_state_fields),
        ("Graph Integration", test_graph_integration),
        ("Retrieve Dynamic K", test_retrieve_dynamic_k),
        ("Feature Flags", test_feature_flags),
        ("End-to-End Active Retrieval", test_end_to_end_with_active_retrieval),
        ("Error Handling", test_error_handling),
    ]

    print("\n" + "="*60)
    print("ACTIVE RETRIEVAL INTEGRATION TESTS")
    print("="*60 + "\n")

    results = []
    for name, test_func in tests:
        print(f"Running: {name}")
        try:
            success = test_func()
            results.append((name, success))
        except Exception as e:
            print(f"âœ— Test crashed: {e}")
            results.append((name, False))
        print()

    # ìš”ì•½
    print("="*60)
    print("TEST SUMMARY")
    print("="*60)

    passed = sum(1 for _, success in results if success)
    total = len(results)

    for name, success in results:
        status = "âœ“ PASS" if success else "âœ— FAIL"
        print(f"{status}: {name}")

    print(f"\nTotal: {passed}/{total} tests passed ({passed/total*100:.1f}%)")

    if passed == total:
        print("\nğŸ‰ All tests passed! Active Retrieval is ready.")
    else:
        print(f"\nâš ï¸  {total - passed} test(s) failed. Please review.")

    print("="*60 + "\n")

    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
