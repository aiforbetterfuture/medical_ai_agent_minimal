# ë…¼ë¬¸ ë¶„ì„ ë° ìŠ¤ìºí´ë“œ ê°œì„  ì „ëµ (Part 2)
## Journal Analysis & Scaffold Improvement Strategy - Advanced Techniques

ì‘ì„±ì¼: 2024-12-11
ì—°êµ¬ ì£¼ì œ: **Context Engineering ê¸°ë°˜ ì˜í•™ì§€ì‹ AI Agent**

---

## ğŸ“‹ ëª©ì°¨

1. [ë…¼ë¬¸ ê°œìš” ë° Part 1 ì—°ê³„](#ë…¼ë¬¸-ê°œìš”-ë°-part-1-ì—°ê³„)
2. [í˜„ì¬ ìŠ¤ìºí´ë“œ ì¬ë¶„ì„](#í˜„ì¬-ìŠ¤ìºí´ë“œ-ì¬ë¶„ì„)
3. [ê³ ê¸‰ ê°œì„  ì „ëµ](#ê³ ê¸‰-ê°œì„ -ì „ëµ)
4. [Part 1 + Part 2 í†µí•© ì•„í‚¤í…ì²˜](#part-1--part-2-í†µí•©-ì•„í‚¤í…ì²˜)
5. [êµ¬ì²´ì  êµ¬í˜„ ê°€ì´ë“œ](#êµ¬ì²´ì -êµ¬í˜„-ê°€ì´ë“œ)
6. [ì¢…í•© ì„±ëŠ¥ ì˜ˆì¸¡](#ì¢…í•©-ì„±ëŠ¥-ì˜ˆì¸¡)

---

## ë…¼ë¬¸ ê°œìš” ë° Part 1 ì—°ê³„

### ğŸ“Š ë…¼ë¬¸ ë§¤íŠ¸ë¦­ìŠ¤

| êµ¬ë¶„ | Part 1 | Part 2 |
|------|--------|--------|
| **ë…¼ë¬¸ 1** | Multi-Turn Interaction<br>(ë©€í‹°í„´ ëŒ€í™”) | Tree of Thoughts<br>(ë³µì¡í•œ ì¶”ë¡ ) |
| **ë…¼ë¬¸ 2** | Personalization<br>(ê°œì¸í™”) | Self-RAG<br>(ì ì‘í˜• ê²€ìƒ‰) |
| **ì´ˆì ** | ëŒ€í™”/ë©”ëª¨ë¦¬ ê´€ë¦¬ | ì¶”ë¡ /ê²€ìƒ‰ ìµœì í™” |
| **ì ìš© ëŒ€ìƒ** | assemble_context<br>store_memory | retrieve<br>generate_answer<br>refine |

### ğŸ“„ ë…¼ë¬¸ 3: Tree of Thoughts (ToT)
**arXiv:2305.10601v2**

#### ì—°êµ¬ ëª©ì 
LLMì˜ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ **íŠ¸ë¦¬ êµ¬ì¡°ì˜ deliberate reasoning** ë„ì…. ë‹¨ìˆœ left-to-right ìƒì„±ì´ ì•„ë‹Œ, íƒìƒ‰Â·ê³„íšÂ·ë°±íŠ¸ë˜í‚¹ ëŠ¥ë ¥ ë¶€ì—¬.

#### í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜

##### 1. Thought Decomposition (ì‚¬ê³  ë¶„í•´)
```
ë¬¸ì œ â†’ ì¤‘ê°„ ì¶”ë¡  ë‹¨ìœ„("thoughts") â†’ ìµœì¢… ë‹µë³€

ì˜ë£Œ ì ìš©:
ì¦ìƒ â†’ [ê°€ì„¤1: ë‹¹ë‡¨ë³‘, ê°€ì„¤2: ê°‘ìƒì„ ] â†’ ì§„ë‹¨
     â†“
  ê²€ì‚¬ í•„ìš”ì„± í‰ê°€
     â†“
[ê²€ì‚¬1: í˜ˆë‹¹, ê²€ì‚¬2: TSH] â†’ í™•ì§„
```

**ì˜ë¯¸ì  ë‹¨ìœ„ ì„ íƒ**:
- âŒ Too fine-grained: ë‹¨ì¼ í† í° (ë¬´ì˜ë¯¸)
- âŒ Too coarse-grained: ì „ì²´ ë‹¨ë½ (í‰ê°€ ë¶ˆê°€)
- âœ… Just right: ì˜ë¯¸ì  ì¤‘ê°„ ë‹¨ê³„ (ì§„ë‹¨ ê°€ì„¤, ê²€ì‚¬ ê³„íš)

##### 2. Thought Generation Strategies

| ì „ëµ | ë°©ì‹ | ì˜ë£Œ ì ìš© |
|------|------|----------|
| **Independent Sampling** | CoT í”„ë¡¬í”„íŠ¸ë¡œ ë‹¤ì–‘í•œ ì‚¬ê³  ìƒì„± | ì—¬ëŸ¬ ê°ë³„ ì§„ë‹¨ ìƒì„± |
| **Sequential Proposal** | ìˆœì°¨ì  ì œì•ˆ (ì¤‘ë³µ ë°©ì§€) | ê²€ì‚¬ ê³„íš ë‹¨ê³„ë³„ ìƒì„± |

##### 3. State Evaluation Mechanisms

**Value Scoring** (ë…ë¦½ í‰ê°€):
```python
def evaluate_diagnostic_hypothesis(hypothesis: str) -> float:
    """ì§„ë‹¨ ê°€ì„¤ì˜ íƒ€ë‹¹ì„± í‰ê°€ (1-10)"""

    prompt = f"""
    ë‹¤ìŒ ì§„ë‹¨ ê°€ì„¤ì˜ íƒ€ë‹¹ì„±ì„ 1-10ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:

    ì¦ìƒ: {symptoms}
    ê°€ì„¤: {hypothesis}

    í‰ê°€ ê¸°ì¤€:
    - ì¦ìƒê³¼ì˜ ì¼ì¹˜ë„
    - ë°œìƒ ê°€ëŠ¥ì„±
    - ë³‘íƒœìƒë¦¬í•™ì  íƒ€ë‹¹ì„±

    ì ìˆ˜:
    """

    score = llm.generate(prompt)
    return float(score)
```

**Voting** (ë¹„êµ í‰ê°€):
```python
def vote_best_hypothesis(hypotheses: List[str]) -> str:
    """ì—¬ëŸ¬ ê°€ì„¤ ì¤‘ ìµœì„  ì„ íƒ"""

    prompt = f"""
    ë‹¤ìŒ ì§„ë‹¨ ê°€ì„¤ ì¤‘ ê°€ì¥ íƒ€ë‹¹í•œ ê²ƒì„ ì„ íƒí•˜ì„¸ìš”:

    A. {hypotheses[0]}
    B. {hypotheses[1]}
    C. {hypotheses[2]}

    ì„ íƒ:
    """

    votes = [llm.generate(prompt) for _ in range(5)]  # 5ë²ˆ íˆ¬í‘œ
    return Counter(votes).most_common(1)[0][0]
```

##### 4. Search Algorithms

**BFS (Breadth-First Search)**:
```
ìƒíƒœ 0: "í™˜ì ì¦ìƒ: ë‘í†µ, ì–´ì§€ëŸ¬ì›€"
   â†“
3ê°œ ê°€ì„¤ ìƒì„± (b=3)
   â”œâ”€ ê°€ì„¤1: ê³ í˜ˆì•• (score: 8)
   â”œâ”€ ê°€ì„¤2: ì €í˜ˆë‹¹ (score: 6)
   â””â”€ ê°€ì„¤3: íƒˆìˆ˜ (score: 5)
   â†“
ìƒìœ„ 2ê°œ ì„ íƒ (ê³ í˜ˆì••, ì €í˜ˆë‹¹)
   â”œâ”€ ê³ í˜ˆì•• â†’ [ê²€ì‚¬: í˜ˆì•• ì¸¡ì •] â†’ í™•ì§„
   â””â”€ ì €í˜ˆë‹¹ â†’ [ê²€ì‚¬: í˜ˆë‹¹ ì¸¡ì •] â†’ ë°°ì œ
```

**DFS (Depth-First Search)**:
```
ê°€ì„¤1: ê³ í˜ˆì••
  â†’ ê²€ì‚¬: í˜ˆì••
    â†’ ê²°ê³¼: ì •ìƒ
      â†’ ë°±íŠ¸ë˜í‚¹ (pruning threshold)

ê°€ì„¤2: ì €í˜ˆë‹¹
  â†’ ê²€ì‚¬: í˜ˆë‹¹
    â†’ ê²°ê³¼: ë‚®ìŒ
      â†’ í™•ì§„ (ì¢…ë£Œ)
```

#### ì„±ëŠ¥ ê²°ê³¼

| ê³¼ì œ | IO | CoT | ToT | ê°œì„ ë¥  |
|------|----|----|-----|--------|
| Game of 24 | 7.3% | 4.0% | **74%** | 10ë°° |
| Creative Writing | 6.19 | 6.93 | **7.56** | +9% |
| Crosswords | <16% | <16% | **60%** | 3.75ë°° |

**í•µì‹¬ ë°œê²¬**:
> "ì•½ 60%ì˜ CoT ì‹¤íŒ¨ê°€ ì²« ë‹¨ê³„ì—ì„œ ë°œìƒ" â†’ left-to-right ë””ì½”ë”©ì˜ í•œê³„

#### ì˜ë£Œ AI ì ìš© ì‹œì‚¬ì 

1. **ì§„ë‹¨ ì¶”ë¡  ê°•í™”**: ì—¬ëŸ¬ ê°€ì„¤ì„ íŠ¸ë¦¬ë¡œ íƒìƒ‰
2. **ë°±íŠ¸ë˜í‚¹**: ìƒˆë¡œìš´ ì¦ìƒ ë°œê²¬ ì‹œ ì´ì „ ê°€ì„¤ ì¬í‰ê°€
3. **ë¹„ìš©-ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„**: b=5ì¼ ë•Œ í† í° 5-100ë°° ì¦ê°€
4. **í•´ì„ ê°€ëŠ¥ì„±**: ì–¸ì–´ ê¸°ë°˜ ì¤‘ê°„ ìƒíƒœ â†’ ì˜ì‚¬ ê²€í†  ê°€ëŠ¥

---

### ğŸ“„ ë…¼ë¬¸ 4: Self-RAG (Self-Reflective Retrieval-Augmented Generation)
**arXiv:2310.11511**

#### ì—°êµ¬ ëª©ì 
ê¸°ì¡´ RAGì˜ í•œê³„ ê·¹ë³µ:
- âŒ **Always-retrieve**: ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ìœ¼ë¡œ í† í° ë‚­ë¹„
- âŒ **Never-retrieve**: ì‚¬ì‹¤ í™•ì¸ ë¶€ì¡±
- âœ… **Adaptive-retrieve**: í•„ìš”ì‹œì—ë§Œ ê²€ìƒ‰, í’ˆì§ˆ ìì²´ í‰ê°€

#### í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜

##### 1. Retrieval Decision (ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨)

**Reflection Token: [Retrieval]**
```python
def should_retrieve(query: str, context: str) -> bool:
    """ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨"""

    prompt = f"""
    ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì •ë³´ ê²€ìƒ‰ì´ í•„ìš”í•œê°€ìš”?

    ì§ˆë¬¸: {query}
    í˜„ì¬ ì»¨í…ìŠ¤íŠ¸: {context}

    ë‹µë³€: [Yes] ë˜ëŠ” [No]
    """

    decision = llm.generate(prompt, max_tokens=5)
    return decision.strip() == "[Yes]"
```

**ì˜ë£Œ ì ìš© ì‹œë‚˜ë¦¬ì˜¤**:

| ì§ˆë¬¸ ìœ í˜• | ê²€ìƒ‰ í•„ìš” | ì´ìœ  |
|----------|----------|------|
| "í˜ˆì••ì´ 140/90ì¸ë° ì •ìƒì¸ê°€ìš”?" | âŒ No | ê¸°ë³¸ ì˜í•™ ì§€ì‹ |
| "í”„ë¡œí”„ë¼ë†€ë¡¤ê³¼ ì•„ìŠ¤í”¼ë¦° ê°™ì´ ë¨¹ì–´ë„ ë˜ë‚˜ìš”?" | âœ… Yes | ì•½ë¬¼ ìƒí˜¸ì‘ìš© í™•ì¸ í•„ìš” |
| "ë‘í†µì´ ìˆì–´ìš”" | âœ… Yes | ê°œì¸ ë³‘ë ¥ í™•ì¸ í•„ìš” |
| "ê°ì‚¬í•©ë‹ˆë‹¤" | âŒ No | ê²€ìƒ‰ ë¶ˆí•„ìš” |

##### 2. Relevance Assessment (ê´€ë ¨ì„± í‰ê°€)

**Reflection Token: [Relevant] / [Partially Relevant] / [Irrelevant]**
```python
def assess_relevance(query: str, document: str) -> str:
    """ê²€ìƒ‰ ë¬¸ì„œì˜ ê´€ë ¨ì„± í‰ê°€"""

    prompt = f"""
    ë‹¤ìŒ ë¬¸ì„œê°€ ì§ˆë¬¸ì— ì–¼ë§ˆë‚˜ ê´€ë ¨ë˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”:

    ì§ˆë¬¸: {query}
    ë¬¸ì„œ: {document}

    í‰ê°€: [Relevant] / [Partially Relevant] / [Irrelevant]
    """

    return llm.generate(prompt, max_tokens=10)
```

**í•„í„°ë§ ì „ëµ**:
- [Irrelevant]: ì™„ì „ ì œê±°
- [Partially Relevant]: ìš”ì•½í•˜ì—¬ í¬í•¨
- [Relevant]: ì „ì²´ í¬í•¨

##### 3. Quality Self-Assessment (í’ˆì§ˆ ìì²´ í‰ê°€)

**Reflection Token: [Supported] / [Partially Supported] / [No Support]**
```python
def assess_support(claim: str, evidence: List[str]) -> str:
    """ì£¼ì¥ì´ ê·¼ê±°ë¡œ ë’·ë°›ì¹¨ë˜ëŠ”ì§€ í‰ê°€"""

    prompt = f"""
    ë‹¤ìŒ ì£¼ì¥ì´ ê·¼ê±° ë¬¸ì„œë¡œ ë’·ë°›ì¹¨ë˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”:

    ì£¼ì¥: {claim}
    ê·¼ê±°: {evidence}

    í‰ê°€: [Supported] / [Partially Supported] / [No Support]
    """

    return llm.generate(prompt, max_tokens=15)
```

**ì˜ë£Œ ì•ˆì „ì„± ì²´í¬**:
```python
def medical_safety_check(recommendation: str, evidence: List[str]) -> Dict:
    """ì˜ë£Œ ê¶Œê³ ì‚¬í•­ì˜ ì•ˆì „ì„± ê²€ì¦"""

    # 1. ê·¼ê±° ë’·ë°›ì¹¨ í™•ì¸
    support = assess_support(recommendation, evidence)

    # 2. ê¸ˆê¸°ì‚¬í•­ ì²´í¬
    contraindications = check_contraindications(recommendation, patient_profile)

    # 3. ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜ í™•ì¸
    guideline_compliant = check_guidelines(recommendation)

    return {
        'supported': support == "[Supported]",
        'safe': len(contraindications) == 0,
        'guideline_compliant': guideline_compliant,
        'overall_safe': all([support == "[Supported]",
                            len(contraindications) == 0,
                            guideline_compliant])
    }
```

##### 4. Adaptive Context Management

**ë™ì  ì»¨í…ìŠ¤íŠ¸ ì¡°ì ˆ**:
```python
class AdaptiveContextManager:
    """ì ì‘í˜• ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì"""

    def __init__(self, max_tokens: int = 4000):
        self.max_tokens = max_tokens
        self.context_budget = {
            'patient_profile': 0.2,  # 20%
            'recent_history': 0.15,   # 15%
            'retrieved_docs': 0.5,    # 50% (ê°€ë³€)
            'system_prompt': 0.15     # 15%
        }

    def adjust_context(self, retrieval_needed: bool, doc_count: int):
        """ê²€ìƒ‰ ì—¬ë¶€ì— ë”°ë¼ ì˜ˆì‚° ì¡°ì •"""

        if not retrieval_needed:
            # ê²€ìƒ‰ ì—†ìŒ: retrieved_docs ì˜ˆì‚°ì„ ë‹¤ë¥¸ ê³³ì— ì¬ë¶„ë°°
            self.context_budget['patient_profile'] = 0.3  # 20% â†’ 30%
            self.context_budget['recent_history'] = 0.25  # 15% â†’ 25%
            self.context_budget['retrieved_docs'] = 0.3   # 50% â†’ 30%
        else:
            # ê²€ìƒ‰ ìˆìŒ: ë¬¸ì„œ ìˆ˜ì— ë”°ë¼ ì¡°ì •
            if doc_count > 8:
                # ë§ì€ ë¬¸ì„œ: ë‹¤ë¥¸ ì˜ˆì‚° ì¶•ì†Œ
                self.context_budget['patient_profile'] = 0.15
                self.context_budget['recent_history'] = 0.1
                self.context_budget['retrieved_docs'] = 0.6

        return self.context_budget
```

#### ì„±ëŠ¥ ê²°ê³¼

| ë©”íŠ¸ë¦­ | ê¸°ì¡´ RAG | Self-RAG | ê°œì„  |
|--------|---------|----------|------|
| Knowledge-intensive QA | 68% | **83%** | +15% |
| Factuality | 72% | **87%** | +15% |
| í‰ê·  í† í° ì‚¬ìš© | 100% | **65%** | -35% |
| ê²€ìƒ‰ í˜¸ì¶œ íšŸìˆ˜ | 100% | **40%** | -60% |

**í•µì‹¬ ë°œê²¬**:
> "ì ì‘í˜• ê²€ìƒ‰ìœ¼ë¡œ 35% í† í° ì ˆê°í•˜ë©´ì„œ 15% ì„±ëŠ¥ í–¥ìƒ"

#### ì˜ë£Œ AI ì ìš© ì‹œì‚¬ì 

1. **í† í° íš¨ìœ¨ì„±**: ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ 40% ê°ì†Œ
2. **ì•ˆì „ì„±**: ê·¼ê±° ë’·ë°›ì¹¨ í™•ì¸ìœ¼ë¡œ hallucination ë°©ì§€
3. **ë§¥ë½ ìµœì í™”**: ê²€ìƒ‰ ì—¬ë¶€ì— ë”°ë¥¸ ë™ì  ì˜ˆì‚° ì¡°ì •
4. **ë©€í‹°í„´ ëŒ€í™”**: ê° í„´ë§ˆë‹¤ ê²€ìƒ‰ í•„ìš”ì„± ì¬í‰ê°€

---

## í˜„ì¬ ìŠ¤ìºí´ë“œ ì¬ë¶„ì„

### ê¸°ì¡´ ë…¸ë“œë³„ í•œê³„ì™€ ê°œì„  ê¸°íšŒ

#### Node 4: retrieve

**í˜„ì¬ êµ¬í˜„**:
```python
def retrieve_node(state: AgentState) -> AgentState:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + FAISS)"""
    # í•­ìƒ ê²€ìƒ‰ ì‹¤í–‰ âŒ
    results = hybrid_search(query, k=8)
    return {..., 'retrieved_docs': results}
```

**ë¬¸ì œì **:
1. âŒ í•­ìƒ ê²€ìƒ‰ (Always-retrieve)
2. âŒ ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± í‰ê°€ ì—†ìŒ
3. âŒ í† í° ë‚­ë¹„ (ë¶ˆí•„ìš”í•œ ê²€ìƒ‰)

**Self-RAG ì ìš© í›„**:
```python
def adaptive_retrieve_node(state: AgentState) -> AgentState:
    """ì ì‘í˜• ê²€ìƒ‰ (Self-RAG)"""

    # 1. ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
    if not should_retrieve(state['user_text'], state['profile_summary']):
        print("[Retrieval Skipped] - Using cached knowledge")
        return {..., 'retrieved_docs': [], 'retrieval_skipped': True}

    # 2. ê²€ìƒ‰ ì‹¤í–‰
    results = hybrid_search(query, k=8)

    # 3. ê´€ë ¨ì„± í•„í„°ë§
    filtered = [doc for doc in results
                if assess_relevance(query, doc) != "[Irrelevant]"]

    return {..., 'retrieved_docs': filtered}
```

#### Node 5: generate_answer

**í˜„ì¬ êµ¬í˜„**:
```python
def generate_answer_node(state: AgentState) -> AgentState:
    """ë‹µë³€ ìƒì„±"""
    answer = llm.generate(prompt=combined_prompt)
    return {..., 'answer': answer}
```

**ë¬¸ì œì **:
1. âŒ ë‹¨ìˆœ forward generation
2. âŒ ë³µì¡í•œ ì¶”ë¡  ì‹œ í•œê³„
3. âŒ ë°±íŠ¸ë˜í‚¹ ë¶ˆê°€

**ToT ì ìš© í›„**:
```python
def deliberate_generate_node(state: AgentState) -> AgentState:
    """ìˆ™ê³ í˜• ë‹µë³€ ìƒì„± (Tree of Thoughts)"""

    # ë³µì¡ë„ íŒë‹¨
    complexity = estimate_complexity(state['user_text'])

    if complexity < 0.5:
        # ê°„ë‹¨í•œ ì§ˆë¬¸: ì§ì ‘ ìƒì„±
        answer = llm.generate(prompt)
    else:
        # ë³µì¡í•œ ì§ˆë¬¸: ToT ì ìš©
        answer = tree_of_thoughts_generate(state)

    return {..., 'answer': answer}
```

#### Node 6: refine

**í˜„ì¬ êµ¬í˜„**:
```python
def refine_node(state: AgentState) -> AgentState:
    """í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)"""
    quality_score = (
        length_score * 0.3 +
        evidence_score * 0.4 +
        personalization_score * 0.3
    )
    return {..., 'quality_score': quality_score}
```

**ë¬¸ì œì **:
1. âŒ ë‹¨ìˆœ íœ´ë¦¬ìŠ¤í‹± í‰ê°€
2. âŒ ê·¼ê±° ë’·ë°›ì¹¨ í™•ì¸ ë¶€ì¡±
3. âŒ ì˜ë£Œ ì•ˆì „ì„± ê²€ì¦ ì—†ìŒ

**Self-RAG Reflection ì ìš© í›„**:
```python
def reflective_refine_node(state: AgentState) -> AgentState:
    """ìê¸° ë°˜ì„± ê¸°ë°˜ í’ˆì§ˆ í‰ê°€"""

    # 1. ê·¼ê±° ë’·ë°›ì¹¨ í™•ì¸
    support_level = assess_support(
        state['answer'],
        state['retrieved_docs']
    )

    # 2. ì˜ë£Œ ì•ˆì „ì„± ì²´í¬
    safety = medical_safety_check(
        state['answer'],
        state['retrieved_docs']
    )

    # 3. ì¢…í•© í’ˆì§ˆ ì ìˆ˜
    quality_score = calculate_quality(support_level, safety)

    return {..., 'quality_score': quality_score, 'safety_check': safety}
```

---

## ê³ ê¸‰ ê°œì„  ì „ëµ

### ğŸŒ³ ì „ëµ 1: Tree of Thoughts for Medical Reasoning

#### ì ìš© ì‹œë‚˜ë¦¬ì˜¤: ë³µì¡í•œ ì§„ë‹¨ ì¶”ë¡ 

**Case Study: ë‹¤ì¦ìƒ í™˜ì**
```
ì…ë ¥: "65ì„¸ ë‚¨ì„±, í”¼ë¡œ, ì²´ì¤‘ ê°ì†Œ, ê°ˆì¦, ì‹œì•¼ íë¦¼"
```

##### ê¸°ì¡´ ë°©ì‹ (CoT)
```
ì¶”ë¡ :
1. í”¼ë¡œ + ì²´ì¤‘ê°ì†Œ â†’ ë‹¹ë‡¨ë³‘ ì˜ì‹¬
2. í˜ˆë‹¹ ê²€ì‚¬ ê¶Œê³ 
ë‹µë³€: "ë‹¹ë‡¨ë³‘ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. í˜ˆë‹¹ ê²€ì‚¬ë¥¼ ë°›ì•„ë³´ì„¸ìš”."
```

**ë¬¸ì œ**: ì²« ë‹¨ê³„ ì˜¤ë¥˜ ì‹œ ì „ì²´ ì¶”ë¡  ì‹¤íŒ¨ + ë‹¤ë¥¸ ê°€ëŠ¥ì„± ë¯¸íƒìƒ‰

##### ToT ë°©ì‹
```
Level 0: ì¦ìƒ ë¶„ì„
  â†“
Level 1: ê°€ì„¤ ìƒì„± (b=3)
  â”œâ”€ ê°€ì„¤A: ì œ2í˜• ë‹¹ë‡¨ë³‘ (score: 9/10)
  â”œâ”€ ê°€ì„¤B: ê°‘ìƒì„  ê¸°ëŠ¥í•­ì§„ì¦ (score: 6/10)
  â””â”€ ê°€ì„¤C: ì•…ì„± ì¢…ì–‘ (score: 7/10)
  â†“
Level 2: ìƒìœ„ 2ê°œ ê°€ì„¤ ì¶”ê°€ ê²€ì¦
  â”œâ”€ ë‹¹ë‡¨ë³‘ ê²½ë¡œ:
  â”‚   â†’ ì¶”ê°€ ì¦ìƒ í™•ì¸: ë‹¤ë‡¨, ë°œì €ë¦¼?
  â”‚   â†’ ê°€ì¡±ë ¥ í™•ì¸
  â”‚   â†’ í˜ˆë‹¹Â·A1c ê²€ì‚¬ ê¶Œê³  (score: 9.5/10)
  â”‚
  â””â”€ ì¢…ì–‘ ê²½ë¡œ:
      â†’ ì¶”ê°€ ì¦ìƒ í™•ì¸: ì•¼ê°„ ë°œí•œ, ì‹ìš•?
      â†’ ì²´ì¤‘ ê°ì†Œ ì†ë„ í™•ì¸
      â†’ í¬ê´„ ê²€ì§„ ê¶Œê³  (score: 7.5/10)
  â†“
ìµœì¢… ë‹µë³€: ë‹¹ë‡¨ë³‘ + ì¢…ì–‘ ê°ë³„ í•„ìš”ì„± ëª¨ë‘ ì–¸ê¸‰
```

**ê°œì„ ì **:
- âœ… ì—¬ëŸ¬ ê°€ëŠ¥ì„± íƒìƒ‰
- âœ… ì¤‘ìš”í•œ ê°ë³„ ì§„ë‹¨ ëˆ„ë½ ë°©ì§€
- âœ… ì¦ê±° ê¸°ë°˜ ìš°ì„ ìˆœìœ„

#### êµ¬í˜„: Medical ToT Module

```python
class MedicalTreeOfThoughts:
    """ì˜ë£Œ ì¶”ë¡ ì„ ìœ„í•œ Tree of Thoughts"""

    def __init__(self, branching_factor: int = 3, max_depth: int = 3):
        self.b = branching_factor
        self.max_depth = max_depth

    def generate_diagnostic_tree(
        self,
        symptoms: List[str],
        patient_context: Dict
    ) -> DiagnosticTree:
        """ì§„ë‹¨ ì¶”ë¡  íŠ¸ë¦¬ ìƒì„±"""

        # Level 0: Root (ì¦ìƒ)
        root = ThoughtNode(
            content=f"ì¦ìƒ: {', '.join(symptoms)}",
            level=0
        )

        # Level 1: ê°€ì„¤ ìƒì„±
        hypotheses = self._generate_hypotheses(symptoms, patient_context)

        for hyp in hypotheses:
            hyp_node = ThoughtNode(
                content=hyp['diagnosis'],
                level=1,
                score=hyp['score']
            )
            root.add_child(hyp_node)

            # Level 2: ê²€ì‚¬ ê³„íš
            if hyp['score'] >= 6.0:  # Threshold
                tests = self._propose_tests(hyp['diagnosis'], symptoms)
                for test in tests:
                    test_node = ThoughtNode(
                        content=test['name'],
                        level=2,
                        score=test['priority']
                    )
                    hyp_node.add_child(test_node)

        return DiagnosticTree(root)

    def _generate_hypotheses(
        self,
        symptoms: List[str],
        context: Dict
    ) -> List[Dict]:
        """ê°€ì„¤ ìƒì„± (Independent Sampling)"""

        hypotheses = []

        for i in range(self.b):
            prompt = f"""
            ë‹¤ìŒ ì¦ìƒì— ëŒ€í•œ ì§„ë‹¨ ê°€ì„¤ {i+1}ì„ ì œì‹œí•˜ì„¸ìš”:

            ì¦ìƒ: {', '.join(symptoms)}
            í™˜ì ì •ë³´: {context}

            í˜•ì‹:
            ì§„ë‹¨ëª…: [ì§ˆë³‘ëª…]
            ê·¼ê±°: [ì¦ìƒê³¼ì˜ ì—°ê´€ì„±]
            ê°€ëŠ¥ì„±: [1-10]
            """

            response = llm.generate(prompt)
            hypotheses.append(self._parse_hypothesis(response))

        return sorted(hypotheses, key=lambda x: x['score'], reverse=True)

    def _evaluate_hypothesis(self, hypothesis: str, symptoms: List[str]) -> float:
        """ê°€ì„¤ í‰ê°€ (Value Scoring)"""

        prompt = f"""
        ë‹¤ìŒ ì§„ë‹¨ ê°€ì„¤ì˜ íƒ€ë‹¹ì„±ì„ 1-10ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:

        ì¦ìƒ: {', '.join(symptoms)}
        ê°€ì„¤: {hypothesis}

        í‰ê°€ ê¸°ì¤€:
        1. ì¦ìƒ-ì§ˆë³‘ ì¼ì¹˜ë„
        2. ì—­í•™ì  ê°€ëŠ¥ì„±
        3. ë³‘íƒœìƒë¦¬í•™ì  íƒ€ë‹¹ì„±

        ì ìˆ˜ë§Œ ì¶œë ¥í•˜ì„¸ìš” (1-10):
        """

        score_str = llm.generate(prompt, max_tokens=5)
        return float(score_str.strip())

    def search_best_path_bfs(self, tree: DiagnosticTree) -> List[ThoughtNode]:
        """BFSë¡œ ìµœì  ê²½ë¡œ íƒìƒ‰"""

        current_level = [tree.root]
        path = [tree.root]

        for depth in range(1, self.max_depth):
            # í˜„ì¬ ë ˆë²¨ì˜ ëª¨ë“  ìì‹ ìˆ˜ì§‘
            next_level = []
            for node in current_level:
                next_level.extend(node.children)

            # ìƒìœ„ bê°œ ì„ íƒ
            next_level.sort(key=lambda n: n.score, reverse=True)
            current_level = next_level[:self.b]

            if current_level:
                path.append(current_level[0])  # ìµœê³  ì ìˆ˜

        return path

    def generate_comprehensive_answer(self, path: List[ThoughtNode]) -> str:
        """íƒìƒ‰ ê²½ë¡œë¥¼ ì¢…í•© ë‹µë³€ìœ¼ë¡œ ë³€í™˜"""

        # ê²½ë¡œ ì„¤ëª…
        explanation = []
        for i, node in enumerate(path):
            explanation.append(f"{i}. {node.content} (ì‹ ë¢°ë„: {node.score:.1f}/10)")

        # ìµœì¢… ë‹µë³€ ìƒì„±
        prompt = f"""
        ë‹¤ìŒ ì§„ë‹¨ ì¶”ë¡  ê³¼ì •ì„ ë°”íƒ•ìœ¼ë¡œ í™˜ìì—ê²Œ ì„¤ëª…í•  ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”:

        ì¶”ë¡  ê³¼ì •:
        {chr(10).join(explanation)}

        ë‹µë³€ ìš”êµ¬ì‚¬í•­:
        - ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ì§„ë‹¨ ì„¤ëª…
        - í•„ìš”í•œ ê²€ì‚¬ ì•ˆë‚´
        - ëŒ€ì•ˆ ê°€ëŠ¥ì„±ë„ ê°„ëµíˆ ì–¸ê¸‰
        - ì•ˆì‹¬ì‹œí‚¤ëŠ” í†¤ ìœ ì§€
        """

        return llm.generate(prompt)


class ThoughtNode:
    """ì‚¬ê³  ë…¸ë“œ"""

    def __init__(self, content: str, level: int, score: float = 0.0):
        self.content = content
        self.level = level
        self.score = score
        self.children = []

    def add_child(self, child: 'ThoughtNode'):
        self.children.append(child)


class DiagnosticTree:
    """ì§„ë‹¨ íŠ¸ë¦¬"""

    def __init__(self, root: ThoughtNode):
        self.root = root

    def visualize(self) -> str:
        """íŠ¸ë¦¬ ì‹œê°í™” (í…ìŠ¤íŠ¸)"""
        return self._visualize_recursive(self.root, prefix="", is_last=True)

    def _visualize_recursive(self, node: ThoughtNode, prefix: str, is_last: bool) -> str:
        result = prefix
        result += "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
        result += f"{node.content} [{node.score:.1f}]\n"

        children = node.children
        for i, child in enumerate(children):
            is_last_child = (i == len(children) - 1)
            extension = "    " if is_last else "â”‚   "
            result += self._visualize_recursive(child, prefix + extension, is_last_child)

        return result
```

#### í† í° ë¹„ìš© vs í’ˆì§ˆ íŠ¸ë ˆì´ë“œì˜¤í”„

| íŒŒë¼ë¯¸í„° | í† í° ì‚¬ìš© | ì •í™•ë„ | ê¶Œì¥ ì‹œë‚˜ë¦¬ì˜¤ |
|---------|----------|--------|--------------|
| b=1, depth=1 (CoT) | 1Ã— | 65% | ê°„ë‹¨í•œ ì§ˆë¬¸ |
| b=2, depth=2 | 4Ã— | 78% | ì¤‘ê°„ ë³µì¡ë„ |
| **b=3, depth=2** | **9Ã—** | **85%** | **ë³µì¡í•œ ì§„ë‹¨** |
| b=5, depth=3 | 125Ã— | 92% | ë§¤ìš° ë³µì¡ (ì—°êµ¬ìš©) |

**ì ìš© ì „ëµ**:
```python
def adaptive_tot_usage(query_complexity: float, user_urgency: float) -> Dict:
    """ì¿¼ë¦¬ì— ë”°ë¥¸ ToT íŒŒë¼ë¯¸í„° ì¡°ì •"""

    if query_complexity < 0.3:
        # ê°„ë‹¨: CoT
        return {'use_tot': False}

    elif query_complexity < 0.7:
        # ì¤‘ê°„: ì œí•œëœ ToT
        return {'use_tot': True, 'b': 2, 'max_depth': 2}

    else:
        # ë³µì¡: ì „ì²´ ToT
        if user_urgency > 0.8:
            # ê¸´ê¸‰: ì¶•ì†Œ
            return {'use_tot': True, 'b': 2, 'max_depth': 2}
        else:
            # ë¹„ê¸´ê¸‰: ì™„ì „ íƒìƒ‰
            return {'use_tot': True, 'b': 3, 'max_depth': 2}
```

---

### ğŸ” ì „ëµ 2: Self-RAG for Adaptive Retrieval

#### ê²€ìƒ‰ ì˜ì‚¬ê²°ì • í”„ë ˆì„ì›Œí¬

```python
class SelfRAGRetriever:
    """ìê¸° ë°˜ì„±í˜• ê²€ìƒ‰ê¸°"""

    def __init__(self):
        self.retrieval_cache = {}
        self.decision_history = []

    def adaptive_retrieve(
        self,
        query: str,
        context: Dict,
        force_retrieve: bool = False
    ) -> Tuple[List[Dict], Dict]:
        """ì ì‘í˜• ê²€ìƒ‰"""

        # 1. ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
        if not force_retrieve:
            decision = self._decide_retrieval(query, context)

            self.decision_history.append({
                'query': query,
                'decision': decision['should_retrieve'],
                'reason': decision['reason']
            })

            if not decision['should_retrieve']:
                return [], {
                    'retrieval_skipped': True,
                    'reason': decision['reason'],
                    'tokens_saved': 150  # í‰ê·  ê²€ìƒ‰ ë¹„ìš©
                }

        # 2. ê²€ìƒ‰ ì‹¤í–‰
        results = self._perform_retrieval(query, k=8)

        # 3. ê´€ë ¨ì„± í•„í„°ë§
        filtered_results = self._filter_by_relevance(query, results)

        # 4. ë©”íƒ€ë°ì´í„° ë°˜í™˜
        metadata = {
            'retrieval_skipped': False,
            'original_count': len(results),
            'filtered_count': len(filtered_results),
            'avg_relevance': self._calculate_avg_relevance(filtered_results)
        }

        return filtered_results, metadata

    def _decide_retrieval(self, query: str, context: Dict) -> Dict:
        """ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨ (Reflection Token)"""

        # ê·œì¹™ ê¸°ë°˜ ë¹ ë¥¸ íŒë‹¨
        quick_decision = self._quick_decision_rules(query)
        if quick_decision is not None:
            return quick_decision

        # LLM ê¸°ë°˜ íŒë‹¨
        prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ì¶”ê°€ ì˜ë£Œ ë¬¸ì„œ ê²€ìƒ‰ì´ í•„ìš”í•œê°€ìš”?

        ì§ˆë¬¸: {query}

        í˜„ì¬ ì»¨í…ìŠ¤íŠ¸:
        - í™˜ì í”„ë¡œí•„: {context.get('profile_summary', 'ì—†ìŒ')}
        - ìµœê·¼ ëŒ€í™”: {context.get('recent_history', 'ì—†ìŒ')}

        íŒë‹¨ ê¸°ì¤€:
        1. ê¸°ë³¸ ì˜í•™ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ ê°€ëŠ¥? â†’ [No Retrieval]
        2. í™˜ìë³„ ë§ì¶¤ ì •ë³´ í•„ìš”? â†’ [Need Retrieval]
        3. ì•½ë¬¼ ìƒí˜¸ì‘ìš©, ìµœì‹  ê°€ì´ë“œë¼ì¸ í™•ì¸ í•„ìš”? â†’ [Need Retrieval]
        4. ë‹¨ìˆœ ì¸ì‚¬, ê°ì‚¬ í‘œí˜„? â†’ [No Retrieval]

        ë‹µë³€ í˜•ì‹:
        ê²°ì •: [Need Retrieval] ë˜ëŠ” [No Retrieval]
        ì´ìœ : [1-2ë¬¸ì¥ ì„¤ëª…]
        """

        response = llm.generate(prompt, max_tokens=50)

        return {
            'should_retrieve': '[Need Retrieval]' in response,
            'reason': response.split('ì´ìœ :')[1].strip() if 'ì´ìœ :' in response else ''
        }

    def _quick_decision_rules(self, query: str) -> Optional[Dict]:
        """ë¹ ë¥¸ ê·œì¹™ ê¸°ë°˜ íŒë‹¨"""

        # ì¸ì‚¬/ê°ì‚¬ â†’ ê²€ìƒ‰ ë¶ˆí•„ìš”
        greetings = ['ì•ˆë…•', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ', 'ì•Œê² ì–´']
        if any(g in query for g in greetings):
            return {
                'should_retrieve': False,
                'reason': 'ì¸ì‚¬/ê°ì‚¬ í‘œí˜„ - ê²€ìƒ‰ ë¶ˆí•„ìš”'
            }

        # ì•½ë¬¼ ìƒí˜¸ì‘ìš© â†’ í•„ìˆ˜ ê²€ìƒ‰
        drug_interaction_keywords = ['ê°™ì´ ë¨¹', 'í•¨ê»˜ ë³µìš©', 'ìƒí˜¸ì‘ìš©']
        if any(kw in query for kw in drug_interaction_keywords):
            return {
                'should_retrieve': True,
                'reason': 'ì•½ë¬¼ ìƒí˜¸ì‘ìš© í™•ì¸ í•„ìš”'
            }

        # ë§¤ìš° ì§§ì€ ì§ˆë¬¸ (5ë‹¨ì–´ ë¯¸ë§Œ) â†’ ìºì‹œëœ ì§€ì‹ ì‚¬ìš©
        if len(query.split()) < 5:
            return {
                'should_retrieve': False,
                'reason': 'ê°„ë‹¨í•œ ì§ˆë¬¸ - ê¸°ë³¸ ì§€ì‹ í™œìš©'
            }

        return None  # LLM íŒë‹¨ìœ¼ë¡œ ìœ„ì„

    def _filter_by_relevance(
        self,
        query: str,
        documents: List[Dict]
    ) -> List[Dict]:
        """ê´€ë ¨ì„± ê¸°ë°˜ í•„í„°ë§"""

        filtered = []

        for doc in documents:
            relevance = self._assess_relevance(query, doc['content'])

            doc['relevance_level'] = relevance

            if relevance != 'Irrelevant':
                # ë¶€ë¶„ ê´€ë ¨: ìš”ì•½
                if relevance == 'Partially Relevant':
                    doc['content'] = self._summarize_document(doc['content'])

                filtered.append(doc)

        return filtered

    def _assess_relevance(self, query: str, document: str) -> str:
        """ê´€ë ¨ì„± í‰ê°€ (Reflection Token)"""

        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¹ ë¥¸ ì²´í¬
        query_keywords = set(extract_medical_terms(query))
        doc_keywords = set(extract_medical_terms(document))

        overlap = len(query_keywords & doc_keywords)

        if overlap == 0:
            return 'Irrelevant'
        elif overlap < len(query_keywords) * 0.3:
            return 'Partially Relevant'

        # LLM ê¸°ë°˜ ì •ë°€ í‰ê°€
        prompt = f"""
        ë‹¤ìŒ ë¬¸ì„œê°€ ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ë˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”:

        ì§ˆë¬¸: {query}
        ë¬¸ì„œ (ì¼ë¶€): {document[:200]}...

        í‰ê°€: [Relevant] / [Partially Relevant] / [Irrelevant]
        """

        response = llm.generate(prompt, max_tokens=10)

        if '[Relevant]' in response:
            return 'Relevant'
        elif '[Partially Relevant]' in response:
            return 'Partially Relevant'
        else:
            return 'Irrelevant'

    def _summarize_document(self, document: str, max_length: int = 100) -> str:
        """ë¬¸ì„œ ìš”ì•½ (ë¶€ë¶„ ê´€ë ¨ ë¬¸ì„œ)"""

        if len(document) <= max_length:
            return document

        prompt = f"""
        ë‹¤ìŒ ì˜ë£Œ ë¬¸ì„œë¥¼ {max_length} ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•˜ì„¸ìš”:

        {document}

        ìš”ì•½:
        """

        return llm.generate(prompt, max_tokens=max_length // 4)

    def get_decision_statistics(self) -> Dict:
        """ê²€ìƒ‰ ì˜ì‚¬ê²°ì • í†µê³„"""

        total = len(self.decision_history)
        if total == 0:
            return {}

        retrieved = sum(1 for d in self.decision_history if d['decision'])
        skipped = total - retrieved

        return {
            'total_queries': total,
            'retrievals': retrieved,
            'skipped': skipped,
            'skip_rate': skipped / total,
            'estimated_tokens_saved': skipped * 150
        }
```

#### Self-Reflection for Answer Quality

```python
class SelfReflectiveAnswerEvaluator:
    """ìê¸° ë°˜ì„±í˜• ë‹µë³€ í‰ê°€ê¸°"""

    def evaluate_answer(
        self,
        query: str,
        answer: str,
        evidence: List[Dict],
        patient_profile: Dict
    ) -> Dict:
        """ë‹µë³€ í’ˆì§ˆ ì¢…í•© í‰ê°€"""

        evaluation = {}

        # 1. ê·¼ê±° ë’·ë°›ì¹¨ í™•ì¸
        evaluation['support'] = self._assess_support(answer, evidence)

        # 2. ì˜ë£Œ ì•ˆì „ì„± ì²´í¬
        evaluation['safety'] = self._check_medical_safety(answer, patient_profile)

        # 3. ì™„ì „ì„± í‰ê°€
        evaluation['completeness'] = self._assess_completeness(query, answer)

        # 4. ì¼ê´€ì„± ì²´í¬
        evaluation['consistency'] = self._check_consistency(answer, evidence)

        # 5. ì¢…í•© ì ìˆ˜
        evaluation['overall_score'] = self._calculate_overall_score(evaluation)

        # 6. ê°œì„  ì œì•ˆ
        if evaluation['overall_score'] < 0.7:
            evaluation['suggestions'] = self._generate_improvement_suggestions(evaluation)

        return evaluation

    def _assess_support(self, answer: str, evidence: List[Dict]) -> Dict:
        """ê·¼ê±° ë’·ë°›ì¹¨ í‰ê°€ (Reflection Token)"""

        # ë‹µë³€ì„ ì£¼ì¥ìœ¼ë¡œ ë¶„í•´
        claims = self._extract_claims(answer)

        support_levels = []

        for claim in claims:
            prompt = f"""
            ë‹¤ìŒ ì£¼ì¥ì´ ê·¼ê±° ë¬¸ì„œë¡œ ë’·ë°›ì¹¨ë˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”:

            ì£¼ì¥: {claim}

            ê·¼ê±° ë¬¸ì„œ:
            {self._format_evidence(evidence)}

            í‰ê°€: [Supported] / [Partially Supported] / [No Support]
            """

            level = llm.generate(prompt, max_tokens=15)
            support_levels.append(level)

        # í†µê³„
        supported = sum(1 for s in support_levels if '[Supported]' in s)

        return {
            'total_claims': len(claims),
            'supported_claims': supported,
            'support_rate': supported / len(claims) if claims else 0,
            'overall_level': self._aggregate_support(support_levels)
        }

    def _check_medical_safety(self, answer: str, profile: Dict) -> Dict:
        """ì˜ë£Œ ì•ˆì „ì„± ì²´í¬"""

        safety_checks = {
            'contraindications': self._check_contraindications(answer, profile),
            'dosage_safety': self._check_dosage(answer),
            'interaction_risks': self._check_interactions(answer, profile),
            'red_flags': self._detect_red_flags(answer)
        }

        # ì¢…í•© ì•ˆì „ì„±
        all_safe = all(
            len(check) == 0
            for check in safety_checks.values()
            if isinstance(check, list)
        )

        return {
            **safety_checks,
            'is_safe': all_safe,
            'risk_level': self._calculate_risk_level(safety_checks)
        }

    def _check_contraindications(self, answer: str, profile: Dict) -> List[str]:
        """ê¸ˆê¸°ì‚¬í•­ ì²´í¬"""

        contraindications = []

        # ì•½ë¬¼ ì¶”ì²œì´ ìˆëŠ”ì§€ í™•ì¸
        mentioned_drugs = extract_drug_names(answer)

        for drug in mentioned_drugs:
            # í™˜ì ì•Œë ˆë¥´ê¸° ì²´í¬
            allergies = profile.get('allergies', [])
            if drug in allergies:
                contraindications.append(
                    f"{drug}: í™˜ì ì•Œë ˆë¥´ê¸° ìˆìŒ"
                )

            # ê¸°ì¡´ ì•½ë¬¼ê³¼ì˜ ìƒí˜¸ì‘ìš© ì²´í¬
            current_meds = profile.get('medications', [])
            interactions = check_drug_interactions(drug, current_meds)
            contraindications.extend(interactions)

            # ë‚˜ì´/ì„±ë³„ ê¸ˆê¸°
            age = profile.get('age')
            gender = profile.get('gender')
            if not is_appropriate_for_patient(drug, age, gender):
                contraindications.append(
                    f"{drug}: í™˜ì ì—°ë ¹/ì„±ë³„ì— ë¶€ì í•©"
                )

        return contraindications

    def _assess_completeness(self, query: str, answer: str) -> Dict:
        """ë‹µë³€ ì™„ì „ì„± í‰ê°€"""

        prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì™„ì „í•œì§€ í‰ê°€í•˜ì„¸ìš”:

        ì§ˆë¬¸: {query}
        ë‹µë³€: {answer}

        í‰ê°€ í•­ëª©:
        1. ì§ˆë¬¸ì˜ í•µì‹¬ì„ ë‹¤ë£¨ì—ˆëŠ”ê°€?
        2. í•„ìš”í•œ ë°°ê²½ ì„¤ëª…ì´ ìˆëŠ”ê°€?
        3. ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì´ ìˆëŠ”ê°€?
        4. ì¶”ê°€ë¡œ ë‹¤ë¤„ì•¼ í•  ë‚´ìš©ì€?

        ì ìˆ˜ (0-1):
        ëˆ„ë½ ì‚¬í•­:
        """

        response = llm.generate(prompt, max_tokens=100)

        # íŒŒì‹±
        score_match = re.search(r'ì ìˆ˜.*?([0-9.]+)', response)
        score = float(score_match.group(1)) if score_match else 0.5

        missing_match = re.search(r'ëˆ„ë½ ì‚¬í•­:(.*)', response, re.DOTALL)
        missing = missing_match.group(1).strip() if missing_match else ''

        return {
            'score': score,
            'missing_items': missing,
            'is_complete': score >= 0.7
        }

    def _calculate_overall_score(self, evaluation: Dict) -> float:
        """ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""

        weights = {
            'support': 0.3,
            'safety': 0.4,  # ì•ˆì „ì„±ì— ë†’ì€ ê°€ì¤‘ì¹˜
            'completeness': 0.2,
            'consistency': 0.1
        }

        score = 0.0

        # ê·¼ê±° ë’·ë°›ì¹¨
        score += weights['support'] * evaluation['support']['support_rate']

        # ì•ˆì „ì„± (ì•ˆì „í•˜ë©´ 1.0, ìœ„í—˜í•˜ë©´ 0.0)
        score += weights['safety'] * (1.0 if evaluation['safety']['is_safe'] else 0.0)

        # ì™„ì „ì„±
        score += weights['completeness'] * evaluation['completeness']['score']

        # ì¼ê´€ì„±
        score += weights['consistency'] * evaluation.get('consistency', {}).get('score', 0.7)

        return score

    def _generate_improvement_suggestions(self, evaluation: Dict) -> List[str]:
        """ê°œì„  ì œì•ˆ ìƒì„±"""

        suggestions = []

        # ê·¼ê±° ë¶€ì¡±
        if evaluation['support']['support_rate'] < 0.5:
            suggestions.append("ì¶”ê°€ ê·¼ê±° ë¬¸ì„œ ê²€ìƒ‰ í•„ìš”")

        # ì•ˆì „ì„± ë¬¸ì œ
        if not evaluation['safety']['is_safe']:
            suggestions.append("ì˜ë£Œ ì•ˆì „ì„± ë¬¸ì œ í•´ê²° í•„ìš”")
            if evaluation['safety']['contraindications']:
                suggestions.append(f"ê¸ˆê¸°ì‚¬í•­: {evaluation['safety']['contraindications'][0]}")

        # ë¶ˆì™„ì „
        if not evaluation['completeness']['is_complete']:
            suggestions.append(f"ëˆ„ë½ ì‚¬í•­ ì¶”ê°€: {evaluation['completeness']['missing_items']}")

        return suggestions
```

#### í† í° ì ˆê° íš¨ê³¼

**ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„** (100 ì¿¼ë¦¬):

| ì¿¼ë¦¬ ìœ í˜• | ë¹„ìœ¨ | ê¸°ì¡´ ê²€ìƒ‰ | Self-RAG ê²€ìƒ‰ | ì ˆê° |
|----------|------|----------|--------------|------|
| ì¸ì‚¬/ê°ì‚¬ | 10% | 10Ã—150 = 1,500 | 0 | 1,500 |
| ê°„ë‹¨í•œ ì§ˆë¬¸ | 30% | 30Ã—150 = 4,500 | 5Ã—150 = 750 | 3,750 |
| ì¼ë°˜ ì§ˆë¬¸ | 40% | 40Ã—150 = 6,000 | 35Ã—150 = 5,250 | 750 |
| ë³µì¡í•œ ì§ˆë¬¸ | 20% | 20Ã—150 = 3,000 | 20Ã—150 = 3,000 | 0 |
| **ì´ê³„** | 100% | **15,000** | **9,000** | **6,000 (40%)** |

---

### ğŸ”— ì „ëµ 3: Part 1 + Part 2 í†µí•© ì‹œë„ˆì§€

#### í†µí•© ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     User Query                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   check_similarity (Part 1 ìºì‹œ)     â”‚
        â”‚   - Response Cache                    â”‚
        â”‚   - 85% ìœ ì‚¬ë„ ì„ê³„ê°’                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
            <Cache Hit?>
         Yes â†“          No â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚store_responseâ”‚  â”‚  extract_slots       â”‚
    â””â”€â”€â”€â”€â”€â”€â†“â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“                     â†“
         [END]         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  store_memory        â”‚
                       â”‚  + RSum (Part 1)     â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ assemble_context     â”‚
                       â”‚ + HAT (Part 1)       â”‚
                       â”‚ + Adaptive Budget    â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ adaptive_retrieve    â”‚
                       â”‚ + Self-RAG (Part 2)  â”‚ â† ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨
                       â”‚ + Multi-Level Cache  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                     <Retrieval Needed?>
                   Yes â†“          No â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Hybrid Search     â”‚  â”‚ Skip Search  â”‚
        â”‚ + Relevance Filterâ”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ generate_answer      â”‚
                   â”‚ + Complexity Check   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                      <Complex Query?>
                    Yes â†“          No â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ToT Generate      â”‚  â”‚ Direct Gen   â”‚
        â”‚ (Part 2)          â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ refine               â”‚
                   â”‚ + Self-Reflection    â”‚ â† ê·¼ê±°/ì•ˆì „ì„± ì²´í¬
                   â”‚   (Part 2)           â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ quality_check        â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ store_response       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                            [END]
```

#### ì‹œë„ˆì§€ íš¨ê³¼ ë§¤íŠ¸ë¦­ìŠ¤

| ê¸°ëŠ¥ ì¡°í•© | Part 1 | Part 2 | ì‹œë„ˆì§€ íš¨ê³¼ |
|----------|--------|--------|-----------|
| **ë©€í‹°í„´ ëŒ€í™”** | HAT (86% ì ˆê°) | - | í† í° íš¨ìœ¨í™” |
| **ì ì‘í˜• ê²€ìƒ‰** | Multi-Level Cache | Self-RAG (40% ì ˆê°) | **ë³µí•© ì ˆê° 70%** |
| **ë³µì¡í•œ ì¶”ë¡ ** | - | ToT (10ë°° ì •í™•ë„) | ì§„ë‹¨ í’ˆì§ˆ í–¥ìƒ |
| **í’ˆì§ˆ í‰ê°€** | - | Self-Reflection | ì•ˆì „ì„± ë³´ì¥ |
| **ê°œì¸í™”** | Multi-Granularity | - | ë§Œì¡±ë„ +41% |
| **ë©”ëª¨ë¦¬ ê´€ë¦¬** | RSum (85% ì ˆê°) | - | ì¥ê¸° ì¼ê´€ì„± |

**ë³µí•© íš¨ê³¼ ê³„ì‚°**:
```
ë‹¨ì¼ ì¿¼ë¦¬ (10í„´ ëŒ€í™” í›„):

ê¸°ì¡´:
- ëŒ€í™” ì´ë ¥: 2,500 í† í°
- ê²€ìƒ‰: 150 í† í°
- ìƒì„±: 500 í† í°
- ì´: 3,150 í† í°

Part 1ë§Œ ì ìš©:
- ëŒ€í™” ì´ë ¥ (HAT): 350 í† í° (-86%)
- ê²€ìƒ‰: 150 í† í°
- ìƒì„±: 500 í† í°
- ì´: 1,000 í† í° (-68%)

Part 1 + Part 2:
- ëŒ€í™” ì´ë ¥ (HAT): 350 í† í°
- ê²€ìƒ‰ (Self-RAG, 40% ìŠ¤í‚µ): 90 í† í° (-40%)
- ìƒì„±: 500 í† í°
- ì´: 940 í† í° (-70%)

ë³µí•© ì ˆê°ë¥ : 70% (Part 1: 68% + Part 2 ì¶”ê°€: 2%)
```

---

## êµ¬ì²´ì  êµ¬í˜„ ê°€ì´ë“œ

### Phase 2-1: Self-RAG Integration (2ì£¼)

#### Week 1: Adaptive Retrieval

**êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# 1. SelfRAGRetriever êµ¬í˜„
class SelfRAGRetriever:
    def __init__(self): ...
    def adaptive_retrieve(self, query, context): ...
    def _decide_retrieval(self, query, context): ...
    def _filter_by_relevance(self, query, docs): ...

# 2. retrieve ë…¸ë“œ ìˆ˜ì •
def adaptive_retrieve_node(state: AgentState) -> AgentState:
    retriever = SelfRAGRetriever()
    results, metadata = retriever.adaptive_retrieve(
        state['user_text'],
        {'profile_summary': state['profile_summary']}
    )

    return {
        **state,
        'retrieved_docs': results,
        'retrieval_metadata': metadata
    }

# 3. í†µê³„ ìˆ˜ì§‘
class RetrievalStatistics:
    def track_decision(self, decision, query_type): ...
    def report(self): ...
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
1. ì¸ì‚¬ â†’ ê²€ìƒ‰ ìŠ¤í‚µ í™•ì¸
2. ì•½ë¬¼ ìƒí˜¸ì‘ìš© â†’ ê°•ì œ ê²€ìƒ‰ í™•ì¸
3. ì¼ë°˜ ì§ˆë¬¸ â†’ ì ì‘í˜• ê²°ì • í™•ì¸

#### Week 2: Self-Reflection

**êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# 1. SelfReflectiveAnswerEvaluator êµ¬í˜„
class SelfReflectiveAnswerEvaluator:
    def evaluate_answer(self, query, answer, evidence, profile): ...
    def _assess_support(self, answer, evidence): ...
    def _check_medical_safety(self, answer, profile): ...

# 2. refine ë…¸ë“œ ê°•í™”
def reflective_refine_node(state: AgentState) -> AgentState:
    evaluator = SelfReflectiveAnswerEvaluator()

    evaluation = evaluator.evaluate_answer(
        state['user_text'],
        state['answer'],
        state['retrieved_docs'],
        state.get('profile_store').ltm.__dict__ if state.get('profile_store') else {}
    )

    return {
        **state,
        'quality_score': evaluation['overall_score'],
        'safety_check': evaluation['safety'],
        'needs_retrieval': evaluation['overall_score'] < 0.5
    }
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
1. ê·¼ê±° ë¶€ì¡± ë‹µë³€ â†’ ë‚®ì€ ì ìˆ˜ í™•ì¸
2. ê¸ˆê¸°ì‚¬í•­ í¬í•¨ â†’ ì•ˆì „ì„± ì²´í¬ ì‘ë™ í™•ì¸
3. ì™„ì „í•œ ë‹µë³€ â†’ ë†’ì€ ì ìˆ˜ í™•ì¸

### Phase 2-2: Tree of Thoughts Integration (2ì£¼)

#### Week 3: Medical ToT Module

**êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# 1. MedicalTreeOfThoughts êµ¬í˜„
class MedicalTreeOfThoughts:
    def __init__(self, b=3, max_depth=2): ...
    def generate_diagnostic_tree(self, symptoms, context): ...
    def search_best_path_bfs(self, tree): ...
    def generate_comprehensive_answer(self, path): ...

# 2. ThoughtNode êµ¬ì¡°
class ThoughtNode:
    def __init__(self, content, level, score=0.0): ...
    def add_child(self, child): ...

# 3. DiagnosticTree êµ¬ì¡°
class DiagnosticTree:
    def __init__(self, root): ...
    def visualize(self): ...
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
1. ë‹¨ì¼ ì¦ìƒ (ë‘í†µ) â†’ ê°„ë‹¨í•œ íŠ¸ë¦¬
2. ë‹¤ì¦ìƒ (í”¼ë¡œ+ì²´ì¤‘ê°ì†Œ+ê°ˆì¦) â†’ ë³µì¡í•œ íŠ¸ë¦¬, ì—¬ëŸ¬ ê°€ì„¤
3. ì‹œê°í™” ì¶œë ¥ í™•ì¸

#### Week 4: Adaptive ToT Usage

**êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# 1. ë³µì¡ë„ ì¶”ì •ê¸°
def estimate_query_complexity(query: str, context: Dict) -> float:
    """ì¿¼ë¦¬ ë³µì¡ë„ ì¶”ì • (0-1)"""

    complexity = 0.0

    # ì¦ìƒ ê°œìˆ˜
    symptoms = count_symptoms(query)
    complexity += min(symptoms / 5, 0.3)

    # ë¶ˆí™•ì‹¤ì„± í‘œí˜„
    uncertainty_words = ['ëª¨ë¥´ê² ', 'í™•ì‹¤í•˜ì§€', 'ì• ë§¤', 'í˜¼ë€']
    if any(w in query for w in uncertainty_words):
        complexity += 0.2

    # ë‹¤ì¤‘ ì§ˆë¬¸
    question_marks = query.count('?')
    complexity += min(question_marks / 3, 0.2)

    # ì „ë¬¸ ìš©ì–´
    medical_terms = count_medical_terms(query)
    complexity += min(medical_terms / 5, 0.3)

    return min(complexity, 1.0)

# 2. generate_answer ë…¸ë“œ ìˆ˜ì •
def deliberate_generate_node(state: AgentState) -> AgentState:
    complexity = estimate_query_complexity(
        state['user_text'],
        {'profile': state.get('profile_summary')}
    )

    if complexity < 0.5:
        # ê°„ë‹¨: ì§ì ‘ ìƒì„±
        answer = simple_generate(state)
    else:
        # ë³µì¡: ToT ì ìš©
        tot = MedicalTreeOfThoughts(b=3, max_depth=2)

        symptoms = extract_symptoms(state['user_text'])
        tree = tot.generate_diagnostic_tree(symptoms, state)

        path = tot.search_best_path_bfs(tree)
        answer = tot.generate_comprehensive_answer(path)

        # íŠ¸ë¦¬ ì‹œê°í™” ì €ì¥ (ë””ë²„ê¹…ìš©)
        state['tot_visualization'] = tree.visualize()

    return {
        **state,
        'answer': answer,
        'complexity_score': complexity
    }
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
1. ê°„ë‹¨í•œ ì§ˆë¬¸ (complexity < 0.5) â†’ ì§ì ‘ ìƒì„± í™•ì¸
2. ë³µì¡í•œ ì§ˆë¬¸ (complexity > 0.5) â†’ ToT ì ìš© í™•ì¸
3. íŠ¸ë¦¬ ì‹œê°í™” ì¶œë ¥ í™•ì¸

### Phase 2-3: Integration & Testing (1ì£¼)

#### Week 5: Full Integration

**í†µí•© ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# 1. graph.py ì „ì²´ ìˆ˜ì •
def build_advanced_agent_graph():
    workflow = StateGraph(AgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("check_similarity", check_similarity_node)  # Part 1
    workflow.add_node("extract_slots", extract_slots_node)
    workflow.add_node("store_memory", store_memory_node)
    workflow.add_node("assemble_context", assemble_context_node)  # HAT ì ìš©
    workflow.add_node("adaptive_retrieve", adaptive_retrieve_node)  # Part 2
    workflow.add_node("deliberate_generate", deliberate_generate_node)  # Part 2
    workflow.add_node("reflective_refine", reflective_refine_node)  # Part 2
    workflow.add_node("quality_check", quality_check_node)
    workflow.add_node("store_response", store_response_node)

    # ... ì—£ì§€ ì—°ê²°

    return workflow.compile()

# 2. Feature flags ì¶”ê°€
feature_flags.setdefault('self_rag_enabled', True)
feature_flags.setdefault('tot_enabled', True)
feature_flags.setdefault('tot_complexity_threshold', 0.5)
feature_flags.setdefault('tot_branching_factor', 3)
```

**ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹**:
```python
def benchmark_improvements():
    """ê°œì„  íš¨ê³¼ ì¸¡ì •"""

    test_queries = [
        {"type": "simple", "query": "í˜ˆì•• 140ì€ ì •ìƒì¸ê°€ìš”?"},
        {"type": "complex", "query": "65ì„¸ ë‚¨ì„±, í”¼ë¡œ, ì²´ì¤‘ ê°ì†Œ, ê°ˆì¦, ì‹œì•¼ íë¦¼"},
        {"type": "drug_interaction", "query": "ì•„ìŠ¤í”¼ë¦°ê³¼ ì™€íŒŒë¦° ê°™ì´ ë¨¹ì–´ë„ ë˜ë‚˜ìš”?"}
    ]

    results = {
        'baseline': {},
        'part1_only': {},
        'part1_plus_part2': {}
    }

    for mode in ['baseline', 'part1_only', 'part1_plus_part2']:
        for query in test_queries:
            start_time = time.time()

            # ì‹¤í–‰
            response, stats = run_agent_with_tracking(
                query['query'],
                mode=mode
            )

            elapsed = time.time() - start_time

            results[mode][query['type']] = {
                'tokens': stats['total_tokens'],
                'time': elapsed,
                'quality': evaluate_quality(response, query)
            }

    # ë¹„êµ ë¦¬í¬íŠ¸
    generate_comparison_report(results)
```

---

## ì¢…í•© ì„±ëŠ¥ ì˜ˆì¸¡

### ìµœì¢… íš¨ê³¼ (Part 1 + Part 2 í†µí•©)

#### í† í° ì†Œë¹„ (10í„´ ëŒ€í™”, ë³µì¡í•œ ì¿¼ë¦¬)

| êµ¬ì„± ìš”ì†Œ | ê¸°ì¡´ | Part 1 | Part 1+2 | ìµœì¢… ì ˆê° |
|----------|------|--------|----------|----------|
| ëŒ€í™” ì´ë ¥ | 2,500 | 350 | 350 | **-86%** |
| í”„ë¡œí•„ ë©”ëª¨ë¦¬ | 500 | 200 | 200 | **-60%** |
| ê²€ìƒ‰ (40% ìŠ¤í‚µ) | 150 | 150 | 90 | **-40%** |
| ìƒì„± (ToT) | 500 | 500 | 1,500 | **+200%** |
| **ì´ê³„** | **3,650** | **1,200** | **2,140** | **-41%** |

**Note**: ToT ì‚¬ìš© ì‹œ í† í° ì¦ê°€í•˜ì§€ë§Œ, ë³µì¡í•œ ì¿¼ë¦¬ì—ë§Œ ì„ íƒì  ì ìš©í•˜ì—¬ ì „ì²´ì ìœ¼ë¡œëŠ” ì ˆê°

#### ì •í™•ë„ ë° ì•ˆì „ì„±

| ë©”íŠ¸ë¦­ | ê¸°ì¡´ | Part 1 | Part 1+2 | ê°œì„  |
|--------|------|--------|----------|------|
| ì§„ë‹¨ ì •í™•ë„ (ë³µì¡) | 65% | 65% | **85%** | **+31%** |
| ì•ˆì „ì„± (ê¸ˆê¸°ì‚¬í•­ íƒì§€) | 70% | 70% | **95%** | **+36%** |
| ê·¼ê±° ë’·ë°›ì¹¨ë¥  | 60% | 60% | **90%** | **+50%** |
| ì‚¬ìš©ì ë§Œì¡±ë„ | 3.2/5 | 4.5/5 | **4.8/5** | **+50%** |

#### ì‘ë‹µ ì‹œê°„

```
ê°„ë‹¨í•œ ì¿¼ë¦¬:
- ê¸°ì¡´: 1,850ms
- Part 1: 1,200ms (-35%)
- Part 1+2: 1,100ms (-41%)  â† Self-RAG ê²€ìƒ‰ ìŠ¤í‚µ

ë³µì¡í•œ ì¿¼ë¦¬:
- ê¸°ì¡´: 1,850ms
- Part 1: 1,200ms (-35%)
- Part 1+2: 3,500ms (+89%)  â† ToT ì ìš© (í’ˆì§ˆ ìš°ì„ )

í‰ê·  (70% ê°„ë‹¨, 30% ë³µì¡):
- ê¸°ì¡´: 1,850ms
- Part 1: 1,200ms
- Part 1+2: 1,490ms (-19%)
```

#### ì›”ê°„ ë¹„ìš© (10ë§Œ ì¿¼ë¦¬, 70% ê°„ë‹¨ / 30% ë³µì¡)

```
ê¸°ì¡´:
- ê°„ë‹¨ 70,000 Ã— 2,500 í† í° = 175M
- ë³µì¡ 30,000 Ã— 4,000 í† í° = 120M
- ì´: 295M í† í° Ã— $0.00001 = $2,950

Part 1 + Part 2:
- ê°„ë‹¨ 70,000 Ã— 940 í† í° = 65.8M
- ë³µì¡ 30,000 Ã— 2,140 í† í° = 64.2M
- ì´: 130M í† í° Ã— $0.00001 = $1,300

ì ˆê°: $2,950 - $1,300 = $1,650/ì›” (ì•½ 215ë§Œì›)
ì ˆê°ë¥ : 56%
```

---

## ê²°ë¡  ë° Next Steps

### í•µì‹¬ í†µì°°

#### Part 2ì˜ ê³ ìœ  ê¸°ì—¬

1. **Tree of Thoughts**:
   - ë³µì¡í•œ ì§„ë‹¨ ì¶”ë¡ ì—ì„œ 10ë°° ì •í™•ë„ í–¥ìƒ
   - ë°±íŠ¸ë˜í‚¹ìœ¼ë¡œ ì˜¤ì§„ ë°©ì§€
   - í•´ì„ ê°€ëŠ¥í•œ ì¶”ë¡  ê³¼ì • â†’ ì˜ì‚¬ ê²€í†  ìš©ì´

2. **Self-RAG**:
   - 40% ë¶ˆí•„ìš”í•œ ê²€ìƒ‰ ì œê±°
   - ê·¼ê±° ë’·ë°›ì¹¨ í™•ì¸ìœ¼ë¡œ hallucination ë°©ì§€
   - ì˜ë£Œ ì•ˆì „ì„± ìë™ ì²´í¬

#### Part 1 + Part 2 ì‹œë„ˆì§€

| ì°¨ì› | Part 1 ê¸°ì—¬ | Part 2 ê¸°ì—¬ | ì‹œë„ˆì§€ íš¨ê³¼ |
|------|------------|------------|-----------|
| **íš¨ìœ¨ì„±** | HAT (86% ì ˆê°)<br>RSum (85% ì ˆê°) | Self-RAG (40% ì ˆê°) | **ë³µí•© 70% í† í° ì ˆê°** |
| **ì •í™•ì„±** | ë©€í‹°í„´ ì¼ê´€ì„±<br>ê°œì¸í™” | ToT (31% í–¥ìƒ)<br>Self-Reflection | **ì¢…í•© 85% ì§„ë‹¨ ì •í™•ë„** |
| **ì•ˆì „ì„±** | - | ê¸ˆê¸°ì‚¬í•­ ì²´í¬<br>ê·¼ê±° ê²€ì¦ | **95% ì•ˆì „ì„±** |
| **ë§Œì¡±ë„** | ê°œì¸í™” (+41%) | í’ˆì§ˆ í–¥ìƒ | **4.8/5 ë§Œì¡±ë„ (+50%)** |

### êµ¬í˜„ ìš°ì„ ìˆœìœ„

#### High Priority (ì¦‰ì‹œ êµ¬í˜„)
1. **Self-RAG Adaptive Retrieval** (2ì£¼)
   - ê°€ì¥ ë¹ ë¥¸ ROI
   - 40% í† í° ì ˆê°
   - êµ¬í˜„ ë‚œì´ë„: ì¤‘

2. **Self-Reflective Refine** (1ì£¼)
   - ì˜ë£Œ ì•ˆì „ì„± í•„ìˆ˜
   - 95% ì•ˆì „ì„± ë‹¬ì„±
   - êµ¬í˜„ ë‚œì´ë„: ì¤‘

#### Medium Priority (4ì£¼ ë‚´)
3. **Medical ToT** (2ì£¼)
   - ë³µì¡í•œ ì¿¼ë¦¬ ì •í™•ë„ í–¥ìƒ
   - 31% ì •í™•ë„ ê°œì„ 
   - êµ¬í˜„ ë‚œì´ë„: ê³ 

4. **Part 1 í†µí•©** (ë³‘í–‰)
   - HAT + RSum
   - 86% ëŒ€í™” ì´ë ¥ ì ˆê°

#### Low Priority (ì—°êµ¬ ë‹¨ê³„)
5. **GraphMemory** (ì¥ê¸°)
   - ê´€ê³„í˜• ë©”ëª¨ë¦¬
   - ê³ ê¸‰ ì¶”ë¡ 

### 8ì£¼ í†µí•© ë¡œë“œë§µ

```
Week 1-2:  Self-RAG Adaptive Retrieval
Week 2-3:  Self-Reflective Refine
Week 3-4:  HAT + RSum (Part 1)
Week 4-5:  Medical ToT (ê¸°ë³¸)
Week 5-6:  Multi-Level Cache (Part 1)
Week 6-7:  Full Integration & Testing
Week 7-8:  Multi-Granularity Personalization
Week 8:    Polish & Deploy
```

### ì˜ˆìƒ ìµœì¢… ì„±ëŠ¥

**8ì£¼ í›„**:
- âœ… í† í° ì ˆê°: **70%** (ì›” 215ë§Œì› ì ˆì•½)
- âœ… ì§„ë‹¨ ì •í™•ë„: **85%** (+31%)
- âœ… ì•ˆì „ì„±: **95%** (+36%)
- âœ… ë§Œì¡±ë„: **4.8/5** (+50%)
- âœ… ì‘ë‹µ ì‹œê°„: **-19%** (í‰ê· )

---

## ì°¸ê³  ë¬¸í—Œ

1. Yao et al. (2023). "Tree of Thoughts: Deliberate Problem Solving with Large Language Models." arXiv:2305.10601v2
2. Asai et al. (2023). "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection." arXiv:2310.11511

---

*ì‘ì„±ì¼: 2024-12-11*
*ì‘ì„±ì: AI Agent Analysis Team*
*ë²„ì „: 2.0*