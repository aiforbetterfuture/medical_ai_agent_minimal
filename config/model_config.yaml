llm:
  provider: openai
  model: gpt-4o-mini
  temperature: 0.7
  max_tokens: 1200
  llm_fallback:
    provider: gemini
    model: gemini-2.0-flash-exp
    temperature: 0.6
    max_tokens: 1200

