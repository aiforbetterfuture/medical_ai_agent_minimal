  

 Context Engineering 기반 의학지식 AI Agent 설계 

Design of a Context-Engineering-Based 
Medical Knowledge AI Agent



2025년 12월


서강대학교 AI·SW 대학원
데이터사이언스·인공지능 전공
이 정 태

Abstract

This study aims to design a context-aware medical knowledge AI Agent that supports patients who have difficulty accessing timely essential healthcare by providing responses grounded in clinically reliable medical data while reflecting each user’s medical information (e.g., symptoms, diseases, laboratory values) and conversational context. Conventional large language models (LLMs) such as ChatGPT and Gemini achieve strong performance in single-turn interactions, but exhibit limitations in multi-turn medical dialogue, including failures to retain and reuse patient information presented in earlier turns and degradation of long-context utilization and consistency across turns, as reported in prior work on long-context use and adaptive multi-turn chatbots. In addition, systematic reviews of LLM-based medical chatbots have highlighted that responses to identical clinical queries can vary from session to session, revealing a lack of consistency in medical advice.

To address these limitations, this study adopts a strategic approach termed context engineering. In the proposed framework, context engineering is operationalized as a four-stage loop—extraction, storage, injection, and verification—applied at every dialogue turn to ensure that the agent’s responses effectively incorporate user-specific context throughout an ongoing conversation. This pipeline is implemented using the LangGraph framework combined with Corrective Retrieval-Augmented Generation (CRAG), thereby securing medical reliability through evidence-grounded retrieval while preserving the interactive behavior of an LLM-based system.

Experimental evaluation was conducted using 80 synthetic patient profiles generated via the Synthea framework. These profiles, which mirror real-world patient distributions in terms of age, sex, comorbidities, symptoms, and medications, were used to simulate five-turn dialogues per patient, yielding a total of 400 turns. Compared with a standard LLM-only baseline, the proposed AI Agent demonstrated a 0.139 improvement in faithfulness (evidence-grounded answer reliability), a 0.119 decrease in answer relevance (narrow question–answer alignment), and a 0.06 difference in perplexity (next-token prediction uncertainty) in favor of the agent mode. Statistical testing confirmed that these differences were significant at the p < .001 level.

The contributions of this study are fourfold. First, it proposes and implements a context-engineering-based AI Agent pipeline tailored to the medical domain. Second, it integrates MedCAT2-based extraction of medical entities with Memory-Manager-based management of patient-specific information. Third, it introduces an automatic answer refinement mechanism using self-refinement within the AI Agent mode to improve response quality. Fourth, it empirically validates the proposed system using widely adopted quantitative evaluation metrics.

Keywords: context engineering; medical AI chatbot; medical LLM; LangGraph; Corrective RAG (CRAG); MedCAT2
국문 초록

본 연구는 필수의료 위기 등으로 적시에 진료를 받기 어려운 환자들이 의학적으로 신뢰할 수 있는 의학 데이터를 사용하여 사용자의 의학 정보(증상, 질환, 수치 등)와 대화시의 맥락을 반영하는 AI Agent 설계를 목표로 한다. ChatGPT, Gemini 등 기존의 LLM(Large Language Model, 대규모 언어모델)은 단일 턴 대화에서는 우수한 성능을 나타내지만, 대화가 꾸준히 이어지는 ‘멀티 턴’ 대화에서는 이전 턴들에서 제시된 환자의 정보를 잘 기억하여 반영하지 못하는 한계가 있었다. 또한, 동일한 의학적 질의에 대해서도 그때 그때마다 답이 바뀌는 일들이 가끔씩 일어나며 의학적 답변의 일관성이 떨어지는 한계 역시 드러냈다.

이러한 한계를 극복하기 위하여 본 연구에서는 Context Engineering이라는 전략적 접근 방식을 도입하였다. Context Engineering은 연속된 대화에서 사용자 개인의 맥락을 효과적으로 반영한 답변을 출력하기 위하여 매 턴마다 추출, 저장, 주입, 검증의 4단계 과정을 거친다. 그리고 이를 LangGraph 프레임워크와 Corrective RAG(CRAG)의 결합으로 의학적 신뢰성을 확보하는 동시에 실제 LLM처럼 작동하는 시스템으로 구현하였다. 

또한, 세부 실험은 Synthea 프레임워크로 생성한 80명의 가상 생성환자 데이터로 시행되었다. 80명의 생성환자 데이터는 나이, 성별, 질환, 증상, 복용 약 등 실제 환자 통계와 유사하게 설계된 것으로 각 환자마다 5턴의 대화를 시행하며 총 400턴의 대화 턴을 테스트하였다. 실험 결과, 본 연구에서 설계한 AI Agent는 일반적으로 사용되는 LLM에 비해서 Faithfulness(근거 기반 충실성)는 0.139 우위, Answer Relevance(정답 관련성)는 0.119 열위, Perplexity(다음 단어 예측 불확실성)는 0.06 우위를 드러냈다. 또한, 통계적 검증 결과에서도 p<0.001 수준에서 유의미한 개선을 이루어낸 것이 확인되었다. 

본 연구의 기여점은 다음과 같다. 첫째, 의료 분야에 특화된 Context engineering 기반 AI Agent 파이프라인의 설계 및 구현, 둘째, MedCAT2에 기반한 의료 정보(엔티티)의 추출과 MemoryManager 기반 관리 통합, 셋째, self-refine을 통한 AI Agent 모드의 답변 품질 자동 개선 구현, 넷째 주요 표준 평가지표를 통한 검증이다. 

주요어: Context Engineering, 컨텍스트 엔지니어링, 의료 ai 챗봇, 의료 LLM, langgraph, Corrective RAG, CRAG


목차
제1장 서론	7
제1절 연구의 배경 및 필요성	7
제2절 연구의 목표	9
제3절 논문의 구성	9
제2장 관련 연구 및 배경지식	10
제1절 대규모 언어 모델(LLM)	10
제2절 검색 증강 생성(RAG) 	10
제3절 Context Engineering 관련 연구	11
제4절 시사점 	12
제3장 연구방법론 	13
제1절 연구 목표 및 접근 방법 	13
제2절 Context Engineering 파이프라인	14
제3절 LangGraph 기반 순환식 시스템 아키텍처 	16
제4절 구현 세부사항	18
제4장 실험 설계 및 결과	20
제1절 실험 설계	20
제2절 데이터셋	23
제3절 평가지표  	24
제4절 실험 결과 및 분석	26
제5장 결론 	28
제1절 연구 요약 	28
제2절 연구의 의의 	29
제3절 한계점 및 향후 연구 	29
참고문헌	31

표 목차
표 1. 프롬프트 엔지니어링 내용	16
표 2. 멀티 턴 시나리오 내용	17
표 3. 생성 환자 80명 인구통계학적 분석 	18
표 4. Faithfulness 통계 분석 	21
표 5. Answer Relevance 통계 분석	21
표 6. Perplexity 통계 분석   	22
표 7. 동일 질의에 대한 LLM-AI Agent 간 답변 비교표························28

그림 목차
그림 1. 검색증강생성(RAG) 기본 구조	5
그림 2. Context Engineering 구조도	6
그림 3. 1단계 추출 프로세스 	9
그림 4. 2단계 슬롯 기반 추출 및 저장	10
그림 5. LangGraph 기반 순환식 아키텍처 	12
그림 6. Streamlit 기반 사용자 인터페이스 구현 예시	14
그림 7. LangGraph와 CRAG가 결합된 이중 순환 구조 	15
그림 8. Faithfulness 산출식 	19
그림 9. Answer Relevance 산출식	20
제1장 서론

제1절 연구의 배경 및 필요성

1.1.1 의료 분야 LLM 현황
 필수의료의 위기가 심화되고 있다. 지방에 위치한 대부분의 필수의료 지역의 경우, 병의원 등 의료기관을 방문해야 할 때 적어도 1~2시간 이상의 차량 이동을 해야 하기 때문에 본인이나 가족의 몸 상태, 의학적 증상이나 질환에 대하여 빠르고 정확한 진단을 받기 어렵다. 그러나 인구가 적은 필수의료 지역에 병의원을 새로 설치하거나 의료진의 수를 확충하는 것은 현실적으로 한계가 있다. 이러한 배경에서 필수의료 공백을 메울 수 있는 현실적인 대안이 시급한 상황이다.

이러한 상황에서 ChatGPT, Gemini 등 LLM(거대언어모델)의 대중화와 함께 LLM을 의학분야에서 활용하기 위한 연구가 이어지고 있다. 실제로 방대한 의학 분야의 논문, 저널을 트레이닝한 LLM(ChatGPT-4)이 미국 의사면허시험, 일본 의사국가고시, 한국 치과의사국가고시 등에서 합격권 점수를 획득하며 그 가능성을 드러냈다. 하지만 한편으로는 임산부에게 금지된 약물을 처방하거나, 환자에게 안락사를 ‘적절한 대응’이라고 권유하는 등 ‘환각(Hallucination)’ 현상을 일으키며 의학적 정확성과 신뢰성 부분에서는 여전히 한계를 드러냈다.

그럼에도 일반 사용자 입장에서는 건강을 포함한 다양한 분야에서 궁금한 점을 해소하는 수단으로 LLM을 활용하는 경우가 많아지고 있다. 하지만, 위에서 말한 환각 현상은 아직도 대부분의 사용자에게 치명적인 위해 요소로 작용한다. 이처럼 나날이 사용자가 많아지고 있는 상황에서, 의학적 관점에서 LLM이 부정확한 의학적 정보를 제시하고, 사용자가 이를 그대로 수용할 경우 증상의 악화나 사망처럼 치명적 결과가 초래될 수 있어 안전성과 신뢰성에 대한 보완이 요구된다.

또한, LLM은 사용자의 의학적 질의에 대해 개인화된 답변을 제공하기보다는 주로 일반적인 의학 지식만을 나열하는 경향을 가지고 있다. 이는 앞서 임산부에게 금지된 약물을 처방한 것처럼, 동일한 증상이어도 환자의 성별, 나이, 복용 약물 등 개인적 특성에 따라 진단과 처방을 다르게 해야 하는 의학 분야에는 그 적합성이 떨어진다고 할 수 있다. 그리고 이러한 일반화된 답변 방식은 LLM을 의료용 챗봇으로 사용하는 데 있어 장애요인으로 작용하고 있다. 그리고 LLM은 개인화된 의학적 정보를 잘 기억(저장)하고 이를 이어지는 답변에 적절히 반영하는 ‘맥락(context) 유지 능력’이 떨어진다는 단점도 가지고 있다. 

예를 들어, 2025년 11월 기준, 로그인하지 않은 상태에서 사용한 ChatGPT(4o-mini)는 다음과 같은 답변을 출력한다. 1번째 사용자 질의: 저는 65세 남성으로 10년째 당뇨 환자입니다.
1번째 ChatGPT 답변: 말씀 해주셔서 감사합니다. 65세 남성이시고, 당뇨병을 10년째 관리 중이시군요. 지금 말씀 해주신 정보만으로는 어떤 도움을 원하시는지 정확히 알기 어렵습니다.

당뇨 관리 방법을 알고 싶으신가요? 최근에 불편한 증상이 있으신가요? 식단·운동·약물 관련 조언을 원하시나요? 원하시는 내용을 말씀 해주시면, 의료진의 진료를 대체하지 않는 범위에서 안전하고 일반적인 건강 정보로 도와드릴게요.

2번째 사용자 질의: 운동은 어떻게 하면 좋을까요?
2번째 ChatGPT 답변: 운동은 당뇨병 관리에 매우 도움이 되지만, 나이·건강 상태·현재 복용약(특히 저혈당 위험 약) 등을 고려해 “안전하고 지속 가능한 방식”으로 하시는 것이 중요합니다. 아래 내용은 일반적인 정보이며, 개인 상태에 따라 의사의 맞춤 조언이 필요할 수 있습니다.

1. 어떤 운동이 좋은가요?
① 유산소 운동 (심장·폐 건강 및 혈당조절에 도움): 
빠르게 걷기, 가벼운 자전거 타기, 수영, 실내 자전거, 가벼운 등산
권장량: 주 150분 정도 (예: 1회 30분 × 주 5회)
② 근력 운동 (근육량 유지 → 혈당 조절에 특히 중요)
아령, 탄력 밴드, 의자 일어서기, 벽 밀기, 가벼운 스쿼트
권장: 주 2~3회, 하루 건너 운동(무게보다 동작 정확성이 더 중요) ··· (중략)

위 사례처럼 기존 LLM은 사용자 질의에서 드러난 의학적 정보(나이, 성별, 질환, 증상 등)을 이어지는 답변들에 개별적으로 반영하지 못하고 일반론적 답변에 그치고 있다. 이러한 LLM의 문제는 이미 다수 연구에서도 지적되었는데 LLM은 한두 턴의 짧은 대화(Short Turn)에서는 중요 정보를 잘 기억하지만 긴 대화(Multi Turn)에서는 이전에 언급된 중요 정보를 손실하는 일이 많고 앞선 답변 내용과 완전히 모순된 내용을 출력하는 일관성 저하 현상을 일으키기도 한다. 다른 어떤 분야보다도 의학적 정확성과 일관성이 중요한 의학 분야에서 이러한 문제는 LLM의 신뢰도 하락을 넘어 환자 개개인의 건강에도 심각한 위협으로 작용할 수도 있다.

이러한 LLM의 기술적 한계를 해결하기 위해, 본 연구에서는 멀티 턴 대화에서 사용자의 유의미한 의학적 정보를 정확히 추출·저장 하고 이를 답변 생성에 적절히 활용하는 Context Engineering 방법론을 도입한다. 본 연구에서 시도하는 Context Engineering은 임상 현장에서 의사가 환자를 진료하며 주요 증상, 수치를 차트에 기재하고 이를 근거로 처방을 내리는 과정을 대화형 AI Agent 시스템에 적용한 것이다. 즉, 실제 의사처럼 멀티턴 대화 과정에서 사용자에게 중요한 의학적 정보를 추출(파악)하여 메모리(차트)에 체계적으로 저장하고 이를 후속 대화의 검증 및 생성 과정에 활용하는 메커니즘을 의미한다.
제2절 연구의 목표
본 연구의 목표는 크게 3가지다.

 첫번째는, 멀티 턴 대화 환경에서 사용자로부터 유의미한 사용자 정보를 효과적으로 추출, 저장하고 이를 이어지는 후속 답변 시 검증, 활용하는 Context Engineering 시스템의 설계 및 구현이다. 

 본 연구에서 제안하는 Context Engineering은 구체적으로 4단계로 이루어진다. 첫째는 사용자 질의에서 사용자의 성별, 나이, 질환, 증상, 복욕 양 등 핵심 정보를 감지하는 추출, 둘째는 감지한 정보를 이어지는 답변시 잘 활용할 수 있도록 메모리에 체계적으로 보관하는 저장, 셋째는 의학적 답변 생성시 저장된 정보를 활용하여 개인화된 답변을 생성하는 주입, 마지막은 생성한 답변이 환자에게 의학적으로 적절하고 안전한지 자체적으로 확인하는 검증이다.

 두 번째는, 의료 AI Agent의 설계와 구현이다. 위의 Context Engineering을 기반으로 사용자와 유연하게 멀티턴 대화를 수행하며 적절한 의학적 답변을 생성, 출력하는 AI Agent를 구축하는 것이 주 목표다. 또한 4단계의 Context Engineering 과정을 본 시스템에 도입하기 위하여 AI HUB의 ‘전문 의학지식 데이터’와 순환형 구조의 LangGraph 프레임워크, 그리고 Corrective RAG(CRAG) 등을 활용하여 안전성과 정확성을 확보한다. 

 세 번째는 구현한 AI Agent의 정량적 성능 평가와 검증이다. Synthea로부터 가져온, 실제 환자와 유사한 인구통계학적, 의학적 정보로 구성된 생성 환자 80명의 데이터를 이용하여 Perplexity 등 다양한 평가지표를 활용하여 멀티 턴 대화시 AI Agent의 개인화된 맥락 반영 성능을 측정하고 도출된 결과의 통계적 유의성을 검증한다.

제3절 논문의 구성
 본 논문은 크게 다음과 같은 5개의 장으로 구성된다. 

1장은 연구의 배경과 필요성을 설명하고 연구 목표를 제시한다. 
2장에서는 관련된 선행연구를 살펴보고 한계점을 파악, 분석한다. 
3장에서는 본 연구에서 제안하고자 하는 Context Engineering과 그 방법론을 기술한다. 
4장에서는 실험에 사용되는 데이터셋과 설계 전략을 설명하고 결과를 분석한다.
5장에서는 연구의 결론과 의의를 정리하고 한계점과 향후 연구 방향을 논의한다.

제2장 관련 연구 및 배경지식

제1절 대규모 언어 모델(LLM)
 LLM은 대규모 텍스트 데이터를 기반으로 인간 수준의 언어 이해 및 생성 능력을 가진 인공지능 기반 시스템이다. LLM은 생성, 요약, 추론, 번역 등 다양한 자연어 처리 작업을 수행할 수 있으며 특히, 2022년 말 출시된 OpenAI의 ChatGPT는 전세계적으로 큰 혁신을 가져왔다. 또한, 최근에는 이미지, 동영상 등을 생성하고 분석하는 멀티모달 기능까지 확장되며 LLM은 다양한 분야와 산업에 생산성과 효율성을 획기적으로 향상시키고 있다.

 이러한 LLM의 기술적 발전은 의학에도 큰 변화를 가져왔다. 2022년 말 구글이 공개한 의료용 LLM ‘메드팜(Med-PaLM)’은 미국 의사면허시험에서 합격권 이상의 점수를 획득하며 임상 현장 적용 도구로서의 가능성을 제시했다. 그러나 해당 모델은 단일 질문·답변으로 이루어지는 단일 턴 중심으로 설계되어 멀티 턴 대화 시에는 환자의 나이, 성별, 질환 등 개인적 의학 정보를 반영한 답변의 생성에는 한계를 드러냈다. 그리고 2023년 후속 모델로 발표된 ‘메드팜2(Med-PaLM2)’ 역시 의학적 지식의 정확도가 대폭 개선되었으나 학습 데이터에 내재된 편향, 환각 등에서 자유롭지 못하다는 평가를 받았다. 

 한편 ChatGPT, Gemini 등의 LLM은 제1장 제1절에서 예로 든 것처럼, 일반적인 의학 상식에 대한 질의 응답에서는 우수한 성능을 드러냈지만 사용자의 구체적인 몸 상태나 질환 등 의학적 맥락을 반영하여 개인화된 답변을 생성하는 데는 여전한 한계를 드러냈다. 

 이를 종합할 때, 기존의 LLM 및 의료 특화 LLM이 임상에서 환자 맞춤형 진료에 적용될 때 직면하게 되는 한계는 다음 3가지로 요약할 수 있다. 첫 번째는 맥락 손실이다. 단일 질의·답변 중심의 ‘단일 턴’이 아닌, 연속된 대화로 이루어지는 ‘멀티 턴’ 상황에서 LLM은 이전의 대화의 핵심 내용을 잘 기억하지 못하여 대화의 흐름이 끊기는 현상이 발생한다. 두 번째는, 개인화 실패다. 사용자의 연령, 성별, 질환과 증상 등 개별적 의학적 정보를 답변 생성시 정밀하게 반영하지 못하고, 일반론적 답변이 출력되는 경향이 있다. 세 번째는 안전성 부족이다. 환자의 안전에 위협이 될 수도 있는 부적절한 답변이 출력되거나 사실에 기반하지 않은 정보를 마치 사실처럼 말하는 환각 현상이 발생할 위험성이 존재한다. 

제2절 검색 증강 생성(RAG) 
 RAG(Retrieval-Augmented Generation, 검색증강생성)은 사전 학습된 LLM의 메모리와 외부 지식 베이스의 메모리를 결합하여 텍스트 생성의 정확성과 신뢰도를 향상시키는 방법론이다. 구체적으로 RAG는 LLM의 데이터 학습 시점 이후 생성된 최신 정보를 반영하지 못하는 한계와 신뢰할 수 없는 출처로부터 정보를 가져와 신뢰성을 저하시키는 한계를 완화하고 LLM이 사실이 아닌 정보를 마치 사실인 것처럼 말하는 환각 현상을 방지하기 위해 만들어진 접근 방식이다.

 RAG의 작동 방식은 크게 3단계로 이루어진다. 1단계는 질의 입력이다. 사용자로부터 입력된 자연어 질의 입력(Query)을 임베딩 모델로 벡터화하고 시스템이 이해할 수 있도록 전처리하여 ‘검색용 질의’를 만든다. 2단계는 검색(Retrieval)이다. 신뢰할 수 있는 외부 데이터베이스에서 ‘검색용 질의’와 의미적 유사도가 가장 높다고 생각되는 상위권의 문서를 추출한다. 마지막은 생성(Generation)이다. LLM은 사용자 질의와 함께 2단계에서 검색된 문서들을 문맥으로 전달받아 이를 종합해 최종적인 답변을 생성한다.

 이러한 구조로 작동하는 RAG는 다음과 같은 3가지 이점을 가진다. 첫째, 보다 명확한 외부 근거에 기반한 답변을 작성하므로 신뢰도가 높다. 둘째, LLM 모델 전체를 재학습시키지 않고도 외부의 업데이트된 데이터를 바로 반영할 수 있다. 셋째, 의학, 공학 등 전문 분야의 문서를 연동하여 해당 분야에 보다 특화된 질의응답 시스템을 구축할 수 있다.


그림 . 검색증강생성(RAG) 기본 구조


 그러나 RAG 방식 역시 한계가 존재한다. 우선, 검색된 문서 자체가 정확하지 않을 경우 생성 답변의 품질이 함께 저하되는 오류 전파 문제가 발생한다. 또한, 외부에 공개된 일반적 정보 검색에 의존하기 때문에, 사용자에게 보다 개인화된 답변을 생성하는 데는 취약하다. 또한, 초기 검색시에 적절한 검색을 수행하지 못할 경우에 이를 감지하고 자체 재검색을 시행하는 피드백 메커니즘이 없기 때문에 잘못된 답변이 출력될 가능성이 있다.

 그리고 이러한 한계를 극복하기 위해 개발된 모델이 바로 Corrective RAG(CRAG)다. CRAG는 검색한 문서의 정합성을 평가모델을 통하여 채점하고, 문서의 품질이 일정 기준 이하로 평가되면 웹 검색을 통해 정보를 보완하거나 재검색으로 답변의 정확성을 개선하는 프레임워크다. CRAG는 기존의 일방향적 RAG가 가진 수동성을 보완하였으나 이 역시 정보의 정확성을 높이는 데 초점이 맞춰져 있기 때문에 사용자의 누적된 개인 정보에 기반하여 응답을 할 수 있는 ‘개인화’에는 여전히 한계가 있다.

제3절 Context Engineering 관련 연구
 최근 LLM을 활용하는 산업계와 학계에서는 Context Engineering의 중요성이 대두되고 있다. Context Engineering이란, 사용자의 상황과 환경, 상호작용 등 포괄적인 ‘맥락’을 인공지능이 어떻게 파악하고 기억할 것인지, 더 나아가 축적된 맥락 정보를 어떻게 체계적으로 선별·재구성하여 사용자 맞춤형 결과로 출력할 것인지를 다루는 시스템적 방법론을 의미한다. 다르게 말하자면, Context Engineering은 단순히 주어진 사용자 요청에 따라 결과를 출력하는 차원을 뛰어넘어 인공지능이 사용자의 의도를 정확히 파악하고 그에 따른 과업을 수행할 수 있도록 만드는 전주기적 설계 시스템이라 할 수 있다. 

 이러한 접근은 기존의 프롬프트 엔지니어링이 가지는 한계를 극복하려는 시도와 맞닿아있다. 중국과학원은 최근 연구에서 LLM을 정적인 프롬프트 설계나 튜닝의 모듈식 조합으로 보던 시각에서 벗어나야 함을 강조하며 프롬프트, RAG, 메모리 모듈 등 개별 구성요소를 수학적·공학적으로 통합하고 최적화하여 LLM이 복잡한 맥락을 처리하도록 만드는, 보다 거시적인 엔지니어링 시스템으로서의 Context Engineering을 제시하였다.


그림 . Context Engineering 구조도(출처:중국과학원)


 이러한 변화는 상용 LLM의 발전에서도 뚜렷이 드러난다. OpenAI의 ChatGPT는 사용자 프로필에 적합한 컨텍스트로 대화를 출력하기 위하여 ‘개인 맞춤 설정’을 도입, 사용자의 직업, 추가 정보 등을 입력받아 대화에 반영하기 시작하였으며 그 동안의 대화 내용을 기억하여 장기적 맥락을 유지하는 ‘메모리’ 기능도 추가하였다. 구글 Gemini 역시 설정의 ‘개인별 맞춤 AI’ 설정으로 사용자와의 과거 대화, 데이터를 연동하여 보다 개인화된 맞춤형 대화를 제공하는 방향으로 진화하고 있다. 

 결과적으로 이러한 LLM 모델의 변화는 기술 개발의 초점이 ‘사용자 질의에 대해 어떻게 정답에 가까운 우수한 답변을 출력할 것인가?’라는 문제에서 ‘어떻게 하면 사용자의 맥락을 반영한 최적의 개인화 답변을 제공할 것인가?’라는 개인화와 최적화의 문제로 이동하고 있음을 보여준다.

제4절 시사점 
 앞선 선행연구 및 기술 현황을 살펴보면, 다음과 같은 시사점을 도출할 수 있다.

 첫째, 멀티 턴 의료 상담을 위한 체계적인 ‘맥락 관리’의 필요성이다. 기존의 의료 특화 LLM은 의학적 지식의 정확도는 높았으나 대화가 지속될수록 앞서 언급되었던 사용자의 핵심 의학 정보(증상, 질환 등)가 망각되는 ‘맥락 손실’이 빈번하게 발생하였다. 이는 환자의 몸 상태를 동적으로 추적하며 적절한 의학적 처방을 내려야 하는 의료 특화 LLM으로서는 약점으로 작용한다. 그리고 이를 극복하기 위해서는 사용자와의 지속적인 대화에서 중요한 의학 정보를 구조적으로 감지하여 저장하고, 이를 다음 이어지는 답변에 반영하는 Context Engineering 기반의 파이프라인 구축이 필수적으로 요구된다. 

 둘째, 의학 지식의 정확성과 사용자의 개인화를 동시에 달성할 수 있는 RAG 방법론의 도입이다. 기존 RAG는 일반적 의학 지식을 데이터로 사용하여 LLM이 흔히 일으키는 환각 현상을 방지하는 데는 기여했으나 사용자의 개별적 특성을 반영한, 개인화된 답변의 생성에서는 한계를 나타냈다. 또한, 일방향적 구조는 문서 검색에 실패할 경우 수정이 어려웠다. 이는 기존의 일방향성 RAG가 아닌, 순환식의 자체 피드백 및 개선 메커니즘을 가진 Corrective RAG(CRAG)의 도입이 필요하며 사용자 개인의 맥락을 반영할 수 있는 멀티 턴 대화 메커니즘이 필요함을 시사한다.

 셋째, 정적인 프롬프트 엔지니어링을 뛰어넘어 동적인 에이전트 중심의 접근이 필요하다. 위에서 서술한 것처럼 ChatGPT와 Gemini의 변화는, 단순히 LLM 모델의 성능 개선을 뛰어넘어 이제는 사용자와의 상호작용 과정에서 누적된 데이터에서 의미 있는 정보를 발굴하여 이를 적절히 사용자의 답변에 반영하는 맥락 설계가 얼마나 중요한지 보여준다. 그리고 이를 구현하기 위해서는 사용자 질의에 숨겨진 의도를 파악하고, 사용자에 대하여 파악한 정보와 검색된 내용이 적절한지 자체적으로 검증하고 다시 돌아가 이를 개선하는 ‘에이전트’ 형태의 시스템이 필요하다.

 종합하자면, 그 동안의 연구들은 LLM의 성능 개선에 주로 집중해 왔으며 맥락 손실이 자주 발생하는 멀티 턴 환경에서의 개인화된 맥락 유지와 반영 개선 노력은 상대적으로 떨어졌다. 이에 본 연구에서는 CRAG을 뼈대로, Context Engineering이 결합된 의학지식 AI Agent를 제안하고자 한다. 

제3장 연구방법론 

제1절 연구 목표 및 접근 방법 

3.1.1 연구 목표
 본 연구의 목표는 Context Engineering 기반 의학지식 AI Agent를 구현하여 멀티 턴 대화에서 사용자의 핵심 의학 정보를 지속적으로 추출·저장하고 사용자에게 최적의 개인화 답변을 제공하는 데 있다.

 구체적인 세부 목표는 다음과 같다. 첫째, 사용자와의 멀티 턴 대화에서 핵심 기반으로 작용할 Context Engineering 파이프라인을 구축한다. 둘째, 이를 실제 대화 시스템에 적용하여 사용자의 개인적 의학 정보를 저장하고 적절하게 활용하는 멀티 턴 AI Agent를 구현한다. 셋째, 구현된 AI Agent가 LLM대비 의학적 답변의 정확성과 개인화 수준에서 얼마나 유의미한 성능 개선을 보이는지를 정량적 평가지표로 검증한다.

3.1.2 연구 방법 및 절차
 본 연구의 목표 달성을 위한 절차는 다음 4단계로 이루어진다. 1단계는 Context Engineering 파이프라인 구축이다. 자세하게는, 사용자의 질의로부터 유의미한 의학적 정보를 선별하는 ‘추출’, 이를 구조화된 메모리에 체계적으로 보관하는 ‘저장’, 그리고 답변 생성시 이를 적절히 반영하는 ‘주입’, 그리고 생성 답변의 안전성을 확인하는 ‘검증’의 4단계 프로세스를 설계하고 구현한다. 2단계는 LangGraph 기반 순환형 아키텍처 설계다. 일방향적으로 운영되는 체인 구조가 아닌, 상태를 유지하며 복잡한 의사 결정을 순환 구조로 유연하게 수행하는 LangGraph 프레임워크를 도입한다. 3단계는 Corrective Rag(CRAG) 적용이다. 자체 피드백과 개선을 수행하는 Self-Refine 메커니즘을 가진 CRAG는 검색한 문서의 정합성을 자체적으로 평가하고 품질이 일정 수준 이하로 판단되면, 다시 웹검색 등으로 이를 보완하는 모델로 일방향적인 초기 RAG 모델보다 답변의 정확성을 크게 개선한다. 4단계는 가상 환자 데이터에 기반한 정량적 성능 측정이다. 의료 데이터 오픈소스 프레임워크인 Synthea로부터 가져온, 실제 환자와 유사한 인구통계학적, 의학적 특성을 지닌 80명의 가상 환자 데이터를 생성한다. 그리고 LLM과 AI Agent 모드에 대해 각각 멀티 턴 테스트를 실시하고 답변의 충실성, 정답과의 연관성 등을 정량적 지표로 측정한다. 또한, 통계적 가설 검정 등을 통하여 AI Agent 모드의 성능 개선 유의성을 검증한다.

제2절 Context Engineering 파이프라인

3.2.1 전체 프로세스 개요
 본 연구에서 제안하는 Context Engineering은 연속적인 멀티 턴 대화 환경에서 사용자 개인의 맥락을 유지하고, 이를 답변에 효과적으로 반영하기 위해 추출, 저장, 주입, 검증의 4단계 순환 과정을 거친다.

 1단계는 의학적 정보의 ‘추출’이다. 에이전트는 환자의 질의로부터 중요한 의학적 정보를 자동으로 감지하여 ‘추출’한다. 일반적인 의학 진료시의 질의는 대개 인구통계학적 정보(성별, 연령), 질환, 증상, 수치, 복용 약물, 알레르기 등 크게 6가지 항목으로 구성된다. 본 연구에서는 각 항목을 개별 ‘슬롯’으로 정의하고 각 슬롯에 적합한 의학적 정보를 감지하여 저장하는 방식을 사용한다. 이를 위해 본 연구에서는 MedCAT2(Medical Concept Annotation Tool2)를 사용하여 비정형 텍스트에서 정형화된 의학적 정보(엔티티)를 추출한다.

그림 . 1단계 추출 프로세스 


 MedCAT2(Medical Concept Annotation Tool2)는 미국의 표준 의학용어집(UMLS: Unified Medical Language System)에 기반한 의학 분야 특화 모델로 텍스트 내의 다양한 의학적 표현을 표준화된 개념으로 매핑하는 엔티티 연결 성능이 우수하다. 예를 들어, ‘혈압이 높다’, ‘고혈압 증세’, ‘Hypertension’ 등 다양한 의학적 표현을 UMLS CUI(Concept Unique Identifier)와 연동하여 ‘고혈압(C0020538)’이라는 단일 개념으로 매핑 처리한다. 또한, 시스템 내부 설치 방식으로 LLM을 이용한 추출 방식 대비 토큰 소모 등 연산에 들어가는 비용이 낮고 처리 속도가 상대적으로 더 빠르다는 장점을 가진다. 

 한편, 나이와 성별처럼 MedCAT2로 처리가 어려운 인구통계학적 정보는 정규 표현식 기반의 패턴 매칭 알고리즘을 사용했다. 30대, 40대처럼 세대별 표현이나 구체적 나이는 “‘N’0대”, ‘NN살’, ‘NN세’ 로 그리고 ‘남자/남성’, ‘여자/여성/임산부’ 등의 성별 표현을 규칙 기반 패턴으로 탐지하여 추출했다.

 2단계는 추출한 정보의 구조적 ‘저장’이다. 사용자 질의로부터 추출된 정보는 다음과 같이 6가지 항목의 슬롯 메모리에 구조적으로 저장된다. 이 과정에서 새로운 정보가 입력될 때마다 기존 슬롯 데이터가 업데이트되거나 누적되며 에이전트는 대화가 거듭될수록 점점 발전된 ‘사용자 프로필’을 구축하게 된다. 

그림 . 2단계 슬롯 기반 추출 및 저장


 3단계는 프롬프트 ‘주입’이다. ‘저장’ 단계에서 구축된 사용자 프로필은 답변 생성시 시스템 프롬프트에 동적으로 주입된다. LLM이 답변을 생성하기 전, 이전까지 6개 슬롯에 저장된 핵심 정보를 프롬프트의 컨텍스트 영역(Context Window)에 포함시켜 AI Agent가 일반적인 의학 지식이 아닌, 사용자에게 보다 최적화된 개인화 답변을 생성하도록 유도한다.

 4단계는 안전성 및 정확성 ‘검증’이다. 생성 답변은 최종 출력 전에, 별도 검증 모듈로 그 적절성을 평가 받는다. 본 연구에서는 다음 3가지 기준을 중점적으로 확인했다. 첫째는, 생성된 답변이 검색된 의학적 문서에 얼마나 잘 기반하였는지를 확인하는 ‘근거 기반성’이다. 다음은 사용자에게 자칫 위험한 영향을 끼칠 만한 정보가 포함되지 않았는지 확인하는 ‘안전성’이다. 마지막은, 사용자의 개인적 의학 정보가 답변에 잘 반영되었는지 확인하는 ‘맥락의 반영도’이다. 만약, 생성된 답변이 위 기준에 미치지 못한다고 판단되면, 에이전트는 자체 피드백 및 개선(Self-Refine) 메커니즘을 작동시켜 관련된 문서를 재검색하여 답변을 새로이 재생성한다. 

3.2.2 기술적 차별성 및 기대효과
 이렇게 4단계로 구성된 Context Engineering 기반 AI Agent는 기존 LLM 대비 다음과 같은 기술적 차별성을 가진다. 첫째, 맥락 손실의 최소화 및 구조적 관리다. 연속되는 사용자와의 멀티 턴 대화에서도 핵심 정보를 텍스트가 아닌 구조화된 슬롯으로 저장함으로써, 중요한 맥락의 손실 없이 완전한 사용자 프로필을 구성하고 유지할 수 있다. 둘째, 검색, 생성의 효율성 향상이다. 비정형 텍스트가 아닌, 정제된 엔티티 중심으로 사용자의 의학적 정보를 관리함으로써, RAG의 검색 정확도를 더 향상시키고 또한 환각 현상을 완화시키는 데 기여한다. 마지막은 추출 방식의 효율성이다. MedCAT2와 규칙 기반 패턴 감지 방식을 결합하여 LLM API 토큰 소모를 최소화하면서도 의학적 용어와 정보를 보다 빠르고 정확하게 추출해내는 실용적인 시스템을 구현하였다.

제3절 LangGraph 기반 순환식 시스템 아키텍처 

3.3.1 시스템 워크플로우 및 모듈 구성
 본 시스템은 기존의 선형적인 체인 구조가 가진 한계를 극복하고, 생성된 답변의 정합성을 자체적으로 검증하고 수정할 수 있는 LangGraph 프레임워크 기반 순환형 아키텍처로 설계되었다. 시스템은 크게 사용자의 의도를 파악하고 핵심 의학 정보를 추출하는 Slot Extractor, 추출된 정보를 구조적으로 관리하는 Memory Manager, 외부 출처로부터 지식을 검색하는 Retrieval, 생성된 답변의 품질을 자체적으로 검증하고 제어하는 Self-Refine, 최종적인 답변을 출력하는 Final Answer로 구성된다.

3.3.2 순환형 구조의 기술적 우수성
 제시된 아키텍처 다이어그램에서 제일 핵심적인 부분은 바로 ‘Retrieval’과 ‘Self-Refine’ 사이에 형성된 피드백 루프(feedback loop)다. 일반적인 RAG 모델이 관련된 문서 검색 후 그에 기반하여 바로 답변을 생성하는 일방향적 구조인 반면, 본 시스템은 ‘Quality OK?’라는 결정 노드를 통하여 생성된 답변의 품질을 평가한다. 평가 방법은 생성된 답변을 문장 단위로 분해하여 다음 2가지를 검증하는 방식으로 이루어진다. 하나는 답변의 각 문장이 검색된 문서와 논리적으로 일치하는지 보는 ‘근거 기반성’이며 또 다른 하나는 환자의 의학적 프로필(증상, 질환, 복용 약물) 등과 서로 충돌되는 내용은 없는지 보는 ‘맥락 반영 정도’이다. 그리고 평가 결과, 품질이 일정 기준치(본 시스템은 0.7점 설정)에 미달시, 불충분한 정보나 오류를 수정하기 위하여 쿼리를 재작성하고 재검색을 최대 2회까지 반복 수행하도록 설계하여 루프의 무한 반복을 방지하면서도 답변의 정합성이 보장되도록 하는 ‘안전장치’의 역할을 하게 만들었다.

그림 . LangGraph 기반 순환식 아키텍처 


제4절 구현 세부사항

3.4.1 하이브리드 검색 및 재순위화 전략 
 의학적 질의는 전문적인 의학 용어의 정확한 매칭과 증상, 질환에 대한 이해가 동시에 요구된다. 이를 위하여 본 연구에서는 단일 검색 방식이 아닌, 다중 검색 전략을 채택하였다. 정확한 용어 매칭에 적합한 키워드 기반 검색(BM25; Best Matching 25), 사용자의 질의에 내포된 문맥적 의미와 유사성 파악에 뛰어난 의미 검색(FAISS; Facebook AI Similarity Search), 위의 2가지 상이한 검색 결과를 결합할 때, 각 검색기의 순위를 기반으로 가중치를 재산정하여 최적의 문서를 상위권으로 도출하는 상호 순위 융합(RRF; Reciprocal Rank Fusion)을 동시에 사용하여 단일 검색시 발생할 수 있는 검색 누락을 최소화하였다.

3.4.2 시계열 가중치 기반 동적 메모리 관리
 의학지식 AI Agent에게 있어 사용자의 상태 변화를 동적으로 추적하는 것은 대단히 중요하다. 과거에 유효했던 증상이나 질환 등의 의학 정보가 더 이상 적합하거나 유의미하지 않을 수 있고 더 나아가서는 환자에게 치명적인 위해를 가져다 줄 수 있기 때문이다. 그래서, 본 시스템은 사용자가 입력한 의학적 질의, 정보에 대해 매번 타임스탬프를 부여, 시각을 기록한다. 

또한, 답변 생성시에는 간단한 시간 감쇠 함수를 적용하여 최신 정보에 더 높은 가중치를 부여한다. 이를 통해 시스템은 ‘과거에 없던 당뇨 초기 증상 발현’ 등 변화된 맥락을 정확히 감지하고, 관련된 검색 문서로부터 사용자에게 제일 적합한 치료 방향성과 계획 등을 제시하며 잠재적 위험을 방지한다.

3.4.3 사용자 인터페이스(UI) 설계 
 Python 기반 오픈소스 프레임워크인 Streamlit을 활용하여 본 연구에서 설계한 시스템을 웹 어플리케이션으로 구현하였다. 본 사용자 인터페이스 설계시의 가장 큰 특징은 사용자에게 설명 가능한 AI(XAI; eXplainable AI) 요소를 시각적으로 구현했다는 것이다. 

 UI 왼쪽 사이드바는 환자 정보, 진단/질환, 추출된 의학정보 섹션 등 Slot Extractor와 Memory Manager가 백엔드에서 처리한 결과를 시각적으로 실시간 연동하여 사용자가 현재 시스템이 자신의 핵심 의학 정보(당뇨, 고혈압 등)를 정확하게 잘 감지하고 있는지를 바로 확인할 수 있게 하였다. 이러한 UI 구조는 사용자가 에이전트 내부 구조를 모니터링할 수 있게 해 에이전트에 대한 신뢰도를 향상시키고 자칫 잘못 추출된 정보가 맥락에 반영되어 부적합한 답변이 생성되는 것을 사전에 방지하게 만든다.


그림 . Streamlit 기반 사용자 인터페이스 구현 예시


제4장 실험 설계 및 결과

제1절 실험 설계

4.1.1 CRAG 기반 AI Agent
 의학 분야는 정보의 정확성과 신뢰성이 환자의 생명, 안전과 직결되는 특수성을 가진다. 따라서, 본 연구는 LLM의 환각 현상을 방지하기 위하여 RAG를 AI Agent의 기본 뼈대로 채택했다. 특히, 단순한 검색-생성의 일방향적 구조가 아닌, 검색된 정보의 정합성을 평가하고 필요시 쿼리 재작성 등을 수행하며 최대 3회까지 재검색을 수행하는 Corrective RAG(CRAG)을 도입하였다.

 CRAG은 검색된 문서가 사용자 질의에 답변에 적합한지를 판단하기 다음 3가지 기준을 사용한다. 첫째는 사용자 질의의 핵심 키워드가 문서 내에 얼마나 포함되었는지 측정하는 ‘토큰 중복도’, 다음은 벡터 검색 엔진(FAISS 등)이 반환한 의미적 유사도 점수인 ‘검색 유사도’, 마지막은 정보가 지나치게 적은 너무 짧은 문서나 반대로 노이즈가 많은 너무 긴 문서를 제외하기 위하여 적정 길이(100~1,000자)에 가중치를 부여한 ‘문서 길이 점수’이다. 이 3가지를 종합하여 임계값이 0.6 이상의 문서는 유효한 근거로 채택된다. 또한, CRAG는 검색 실패시에 동일한 쿼리를 재사용하는 게 아닌, 쿼리를 재작성하여 보다 전략적으로 관련된 문서를 검색한다. 특히, Slot Extractor로 정리된 사용자의 의학 엔티티를 쿼리에 배치하여 검색의 범위를 축소하는 ‘슬롯 기반 구체화’ 전략을 시행하여 사용자에게 제일 적합한 관련 문서를 찾아낸다. 


그림 . LangGraph와 CRAG가 결합된 이중 순환 구조 


 위에서 언급한, 유사한 순환형 구조를 가진 LangGrpah 프레임워크와 CRAG 간의 관계를 구체적으로 설명하자면 LangGraph는 사용자의 맥락을 어떻게 잘 유지하고 반영할 것인지에 초점을 둔 시스템 아키텍처이고 CRAG는 LangGraph의 Retrieval 노드 안에서 액자식으로 순환하며 SlotExtractor등과 유기적으로 연계하며 의학적 정합성을 가진 관련 문서를 샅샅히 찾아내는 역할을 수행한다.

4.1.2 비교 실험군 설정: LLM vs AI Agent 
 본 연구에서 제안한 AI Agent 모델의 성능을 객관적으로 검증하기 위하여 대조군과 실험군을 다음과 같이 설정하였다. 

 대조군은 일반 사용자들이 가장 많이 사용하는 구글 Gemini(버전 2.5 pro)를 선택하였다. 이는 별도의 프롬프트 엔지니어링 등 외부 개입이 없는 순수 LLM이 사용자와의 멀티 턴 대화 환경에서의 맥락 유지 및 반영 능력을 객관적으로 정확히 측정하기 위함이다. 대조군은 사용자의 핵심 의학 정보 등 개인적 맥락이 전혀 저장되거나 반영되지 않고 오로지 LLM 내부 메모리에만 의존한다.

 실험군은 앞서 설계한 Context Engineering 기반 AI Agent다. LangGraph 기반으로 구축된 AI Agent는 사용자와의 멀티 턴 대화 때마다 핵심 의학 정보를 감지하여 슬롯으로 추출, 저장하고 이를 주입, 검증하는 Context Engineering 파이프라인이 설치되어 개인적 맥락이 지속적으로 반영된다. 

4.1.3 프롬프트 엔지니어링 및 페르소나 전략
 2개 모드 간의 성능 차이를 더 명확히 하고 일반적인 의사-환자 간에서 이루어지는 의료 대화의 특수성을 반영하여 상이한 프롬프트 엔지니어링 전략을 수립했다. 

LLM은 있는 그대로의 성능을 측정하기 위하여 개입을 최소화하였으며 ‘의료 정보 제공자로서 500~700자 이내로 답변하라’는 제약만 설정하였다. 반면 AI Agent 모드에게는 ‘개인화된 의료 전문가’라는, LLM과는 차별화된 페르소나를 부여하고 환자의 구체적 상황 분석과 증상 설명 그리고 대응 계획과 근거 제시, 따뜻한 톤 등 5가지 핵심 원칙을 제시하였다.


모드
프롬프트
LLM
당신은 의료 정보 제공자입니다. 
사용자의 질문에 정보 제공 목적으로 500~700자 이내로 답변하세요.
AI Agent
당신은 개인화된 의료 정보 전문가입니다.
아래 5가지 핵심 원칙에 기반하여 답변하세요.
1. 환자의 구체적 상황(나이, 성별, 과거병력) 분석
2. 증상의 의료적 의미와 메커니즘 설명
3. 단계별 대응 계획 제시
4. 위험 이유를 근거 기반으로 설명
5. 환자의 불안감을 고려한 따뜻한 톤
표 1. 프롬프트 엔지니어링 내용


4.1.4 멀티 턴 시나리오
 Synthea로 생성된 총 80명의 생성 환자에 대해 각 환자별로 5개의 연속된 질의 프롬프트 시나리오를 설정하였다. 첫 번째 턴은 성별, 나이, 질환이나 증상 등을 드러내고 두 번째 턴에서는 질환이나 증상별 수치, 복용 약 등 추가적 정보를 질의한다. 세 번째 턴에서는 모든 증상이나 질환에 중요한 역할을 하는 운동 등 건강관리 방법을, 네 번째 턴에서는 식단을 질의한다. 그리고 마지막 턴은 그간의 대화로 누적된 사용자의 맥락을 종합하여 개인화된 의학적 결론을 도출할 수 있는지를 평가하는 핵심 단계로 
‘건강관리는 어떻게 할까요?’ 등과 같은 포괄적인 질문을 던진다.

턴 
질의 유형
세부 질의
1
인구통계학적 정보 + 주요 질환, 증상
“65세 남성으로 당뇨가 있고 최근 피로가 더 많아졌어요”
2
복용약 및 수치 정보
“메트포르민을 복용하고 혈당은 보통 200정도에요”
3
운동 
“운동은 어떻게 하면 좋을까요?”
4
식단
“식사나 식단은 어떻게 해야 하나요?”
5
종합적 질의
“앞으로 건강 관리는 어떻게 하면 좋을까요?”
표 2. 멀티 턴 시나리오 내용


제2절 데이터셋

4.2.1 의학지식 DB: 전문 의학지식 데이터 
 견고한 RAG를 구축하기 위해서는 의학적 정합성이 검증된 고품질의 외부 지식 데이터베이스 확보가 중요하다. 이를 위해 본 연구에서는 과학기술정보통신부가 주관하는 국가 AI 개발지원 플랫폼인 ‘AI 허브(AI-hub)’에 등록된 ‘전문 의학지식 데이터’를 사용한다. 

 해당 데이터는 서울대학교 병원, 삼성서울병원, 서울성모병원 등 국내 주요 상급종합병원 5곳이 참여하여 구축한 것으로, 약 1억 개의 국영문 전문 의학 말뭉치 토큰과 의학 자연어 처리 태스크에 특화된 1.5만쌍(10만 토큰)의 질의응답 데이터로 구성되었다. 또한 모든 데이터는 전문 의료진의 엄격한 검수를 거쳐 의학적 신뢰성과 임상적 타당성을 확보하였다. 

4.2.2 실험용 환자 데이터: Synthea 기반 가상 코호트
 본 연구에서는 개인정보보호법 준수 및 임상적 다양성을 갖춘 환자 데이터 확보를 위해 미국 MITRE Corporation에서 개발한 Synthea를 활용하여 가상의 환자 데이터를 생성하였다. Synthea는 미국 인구 통계 데이터와 임상 진료 지침을 기반으로 환자의 전 생애주기 의료 기록을 생성하는 검증된 오픈소스 시뮬레이터다. 

 본 연구에서는 유의미한 통계적 검증을 위하여 총 80명의 환자 코호트를 생성하였으며, 전체 코호트는 실제 환자와 유사하게 연령, 성별 등 인구통계학적 특성과 증상, 질환, 투약 이력 등 시계열적 개인 의료 기록을 지니고 있다. 이는 환자로부터 주어진 다양한 의학적 정보로부터 사용자의 프로필을 만들어가며 맥락을 설계하고 반영하는 Context Engineering이 핵심인 본 연구 데이터로서의 필수 조건(의학적 다양성)을 충족한다.



특성
분류
환자 수 
비율(%)
성별
여성
45
56.2
남성
35
43.8
연령대
10~19세
11
13.8
20~29세
12
15.0
30~39세
6
7.5
40~49세
12
15.0
50~59세
13
16.2
60~69세
12
15.0
70~79세
10
12.5
80+ 세
4
5.0
나이
평균 ± 표준편차
46.8 ± 21.8
80
100.0
중앙값(범위)
49.0 (10~101)
표 3. 생성 환자 80명 인구통계학적 분석 


제3절 평가지표  
 본 연구는 CRAG가 도입된 Context Engineering 기반 AI Agent 모드의 답변 품질과 맥락 반영 능력을 다각도로 검증하기 위하여 RAG 시스템 평가 표준 프레임워크인 RAGAS(Retrieval-Augmented Generation Assessment)의 Faithfulness(충실성), Answer Relevance(답변 관련성), 그리고 Perplexity(다음 단어의 예측 불가능성)을 활용하여 정량적 평가를 수행했다.

4.3.1 RAGAS Faithfulness(충실성)

4.3.1.1 선정 근거 
 RAGAS Faithfulness는 생성된 답변이 검색된 문서, 텍스트 등에 얼마나 근거하고 있는지를 정량적으로 측정한다. 본 연구는 외부 문서를 참조하지 않는 LLM과 달리, CRAG 기반의 AI Agent 가 ‘사실적 근거에 기반’한다는 차이점을 정량적으로 명확히 보여주기 위하여 선정하였다.

4.3.1.2 정의 및 산출법
 원문에서는 RAGAS Faithfulness를 RAG로 출력한 답변 S가 사전에 주어진 문맥 C(Context)로부터 논리적으로 추론될 수 있다면, 해당 답변은 충실하다고 평가한다. 또한, 근거에 기반하지 않은 답변은 충실하지 않다고 평가한다.

 Faithfulness 측정은 3단계로 이루어진다. 1단계에서는 생성된 답변을 상세히 분석하기 위하여 ‘단문’으로 더 잘게 쪼갠다. 예를 들면, “서울은 인구 1천만 명의 대한민국 수도이다”라는 문장을 ‘서울의 인구는 1천만 명이다’, ‘서울은 대한민국의 수도다’라는 개별적 의미를 가진 단문으로 쪼개는 것이다. 그리고 이 잘게 쪼갠 단문이 근거에 기반한 것인지를 확인하기 위하여 LLM으로부터 ‘네, 아니오’로 이분법적 판단을 요청한다. 그리고 이 중 근거에 기반하여 ‘네’ 판정을 받은 문장이 전체 문장에서 차지하는 비율이 높을수록 RAGAS Faithfulness 점수가 높아지며 일반적으로 0.7 이상일 경우에는 충실도가 양호하다고 판단된다.

그림 . Faithfulness 산출식 


4.3.2 RAGAS Answer Relevance(답변 관련성)

4.3.2.1 선정 근거
 Answer Relevance는 RAG에서 생성된 답변이 사용자의 최초 질문 의도에 적합하게 출력된 것인지를 측정한다. Answer Relevance는 AI Agent가 사용자의 질문 의도에 적합한 답변을 생성하였는지 확인하기 위하여 선정하였다. Faithfulness와의 차이점은 Faithfulness가 ‘사실적 근거 여부’를 판단한다면 Answer Relevance는 ‘질문 의도와의 적합 여부’를 판단한다는 것이다.

4.3.2.2 정의 및 산출법
 Answer Relevance는 이미 생성된 답변에 대하여 ‘이 답변이 어떠한 질문으로부터 비롯된 것인가?’를 LLM에게 추론하게 한 후, 역으로 질문을 던지게 한다. 그리고 LLM이 역으로 만든 질문을 원래 질문과 대조하며 서로 얼마나 유사한지를 비교한다. 만약, 역으로 만들어진 질문이 원래 질문의 핵심과 유사하다면 그 답변은 ‘정답과 관련성이 높다’고 평가된다.

 산출 공식을 자세히 들여다보면, 우선 원래의 질문과 LLM이 역으로 추론하여 만든 질문을 모두 벡터로 변환한다. 그리고 두 벡터가 얼마나 유사한지를 판단하는 ‘코사인 유사도’를 이용하여 0과 1 사이의 값으로 유사도를 측정한다. 그리고 LLM이 역으로 던진 질문 1개로는 측정의 타당성이 떨어지기 때문에 N개의 질문으로 이를 다시 반복하여 유사도 점수를 모두 합친 후 낸 평균값이 바로 Answer Relevance 점수다. 일반적으로 0.6 이상일 경우에는 원래 질문에 적절히 답변을 했다고 판단된다.


그림 . Answer Relevance 산출식


4.3.3 Perplexity(다음 단어 예측 불확실성)

4.3.3.1 선정 근거
Perplexity는 주로 언어 모델에서 다음에 나올 단어를 예측하기가 얼마나 어려운지를 측정한다. Perplexity는 AI Agent가 구체적인 사용자의 맥락을 반영하는 특성상, 상대적으로 예측하기 쉬운 일반론적 답변보다는 사용자에게 얼마나 차별화된 개인화 답변이 나오는지를 확인하기 위하여 선정하였다. 

4.3.3.2 정의 및 산출법
 Perplexity를 측정하는 방법은 생성된 답변을 다른 LLM에게 보여주고 ‘다음 단어로 무엇이 나올지’를 예측하는 방식으로 이루어진다. 예를 들어 ‘동해물과 백두산이’라는 답변을 LLM에게 보여준다면, 파라미터 학습 데이터가 많은 LLM은 ‘마르고’란 단어를 예측할 것이다. perplexiy는 이처럼 예측하기 쉬운 답변에는 낮은 점수를 부여한다. 하지만, ‘당뇨와 하지정맥을 동시에 겪는 환자에게는’처럼 개별적 정보가 혼재하여 예측이 훨씬 어려워진 답변에는 높은 점수를 부여한다.

 산출 공식을 자세히 살펴보면, perplexity는 일정한 맥락이 부여된 답변에 대하여 다음에 나올 예상 단어의 확률을 로그로 변환한다. 이 외에 예상되는 단어들의 확률 역시 모두 로그로 변환하여 평균을 낸다. 그리고 이 평균값에 지수 변환을 적용하여 최종적인 점수를 산출한 게 바로 perplexity의 점수이다. 

제4절 실험 결과 및 분석

4.4.1 RAGAS Faithfulness 

 LLM의 Faithfulness는 0으로 측정되었다. 이는 LLM이 외부 지식 데이터베이스를 참조하지 않고 모델 내부의 파라미터 지식만으로 답변을 생성했기 때문에 Faithfulness의 평가 구조상 ‘사실적 근거에 기반하지 않았기 때문에’ 나온 필연적 결과다. 

 반면, AI Agent는 매 턴마다 CRAG를 통한 관련 문서 검색을 수행하며 평균 0.139의 점수를 기록하였다. cohen’s d가 2.472로 통계적으로 매우 큰 효과를 나타내 AI Agent가 통계적으로 유의미하게 근거에 기반한 답변을 생성하고 있음을 입증했다. 하지만, 일반적인 수치인 0.7과 대비하면 현저히 수치가 낮은데 이는 사용자의 맥락을 반영하며 답변의 내용이 복잡해져 근거로 선택된 텍스트와 매칭이 되지 않는 경우가 많았기 때문으로 분석된다. 


모드
평균
표준편차
최소
최대
Q1
Q3
LLM
0
0
0
0
0
0
AI Agent
0.139
0.075
0
0.285
0.087
0.194
통계 분석
t-통계량
p-value
통계적 유의성
cohen’s d
34.518
0.00
p<0.001 (유의성 높음)
3.86
표 4. Faithfulness 통계 분석 


4.4.2 RAGAS Answer Relevance
 LLM이 0.361로 AI Agent(0.242)보다 더 높게 측정되었다. 이는 LLM이 질문의 핵심만 요약하여 간결하게 답변하는 경향이 있어 역질문 생성시 원래 질문과의 유사도가 높게 나타났기 때문이다. 반면, AI Agent는 증상, 질환 등 사용자의 개인적 의학 정보를 반영한 상세한 설명과 의학적 판단의 근거 제시 등이 더해지며 답변의 길이가 길어져 원래 질문보다 훨씬 구체적이고 복잡한 내용으로 띠게 되며 벡터 유사도가 낮아진 것으로 판단된다. 

 즉, 통계적으로 이렇게 매우 뚜렷한 차이가 발생한 것은 AI Agent의 성능 저하를 의미하는 것이 아니라 LLM과 AI Agent 간의 답변의 성격 차이에서 기반한 것이라 할 수 있다. 의학적·임상적 관점에서 본다면, 환자가 정말 필요로 하는 것은 간결하게 답변을 제시하는 것보다 본인의 증상, 복용 약물 등을 감안한 ‘개인화된 의학적 설명’일 것이므로 이러한 점수의 차이는 본 연구의 목적인 사용자 개인의 맥락 반영이 적절하게 이루어진 것으로 해석해도 타당할 것이다.


모드
평균
표준편차
최소
최대
Q1
Q3
LLM
0.361
0.114
0.069
0.581
0.295
0.452
AI Agent
0.242
0.114
0
0.570
0.174
0.321
통계 분석
t-통계량
p-value
통계적 유의성
cohen’s d
-18.246
0.00
p<0.001 (유의성 높음)
-2.04
표 5. Answer Relevance 통계 분석


4.4.3 Perplexity 
 AI Agent가 1.306으로 LLM보다 더 높게 측정되었다. 이는 AI Agent가 LLM보다 사용자의 핵심 의학 정보에 기반하여 보다 개인적 맥락을 반영한 답변을 생성하였기 때문이다. 이는 RAGAS Faithfulness, Answer Relevance와의 상관관계 분석에서도 드러난다. 


모드
평균
표준편차
중앙값
최소
최대
25%분위
75%분위
LLM
1.246
0.056
1.245
1.13
1.433
1.21
1.28
AI Agent
1.306
0.046
1.305
1.132
1.459
1.275
1.335
통계 분석
t-통계량
p-value
통계적 유의성
cohen’s d
21.55
0.00
유의(p<0.05)
1.2
표 6. Perplexity 통계 분석   

 
Perplexity는 Faithfulness와 상관관계 0.42, 0.001보다 낮은 p-value를 드러내며 답변의 ‘사실 근거 기반 정도’를 측정하는 Faithfulness와 양의 상관관계를 가지는 것으로 드러났다. 즉, RAG의 근거를 충실하게 반영할수록 perplexity가 증가한다고 볼 수 있다. 또한, Answer Relevance와는 상관계수 –0.08, 0.001보다 낮은 p-value로 음의 상관관계를 가지는 것으로 드러났다. 즉, lmm은 사용자 질의에 대하여 간결하게 상대적으로 예측이 쉬운 일반론적 답변을 생성하고 AI Agent는 사용자 맥락을 밀도 있게 반영하여 더 상세한 답변을 생성한다는 의미로 해석할 수 있다. 

제5장 결론 

제1절 연구 요약 

 본 연구는 필수의료 위기 심화와 LLM이 멀티 턴 대화 환경에서 겪는 맥락 손실과 개인화 실패, 환각 현상 등으로 인한 의학적 위험성 등에 대처하고자 Context Engineering 기반 AI Agent를 설계, 구현하는 것을 목표로 하였다. 

 이를 위해 본 연구에서 MedCAT2 기반의 의학적 슬롯 추출 및 메모리 관리, LangGraph 프레임워크 기반 순환형 아키텍처, 자체 피드백 및 검증을 수행하는 Corrective RAG(CRAG)을 통합한 AI Agent 모델을 제안하였다. 

 오픈소스 시뮬레이터인 Synthea로부터 생성한 실제 환자 코호트와 유사한 80명의 가상 생성 환자로 성능을 평가한 결과, AI Agent는 LLM 대비 RAGAS Faithfulness, Perplexity 등에서 통계적으로 유의미한 성능 개선을 이룬 것이 확인되었다. 비록 개인의 맥락을 밀도 있게 반영한, 상세한 설명으로 Answer Relevance 점수는 낮았지만 이는 사용자에게 보다 개인화된 설명을 하기 위한 과정에서의 트레이드 오프임이 지표 간 상관관계 분석에서 드러났다.

제2절 연구의 의의 
 본 연구의 의의는 다음과 같다.

 첫째, 멀티 턴 대화 환경에서 맥락 손실이 발생하는 LLM의 한계를 보완하기 위하여 기술적으로 개선된 Context Engineering 아키텍처를 제시했다는 것이다. 일반적 LLM 연구들이 파라미터 튜닝이나 프롬프트 엔지니어링 중심이었던 것과 달리, 본 연구는 사용자 질의로부터 핵심적 의학 정보를 슬롯 형태로 구조화하여 저장, 관리하고 이를 답변의 생성 과정에서 동적으로 주입하고 검증하는 Context Engineering 파이프라인을 체계화하였다. 또한, Perplexity 등 정량적 지표를 활용한 테스트 결과에서 LLM의 맥락 손실을 공학적 설계로 일부 해결할 수 있음을 실증하였다.

 둘째, 의학적 신뢰성을 위하여 이중 순환 구조의 아키텍처를 구현하였다. LangGraph의 외부 순환과 CRAG의 내부 순환 구조를 결합하여 사용자에게 의학적 답변을 생성, 출력하기 전, 근거 문서의 의학적 정합성을 자체적으로 평가하고 개선하는 Self-Refine 메커니즘을 견고하게 구축하였다. 이는 자칫 잘못된 의학적 정보가 전달될 경우 치명적인 악영향이 일어날 수도 있는 의료 분야의 특수성을 반영한 것으로, 이후 사실에 근거한 데이터의 사용이 갈수록 중요해질 금융 등 타 분야의 AI 에이전트 설계시 중요 참조 모델이 될 수 있다. 

 셋째, 의료 접근성 향상을 위한 현실적이고 구체적인 대안을 제시하였다. 의학적으로 신뢰성이 확실하게 검증된 의학 데이터를 기반으로 구축된 본 시스템은 많은 비용이 들어가는 대규모 데이터 트레이닝, 설계 과정이 없어도 누구나 안전하게 사용 가능한 의료 상담 서비스를 구현할 수 있음을 보여주었다. 특히, 의료 접근성이 떨어지는 지방 주민들이 1차적으로 빠르고 정확하면서도 신뢰할 수 있는 의학적 답변을 제공 받을 수 있어 이후 필수의료 분야에서의 활용 가능성이 기대된다.

제3절 한계점 및 향후 연구 
 위와 같은 성과에도, 본 연구에는 다음과 같은 한계가 존재하며 이를 바탕으로 향후 연구 방향을 제시한다.

 첫째, 시스템 사용자로 가정한 환자 데이터가 실제 환자가 아닌, 오픈소스인 Synthea로부터 생성된 가상의 환자 데이터라는 점에서 임상적 타당성 검증에 한계가 있었다. 비록 실제 환자군과 유사한 인구통계학적, 의학적 특성을 지니고 있으나 더 비정형적이고 복잡한 데이터로 구성된 실제 환자군을 완벽히 모사하기에는 한계가 있었다. 향후 연구에서는 IRB(생명윤리심의위원회) 승인 등을 거쳐 실제 환자군의 비식별화된 임상 데이터를 확보하고 이를 활용하여 시스템의 임상적 타당성을 검증해야 한다.

 둘째, 실시간성 확보를 위한 응답 속도의 개선이다. LangGraph 기반 외부순환, CRAG 내부 순환 등 이중 순환 구조의 아키텍처가 만들어지며 AI Agent의 평균 응답 시간이 LLM에 비해 훨씬 지연되는 현상이 발생하였다. 응답 속도는 중요한 사용성 지표 중의 1개이므로, 향후에는 검색 프로세스를 병렬화하거나 보다 경량화된 모델 등을 설치하여 응답 속도를 개선하는 연구가 필요하다.

 셋째, 정성적 평가의 부재다. 본 연구에서는 RAGAS Faithfulness, Perplexity 등의 정량적 지표로서 AI Agent가 개인의 핵심 의학 정보를 적절히 추출하고 구조적으로 저장하여 이후 답변시 맥락으로 반영하고 있음을 확인하였다. 하지만, 실제 AI Agent를 사용할 의료진이나 환자의 정성적 평가는 없어서 정확한 성능 측정에 한계가 있었다. 향후 연구에서는 실제 의료진, 환자 등이 사용자 테스트에 참여하며 AI Agent가 정말로 의학적으로 적절하면서도 개인의 맥락을 반영한 개인화된 답변을 만들어내는지를 보다 정밀하게 검증할 필요가 있다.

참고문헌
[1] H. Nori et al., "Capabilities of GPT-4 on Medical Challenge Problems," arXiv preprint arXiv:2303.13375, 2023.
[2] U.S. Food & Drug Administration, "FDA Guidance on Clinical Decision Support Software," 2022.
[3] X. Li et al., "MultiChallenge: Multi-turn Conversational Understanding and Inference Memory," arXiv preprint arXiv:2503.22458v1, 2025.
[4] N. F. Liu et al., "Lost in the Middle: How Language Models Use Long Contexts," arXiv preprint arXiv:2307.03172, 2024.
[5] L. Mei et al., "A Survey of Context Engineering for Large Language Models," arXiv preprint arXiv:2507.13334, 2025.
[6] K. Singhal et al., "Large Language Models Encode Clinical Knowledge," Nature, vol. 620, pp. 172-180, 2023.
[7] K. Singhal et al., "Towards Expert-Level Medical Question Answering with Large Language Models," arXiv preprint arXiv:2305.09617, 2023.
[8] S. Zhang et al., "Personalizing Dialogue Agents: I have a dog, do you have pets too?" in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL), 2018.
[9] P. Lewis et al., "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks," in Advances in Neural Information Processing Systems (NeurIPS), vol. 33, pp. 9459-9474, 2020.
[10] S. Yan et al., "Corrective Retrieval Augmented Generation," arXiv preprint arXiv:2401.15884, 2024.
[11] LangChain AI, "LangGraph: Language Graph Framework," LangChain Documentation, 2024.
[12] J. Walonoski et al., "Synthea: An Approach, Method, and Software Mechanism for Generating Synthetic Patients," Journal of the American Medical Informatics Association, vol. 25, no. 3, pp. 230-238, 2018.
[13] S. Es, J. James, L. O. Espinoza-Bolivar et al., "RAGAS: Automated Evaluation of Retrieval Augmented Generation," arXiv preprint arXiv:2309.15217, 2023.
[14] J. Cohen, Statistical Power Analysis for the Behavioral Sciences, 2nd ed., Lawrence Erlbaum Associates, 1988.
[15] Z. Kraljevic et al., "Multi-domain clinical natural language processing with MedCAT: the Medical Concept Annotation Toolkit," Artificial Intelligence in Medicine, vol. 117, 102083, 2021.
[16] D. Madaan et al., "Self-Refine: Iterative Refinement with Self-Feedback," arXiv preprint arXiv:2303.17651, 2023.
[17] S. Robertson and H. Zaragoza, "The Probabilistic Relevance Framework: BM25 and Beyond," Foundations and Trends in Information Retrieval, vol. 3, no. 4, pp. 333-389, 2009.
[18] J. Johnson, M. Douze, and H. Jégou, "Billion-scale similarity search with GPUs," IEEE Transactions on Big Data, vol. 7, no. 3, pp. 535-547, 2021.
[19] G. V. Cormack et al., "Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods," in Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2009.
[20] Streamlit, "Streamlit: The fastest way to build and share data apps," available at: https://streamlit.io/, 2024.
[21] AI Hub, "전문 의학지식 데이터," 과학기술정보통신부, 2023.

 붙임 : LLM – AI Agent 간 답변 비교 

LLM
AI Agent 
건강 관리를 위해 생활습관을 개선하는 것은 장기적으로 큰 이점을 가져다줍니다. 우선, 균형 잡힌 식단을 유지하는 것이 중요합니다. 과일, 채소, 통곡물, 단백질이 풍부한 음식을 섭취하고, 가공식품과 설탕, 포화지방의 섭취를 줄이는 것이 좋습니다. 이렇게 하면 체중 관리뿐만 아니라 심혈관 건강에도 긍정적인 영향을 미칩니다.

운동은 또 다른 중요한 요소입니다. 매일 30분 이상, 주 5일 정도의 유산소 운동을 목표로 하세요. 걷기, 조깅, 자전거 타기 등 자신에게 맞는 운동을 선택하면 좋습니다. 규칙적인 운동은 체력 향상뿐만 아니라 스트레스 해소에도 도움을 줍니다.

수면도 간과할 수 없는 부분입니다. 성인은 하루 7~9시간의 수면이 필요합니다. 규칙적인 수면 패턴을 유지하고, 잠들기 전에는 전자기기 사용을 줄여 수면의 질을 높이는 것이 중요합니다.

스트레스 관리 역시 건강에 큰 영향을 미칩니다. 요가, 명상, 심호흡 같은 이완 기법을 통해 스트레스를 줄이는 방법을 찾아보세요. 또한, 친구나 가족과의 대화도 정서적 지지를 받을 수 있는 좋은 방법입니다.

마지막으로, 정기적인 건강 검진을 통해 자신의 건강 상태를 체크하는 것이 중요합니다. 조기에 질병을 발견하고 예방하는 데 큰 도움이 됩니다. 금연과 절주도 건강한 생활습관의 중요한 부분입니다. 흡연은 여러 질병의 원인이 되며, 과도한 음주는 간 건강에 해로울 수 있습니다.
이러한 생활습관 개선은 처음에는 어려울 수 있지만, 작은 변화부터 시작해 점차적으로 습관화하면 장기적으로 건강한 삶을 유지하는 데 큰 도움이 될 것입니다.
1. 환자 상황 분석 
67세 남성 환자분께서는 현재 심혈관 질환 예방을 위해 흔히 사용되는 콜레스테롤 저하제인 심바스타틴을 복용 중이십니다. 주거 환경이 불만족스러운 상태로, 이는 스트레스나 생활의 질에 영향을 미칠 수 있습니다. 이러한 요소들은 전반적인 건강 관리에 중요한 영향을 미칠 수 있습니다.

2. 증상의 의료적 의미 
심바스타틴은 혈중 콜레스테롤 수치를 낮추어 심혈관 질환의 위험을 줄이는 데 도움을 줍니다. 그러나 주거 환경이 불만족스러운 경우, 이는 스트레스 증가로 이어질 수 있으며, 스트레스는 심혈관 건강에 부정적인 영향을 미칠 수 있습니다. 스트레스는 혈압을 상승시키고, 심장 박동수를 증가시키며, 장기적으로는 심혈관 질환의 위험을 높일 수 있습니다.

3. 위험 이유 
첫째, 스트레스는 코르티솔과 같은 스트레스 호르몬의 분비를 증가시켜 혈압과 혈당 수치를 높일 수 있습니다. 둘째, 만성적인 스트레스는 염증 반응을 유발하여 혈관 건강에 악영향을 미칠 수 있습니다. 셋째, 스트레스는 건강한 생활습관을 유지하는 데 방해가 될 수 있으며, 이는 운동 부족이나 불규칙한 식습관으로 이어질 수 있습니다.

4. 단계별 대응 방안 
우선, 정기적인 건강 검진을 통해 혈압, 콜레스테롤 수치 및 심혈관 건강 상태를 모니터링하는 것이 중요합니다. 생활습관 개선을 위해서는 규칙적인 운동을 권장합니다. 걷기, 수영, 자전거 타기와 같은 유산소 운동은 심혈관 건강에 도움이 됩니다. 또한, 균형 잡힌 식단을 유지하여 과일, 채소, 통곡물, 건강한 지방을 충분히 섭취하는 것이 좋습니다. 스트레스 관리도 중요합니다. 명상, 요가, 심호흡 운동과 같은 스트레스 완화 기법을 시도해 보세요. 주거 환경 개선이 가능하다면, 생활의 질을 높이는 방향으로 고려해 보시는 것도 좋습니다. 응급 상황에서는 가슴 통증, 호흡 곤란, 심한 두통이 발생할 경우 즉시 응급 의료 서비스를 받으셔야 합니다.

5. 향후 관리 계획 
앞으로는 정기적인 건강 검진과 함께 생활습관 개선을 지속적으로 실천하는 것이 중요합니다. 의료진과의 상담을 통해 약물 복용의 효과를 주기적으로 평가하고, 필요시 약물 조정을 고려할 수 있습니다. 또한, 스트레스 관리와 주거 환경 개선을 위한 계획을 세우고, 이를 실천해 나가는 것이 건강 유지에 도움이 될 것입니다.

근거:
심바스타틴은 콜레스테롤 수치를 낮추어 심혈관 질환 예방에 효과적입니다.
스트레스는 심혈관 질환의 위험 요인으로 작용할 수 있습니다.
규칙적인 운동과 건강한 식습관은 심혈관 건강을 개선하는 데 중요합니다.
스트레스 관리 기법은 정신적, 신체적 건강에 긍정적인 영향을 미칩니다.
※ 본 답변은 LLM 분석과 검증된 의학 문헌 근거를 결합하여 제공되었습니다. 정보 제공 목적이며, 진단·치료를 대체하지 않습니다.
표 7. 동일 질의(앞으로 건강 관리를 위해 어떻게 해야 할까요?)에 대한 LLM-AI Agent 간 답변 비교표 
