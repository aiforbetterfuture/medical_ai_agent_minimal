# ìŠ¤ìºí´ë“œ í‰ê°€ì§€í‘œ ìƒì„¸ ì •ë¦¬

## ğŸ“‹ ê°œìš”

í˜„ì¬ ìŠ¤ìºí´ë“œì— êµ¬í˜„ëœ ëª¨ë“  í‰ê°€ì§€í‘œë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì •ë¦¬í•œ ë¬¸ì„œì…ë‹ˆë‹¤.

---

## 1. RAGAS (Retrieval-Augmented Generation Assessment) ì§€í‘œ

### 1.1 Faithfulness (ì‹ ë¢°ì„±)

**íŒŒì¼**: `experiments/evaluation/ragas_metrics.py`

**ì •ì˜**: ìƒì„±ëœ ë‹µë³€ì´ ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ(contexts)ì™€ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ì¸¡ì •

**ë²”ìœ„**: 0.0 ~ 1.0 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

**ê³„ì‚° ë°©ë²•**:
- RAGAS ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `faithfulness` ë©”íŠ¸ë¦­ ì‚¬ìš©
- LLM ê¸°ë°˜ í‰ê°€: ë‹µë³€ì˜ ì£¼ì¥ì´ contextsì—ì„œ ë’·ë°›ì¹¨ë˜ëŠ”ì§€ í™•ì¸
- Hallucination(í™˜ê°) ê°ì§€: ê·¼ê±° ì—†ì´ ìƒì„±ëœ ì •ë³´ë¥¼ íƒì§€

**ì‚¬ìš© ëª¨ë¸**: GPT-4o-mini (RAGAS ë‚´ë¶€ ì‚¬ìš©)

**ì„¤ì •**:
```python
from ragas.metrics import faithfulness
metrics = [faithfulness]
```

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "faithfulness": 0.85
}
```

**ì˜ë¯¸**:
- **0.9 ì´ìƒ**: ë‹µë³€ì´ ê·¼ê±° ë¬¸ì„œì™€ ë§¤ìš° ì˜ ì¼ì¹˜
- **0.7-0.9**: ëŒ€ì²´ë¡œ ì¼ì¹˜í•˜ë‚˜ ì¼ë¶€ ì£¼ì¥ì´ ê·¼ê±° ë¶€ì¡±
- **0.5-0.7**: ìƒë‹¹ ë¶€ë¶„ ê·¼ê±° ì—†ìŒ
- **0.5 ë¯¸ë§Œ**: ì‹¬ê°í•œ í™˜ê° ë˜ëŠ” ê·¼ê±° ë¶€ì¡±

---

### 1.2 Answer Relevance (ë‹µë³€ ê´€ë ¨ì„±)

**íŒŒì¼**: `experiments/evaluation/ragas_metrics.py`

**ì •ì˜**: ìƒì„±ëœ ë‹µë³€ì´ ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ ì¸¡ì •

**ë²”ìœ„**: 0.0 ~ 1.0 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

**ê³„ì‚° ë°©ë²•**:
- RAGAS ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ `answer_relevancy` ë©”íŠ¸ë¦­ ì‚¬ìš©
- LLM ê¸°ë°˜ í‰ê°€: ë‹µë³€ì´ ì§ˆë¬¸ì„ ì ì ˆíˆ ë‹¤ë£¨ëŠ”ì§€ í™•ì¸
- ì§ˆë¬¸-ë‹µë³€ ê´€ë ¨ì„± ì¸¡ì •

**ì‚¬ìš© ëª¨ë¸**: GPT-4o-mini (RAGAS ë‚´ë¶€ ì‚¬ìš©)

**ì„¤ì •**:
```python
from ragas.metrics import answer_relevancy
metrics = [answer_relevancy]
```

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "answer_relevance": 0.78  # answer_relevancy -> answer_relevanceë¡œ ë³€í™˜ë¨
}
```

**ì˜ë¯¸**:
- **0.9 ì´ìƒ**: ë‹µë³€ì´ ì§ˆë¬¸ì„ ì™„ë²½í•˜ê²Œ ë‹¤ë£¸
- **0.7-0.9**: ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆìœ¼ë‚˜ ì¼ë¶€ ëˆ„ë½
- **0.5-0.7**: ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ê´€ë ¨
- **0.5 ë¯¸ë§Œ**: ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ë¬´ê´€í•˜ê±°ë‚˜ ì™„ì „íˆ ë‹¤ë¥¸ ì£¼ì œ

---

### 1.3 Perplexity (í˜¼ë€ë„)

**íŒŒì¼**: `experiments/evaluation/ragas_metrics.py` (`calculate_perplexity` í•¨ìˆ˜)

**ì •ì˜**: ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ ë¶ˆí™•ì‹¤ì„± ì¸¡ì • (ë‹µë³€ì˜ ìì—°ìŠ¤ëŸ¬ì›€/ì¼ê´€ì„±)

**ë²”ìœ„**: 10.0 ~ 40.0 (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, ì¼ë°˜ë¡ ì  ë‹µë³€ì€ ë‚®ìŒ)

**ê³„ì‚° ë°©ë²•**:
- PersonaChat ë…¼ë¬¸ ë°©ì‹ ê·¼ì‚¬:
  ```
  PPL = exp(-1/N * Î£ log P(w_i | w_1, ..., w_{i-1}))
  ```
- í˜„ì¬ëŠ” íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê·¼ì‚¬:
  - ë‹µë³€ ê¸¸ì´ì™€ ë³µì¡ë„ ê¸°ë°˜
  - ì‹¤ì œ OpenAI logprobsë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì¶”ê°€ API í˜¸ì¶œ í•„ìš”

**ê³µì‹**:
```python
complexity_score = answer_chars / max(answer_length, 1)
approximate_ppl = 15.0 + (complexity_score - 4.0) * 3.0
```

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "perplexity": 18.5
}
```

**ì˜ë¯¸**:
- **10-20**: ì¼ë°˜ë¡ ì  ë‹µë³€ (ë‚®ì€ perplexity)
- **20-30**: ê°œì¸í™”ëœ ë‹µë³€ (ì¤‘ê°„ perplexity)
- **30-40**: ë§¤ìš° êµ¬ì²´ì /ê°œì¸í™”ëœ ë‹µë³€ (ë†’ì€ perplexity)

**ì°¸ê³ **: 
- LLM ëª¨ë“œëŠ” ì¼ë°˜ë¡ ì  ë‹µë³€ìœ¼ë¡œ ë‚®ì€ perplexity
- AI Agent ëª¨ë“œëŠ” ê°œì¸í™”ëœ ë‹µë³€ìœ¼ë¡œ ë†’ì€ perplexity ì˜ˆìƒ
- **ì£¼ì˜**: í˜„ì¬ëŠ” ê·¼ì‚¬ ë°©ë²•ì´ë¯€ë¡œ ì •í™•ë„ ì œí•œì 

---

## 2. ë©€í‹°í„´ ì»¨í…ìŠ¤íŠ¸ ì§€í‘œ

### 2.1 CUS (Context Utilization Score) - ë§¥ë½ í™œìš© ì ìˆ˜

**íŒŒì¼**: `experiments/evaluation/multiturn_context_metrics.py` (`compute_cus` í•¨ìˆ˜)

**ì •ì˜**: ì§ˆë¬¸ì´ ìš”êµ¬í•˜ëŠ” `required_slots` ì¤‘ ë‹µë³€ì´ ì‹¤ì œë¡œ ë°˜ì˜í–ˆëŠ”ì§€ ì¸¡ì •

**ë²”ìœ„**: 0.0 ~ 1.0 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

**ê³„ì‚° ë°©ë²•**:
```python
CUS = (ì‚¬ìš©í•œ ìŠ¬ë¡¯ ê°œìˆ˜) / (ì „ì²´ ìš”êµ¬ ìŠ¬ë¡¯ ê°œìˆ˜)
```

**ì…ë ¥**:
- `answer`: ìƒì„±ëœ ë‹µë³€ í…ìŠ¤íŠ¸
- `required_slots`: ì§ˆë¬¸ì´ ìš”êµ¬í•˜ëŠ” ìŠ¬ë¡¯ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: `["age", "sex", "conditions", "medications", "labs.hba1c"]`)
- `patient_profile`: í™˜ì í”„ë¡œí•„ (ground truth)
- `slots_state`: í˜„ì¬ ìŠ¬ë¡¯ ìƒíƒœ (ProfileStoreì—ì„œ ì¶”ì¶œ)

**ìŠ¬ë¡¯ ì‚¬ìš© íŒì • ë°©ë²•**:
- **ë‚˜ì´**: ì •í™•í•œ ìˆ«ì ë§¤ì¹­ ë˜ëŠ” "65ì„¸", "65 ì‚´", "65-year" íŒ¨í„´
- **ì„±ë³„**: "male/female/ë‚¨ì„±/ì—¬ì„±" ë“± í‚¤ì›Œë“œ ë§¤ì¹­
- **ì§ˆí™˜/ì•½ë¬¼**: ë¦¬ìŠ¤íŠ¸ì˜ ì–´ë–¤ ìš”ì†Œë¼ë„ ë‹µë³€ì— ë‚˜íƒ€ë‚˜ë©´ ì‚¬ìš©ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
- **ê²€ì‚¬ ê²°ê³¼**: ìˆ«ì ê°’ì´ ë‹µë³€ì— í¬í•¨ë˜ë©´ ì‚¬ìš©ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
- **ë™ì˜ì–´ ì§€ì›**: `slot_synonyms.py` ëª¨ë“ˆ ì‚¬ìš© (ê°€ëŠ¥í•œ ê²½ìš°)

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "metric": "CUS",
  "score": 0.75,
  "hits": 3,
  "total": 4,
  "used_detail": {
    "age": {"value": 67, "used": true},
    "sex": {"value": "ë‚¨ì„±", "used": true},
    "conditions": {"value": ["ë‹¹ë‡¨ë³‘"], "used": true},
    "labs.hba1c": {"value": 6.24, "used": false}
  }
}
```

**ì˜ë¯¸**:
- **0.8 ì´ìƒ**: ëŒ€ë¶€ë¶„ì˜ ìš”êµ¬ ìŠ¬ë¡¯ì„ í™œìš©
- **0.6-0.8**: ì ˆë°˜ ì´ìƒ í™œìš©
- **0.4-0.6**: ì¼ë¶€ë§Œ í™œìš©
- **0.4 ë¯¸ë§Œ**: ê±°ì˜ í™œìš©í•˜ì§€ ì•ŠìŒ

**íŠ¹ì§•**:
- Turn 3, 4ì—ì„œ íŠ¹íˆ ì¤‘ìš” (ì˜ë„ì ìœ¼ë¡œ ë§¥ë½ì´ ë¹„ëª…ì‹œì )
- LLM ëª¨ë“œëŠ” ë‚®ì€ CUS ì˜ˆìƒ (ë§¥ë½ ì¬ì‚¬ìš© ì–´ë ¤ì›€)
- AI Agent ëª¨ë“œëŠ” ë†’ì€ CUS ì˜ˆìƒ (ProfileStore í™œìš©)

---

### 2.2 UR (Update Responsiveness) - ì—…ë°ì´íŠ¸ ë°˜ì‘ì„±

**íŒŒì¼**: `experiments/evaluation/multiturn_context_metrics.py` (`compute_ur` í•¨ìˆ˜)

**ì •ì˜**: íŠ¹ì • í„´ì— ìƒˆë¡œ ì…ë ¥ëœ `update_key`ê°€ ë‹µë³€ì— ìš°ì„  ë°˜ì˜ë˜ì—ˆëŠ”ì§€ ì¸¡ì •

**ë²”ìœ„**: 0.0 ë˜ëŠ” 1.0 (ë°˜ì˜ë˜ì—ˆìœ¼ë©´ 1.0, ì•„ë‹ˆë©´ 0.0)

**ê³„ì‚° ë°©ë²•**:
- `update_key`ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í‰ê°€ (ì˜ˆ: Turn 3ì˜ "labs", "vitals")
- ì´ë²ˆ í„´ì— ìƒˆë¡œ ë“¤ì–´ì˜¨ ì •ë³´(`turn_updates`)ê°€ ë‹µë³€ì— ë°˜ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸

**ì…ë ¥**:
- `answer`: ìƒì„±ëœ ë‹µë³€ í…ìŠ¤íŠ¸
- `update_key`: ì§ˆë¬¸ì€í–‰ì—ì„œ ì •ì˜í•œ ì—…ë°ì´íŠ¸ í‚¤ (ì˜ˆ: `"labs"`, `"vitals"`, `"medications"`)
- `turn_updates`: ì´ë²ˆ í„´ì— ìƒˆë¡œ ë“¤ì–´ì˜¨ ì •ë³´ (slots_stateì—ì„œ ì¶”ì¶œ)
- `question_text`: ì§ˆë¬¸ í…ìŠ¤íŠ¸ (ì„ íƒì )

**ì¹´í…Œê³ ë¦¬ë³„ ì²˜ë¦¬**:
- `update_key`ê°€ "labs", "vitals", "medications", "symptoms"ì¸ ê²½ìš°:
  - í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ë‚´ì˜ ëª¨ë“  ì—…ë°ì´íŠ¸ê°€ ë‹µë³€ì— ë°˜ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
  - ë°˜ì˜ëœ í•­ëª© ë¹„ìœ¨ë¡œ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)
- ì¤‘ì²©ëœ ê²½ë¡œ (ì˜ˆ: "labs.hba1c")ì¸ ê²½ìš°:
  - í•´ë‹¹ ê°’ì´ ë‹µë³€ì— ë‚˜íƒ€ë‚˜ë©´ 1.0, ì•„ë‹ˆë©´ 0.0

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "metric": "UR",
  "applicable": true,
  "score": 1.0,
  "update_key": "labs",
  "update_value": {"hba1c": {"value": 6.24, "unit": "%"}},
  "reflected": true,
  "reflected_items": ["hba1c"],
  "total_items": 1
}
```

**ì˜ë¯¸**:
- **1.0**: ìƒˆë¡œ ë“¤ì–´ì˜¨ ì •ë³´ê°€ ë‹µë³€ì— ë°˜ì˜ë¨
- **0.0**: ìƒˆë¡œ ë“¤ì–´ì˜¨ ì •ë³´ê°€ ë‹µë³€ì— ë°˜ì˜ë˜ì§€ ì•ŠìŒ
- **applicable: false**: í•´ë‹¹ í„´ì— update_keyê°€ ì—†ìŒ

**íŠ¹ì§•**:
- Turn 3ì—ì„œ íŠ¹íˆ ì¤‘ìš” (ìƒˆë¡œìš´ ê²€ì‚¬ ê²°ê³¼/ë°”ì´íƒˆ ë°˜ì˜)
- LLM ëª¨ë“œëŠ” ë‚®ì€ UR ì˜ˆìƒ (ì´ì „ í„´ ì •ë³´ ê¸°ì–µ ì–´ë ¤ì›€)
- AI Agent ëª¨ë“œëŠ” ë†’ì€ UR ì˜ˆìƒ (ProfileStoreì— ìë™ ì €ì¥)

---

### 2.3 CCR (Context Contradiction Rate) - ë§¥ë½ ëª¨ìˆœë¥ 

**íŒŒì¼**: `experiments/evaluation/multiturn_context_metrics.py` (`ccr_rule_checks` í•¨ìˆ˜)

**ì •ì˜**: ë‹µë³€ì´ ì´ì „ í„´ê¹Œì§€ ì¶•ì ëœ í™˜ì ì •ë³´(ìŠ¬ë¡¯)ì™€ ëª¨ìˆœë˜ëŠ”ì§€ ì¸¡ì •

**ë²”ìœ„**: 0.0 (ëª¨ìˆœ ì—†ìŒ) ë˜ëŠ” 1.0 (ëª¨ìˆœ ìˆìŒ)

**ê³„ì‚° ë°©ë²•**:
- ë£° ê¸°ë°˜ ì²´í¬ (ëª…ë°±í•œ ëª¨ìˆœë§Œ íƒì§€)
- LLM Judge ì§€ì› (ì˜í•™ì  ëª¨ìˆœ íŒì •, ì„ íƒì )

**ì…ë ¥**:
- `answer`: ìƒì„±ëœ ë‹µë³€ í…ìŠ¤íŠ¸
- `slots_state`: í˜„ì¬ ìŠ¬ë¡¯ ìƒíƒœ (ì´ì „ í„´ê¹Œì§€ ì¶•ì ëœ ì •ë³´)

**ë£° ê¸°ë°˜ ì²´í¬ í•­ëª©**:

1. **ì„±ë³„ ëª¨ìˆœ**:
   - ë‚¨ì„±ì¸ë° ì„ì‹  ì–¸ê¸‰ â†’ ëª¨ìˆœ
   - ì—¬ì„±ì¸ë° ì „ë¦½ì„  ì–¸ê¸‰ â†’ ëª¨ìˆœ

2. **ì§ˆí™˜ ëª¨ìˆœ**:
   - ë‹¹ë‡¨ê°€ ìˆëŠ”ë° "ë‹¹ë‡¨ê°€ ì•„ë‹ˆë‹¤"ë¼ê³  ë¶€ì • â†’ ëª¨ìˆœ

3. **ì•½ë¬¼ ëª¨ìˆœ**:
   - ë©”íŠ¸í¬ë¥´ë¯¼ ë³µìš© ì¤‘ì¸ë° "ë©”íŠ¸í¬ë¥´ë¯¼ì„ ë³µìš©í•˜ì§€ ì•ŠëŠ”ë‹¤"ê³  ë¶€ì • â†’ ëª¨ìˆœ

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "metric": "CCR_rule_obvious",
  "has_contradiction": false,
  "contradictions": [],
  "score": 0.0
}
```

ë˜ëŠ” ëª¨ìˆœì´ ìˆëŠ” ê²½ìš°:
```json
{
  "metric": "CCR_rule_obvious",
  "has_contradiction": true,
  "contradictions": ["sex: male but pregnancy mentioned"],
  "score": 1.0
}
```

**LLM Judge ì§€ì›**:
- `experiments/evaluation/llm_judge_ccr.py`ì˜ `ccr_llm_judge` í•¨ìˆ˜
- ì˜í•™ì  ëª¨ìˆœ íŒì • (ì˜ˆ: CKD í™˜ìì—ê²Œ ê³ ë‹¨ë°± ê¶Œì¥)
- í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: ë£° ê¸°ë°˜ ë¨¼ì € ì²´í¬, í•„ìš”ì‹œ LLM Judge í˜¸ì¶œ

**ì˜ë¯¸**:
- **0.0**: ëª¨ìˆœ ì—†ìŒ (ì¢‹ìŒ)
- **1.0**: ëª¨ìˆœ ìˆìŒ (ë‚˜ì¨)

**íŠ¹ì§•**:
- ì•ˆì „ì„± ì¸¡ì •ì— ì¤‘ìš”
- LLM ëª¨ë“œëŠ” ë†’ì€ CCR ì˜ˆìƒ (ì´ì „ ì •ë³´ ê¸°ì–µ ì–´ë ¤ì›€)
- AI Agent ëª¨ë“œëŠ” ë‚®ì€ CCR ì˜ˆìƒ (ProfileStoreë¡œ ì¼ê´€ì„± ìœ ì§€)

---

## 3. LLM Judge ì§€í‘œ

### 3.1 Judge Total Score (ì¢…í•© íŒì • ì ìˆ˜)

**íŒŒì¼**: `experiments/evaluation/llm_judge_ccr.py` (ì°¸ê³ )

**ì •ì˜**: LLM Judgeë¥¼ í†µí•œ ì¢…í•© í’ˆì§ˆ í‰ê°€

**ë²”ìœ„**: 0.0 ~ 1.0 (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)

**ê³„ì‚° ë°©ë²•**:
- LLM ê¸°ë°˜ í‰ê°€ (ì„¤ì • íŒŒì¼ ì°¸ì¡°)
- `config.yaml`ì˜ `quality.llm_judge` ì„¤ì • ì‚¬ìš©:
  ```yaml
  quality:
    llm_judge:
      enabled: true
      judge_model: "gpt-4o-mini"
      temperature: 0.2
      weights:
        grounding: 0.4
        completeness: 0.4
        accuracy: 0.2
      thresholds:
        pass_score: 0.60
  ```

**ê°€ì¤‘ì¹˜**:
- **grounding (0.4)**: ê·¼ê±° ë¬¸ì„œì™€ì˜ ì¼ì¹˜ë„
- **completeness (0.4)**: ë‹µë³€ì˜ ì™„ì„±ë„
- **accuracy (0.2)**: ë‹µë³€ì˜ ì •í™•ì„±

**ì¶œë ¥ í˜•ì‹**:
```json
{
  "judge_total_score": 0.75
}
```

**ì˜ë¯¸**:
- **0.8 ì´ìƒ**: ë§¤ìš° ìš°ìˆ˜í•œ ë‹µë³€
- **0.6-0.8**: ì–‘í˜¸í•œ ë‹µë³€
- **0.4-0.6**: ë³´í†µ ë‹µë³€
- **0.4 ë¯¸ë§Œ**: ë¶€ì¡±í•œ ë‹µë³€

**ì°¸ê³ **: 
- í˜„ì¬ ì„¤ì •ì—ì„œëŠ” `judge_total_score`ê°€ `per_turn_metrics`ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜, ì‹¤ì œ ê³„ì‚° ì—¬ë¶€ëŠ” ì½”ë“œ í™•ì¸ í•„ìš”

---

## 4. ì„¤ì • íŒŒì¼ì—ì„œ ì •ì˜ëœ ì§€í‘œ

### 4.1 Per-Turn Metrics (í„´ë³„ ì§€í‘œ)

**íŒŒì¼**: `experiments/config.yaml`

**ì„¤ì •**:
```yaml
evaluation:
  per_turn_metrics: ["faithfulness", "answer_relevance", "perplexity", "judge_total_score"]
```

**ì§€í‘œ ëª©ë¡**:
1. `faithfulness`: RAGAS Faithfulness
2. `answer_relevance`: RAGAS Answer Relevance
3. `perplexity`: Perplexity
4. `judge_total_score`: LLM Judge ì¢…í•© ì ìˆ˜

---

### 4.2 Multi-Turn Metrics (ë©€í‹°í„´ ì§€í‘œ)

**íŒŒì¼**: `experiments/config.yaml`

**ì„¤ì •**:
```yaml
evaluation:
  multiturn_metrics: ["context_utilization", "context_contradiction", "update_responsiveness"]
```

**ì§€í‘œ ëª©ë¡**:
1. `context_utilization`: CUS (Context Utilization Score)
2. `context_contradiction`: CCR (Context Contradiction Rate)
3. `update_responsiveness`: UR (Update Responsiveness)

---

## 5. ì´ë²¤íŠ¸ ë¡œê·¸ì— ì €ì¥ë˜ëŠ” ì§€í‘œ

### 5.1 ì €ì¥ í˜•ì‹

**íŒŒì¼**: `runs/{run_id}/events.jsonl`

**ìŠ¤í‚¤ë§ˆ**: `experiments/schemas/events_record.schema.json`

**ì €ì¥ ìœ„ì¹˜**: ê° ì´ë²¤íŠ¸ì˜ `metrics` í•„ë“œ

**ì˜ˆì‹œ**:
```json
{
  "schema_version": "events_record.v1",
  "run_id": "2025-12-13_primary_v1",
  "mode": "agent",
  "patient_id": "SYN_0001",
  "turn_id": 3,
  "question": {...},
  "answer": {...},
  "metrics": {
    "faithfulness": 0.85,
    "answer_relevance": 0.78,
    "perplexity": 18.5,
    "CUS": 0.75,
    "UR": 1.0,
    "CCR": 0.0
  },
  "slots_truth": {...}
}
```

---

## 6. ì§€í‘œ ê³„ì‚° íë¦„

### 6.1 LLM ëª¨ë“œ

```
ì§ˆë¬¸ ì…ë ¥
  â†“
LLM ì§ì ‘ í˜¸ì¶œ
  â†“
ë‹µë³€ ìƒì„±
  â†“
í‰ê°€ì§€í‘œ ê³„ì‚°:
  - RAGAS (faithfulness, answer_relevance)
  - Perplexity
  - CUS (patient_profileë§Œ ì‚¬ìš©, slots_state ì—†ìŒ)
  - UR (turn_updates ì—†ì„ ìˆ˜ ìˆìŒ)
  - CCR (slots_state ì—†ìŒ)
  â†“
ì´ë²¤íŠ¸ ë¡œê·¸ ì €ì¥
```

### 6.2 AI Agent ëª¨ë“œ

```
ì§ˆë¬¸ ì…ë ¥
  â†“
Agent ì‹¤í–‰ (LangGraph)
  â†“
ë‹µë³€ ìƒì„±
  â†“
í‰ê°€ì§€í‘œ ê³„ì‚°:
  - RAGAS (faithfulness, answer_relevance)
  - Perplexity
  - CUS (slots_state ì‚¬ìš© ê°€ëŠ¥)
  - UR (turn_updates ì‚¬ìš© ê°€ëŠ¥)
  - CCR (slots_state ì‚¬ìš© ê°€ëŠ¥)
  â†“
ì´ë²¤íŠ¸ ë¡œê·¸ ì €ì¥
```

---

## 7. ì§€í‘œë³„ ë¹„êµ ì˜ˆìƒ

### 7.1 LLM vs AI Agent ëª¨ë“œ ì˜ˆìƒ ì°¨ì´

| ì§€í‘œ | LLM ëª¨ë“œ ì˜ˆìƒ | AI Agent ëª¨ë“œ ì˜ˆìƒ | ì°¨ì´ ì´ìœ  |
|------|--------------|-------------------|---------|
| **faithfulness** | ì¤‘ê°„ (0.6-0.8) | ë†’ìŒ (0.7-0.9) | AgentëŠ” ê²€ìƒ‰ ë¬¸ì„œ í™œìš© |
| **answer_relevance** | ë†’ìŒ (0.8-0.9) | ë†’ìŒ (0.8-0.9) | ë‘˜ ë‹¤ ì§ˆë¬¸ì— ê´€ë ¨ ìˆìŒ |
| **perplexity** | ë‚®ìŒ (10-20) | ë†’ìŒ (20-35) | AgentëŠ” ê°œì¸í™”ëœ ë‹µë³€ |
| **CUS** | ë‚®ìŒ (0.3-0.5) | ë†’ìŒ (0.7-0.9) | AgentëŠ” ë§¥ë½ ì¬ì‚¬ìš© |
| **UR** | ë‚®ìŒ (0.0-0.3) | ë†’ìŒ (0.8-1.0) | AgentëŠ” ì—…ë°ì´íŠ¸ ë°˜ì˜ |
| **CCR** | ë†’ìŒ (0.2-0.5) | ë‚®ìŒ (0.0-0.1) | AgentëŠ” ì¼ê´€ì„± ìœ ì§€ |

---

## 8. êµ¬í˜„ ìƒíƒœ

### 8.1 ì™„ì „ êµ¬í˜„ëœ ì§€í‘œ

âœ… **RAGAS Faithfulness**: ì™„ì „ êµ¬í˜„
âœ… **RAGAS Answer Relevance**: ì™„ì „ êµ¬í˜„
âœ… **Perplexity**: ê·¼ì‚¬ ë°©ë²•ìœ¼ë¡œ êµ¬í˜„ (ì •í™•ë„ ì œí•œì )
âœ… **CUS**: ì™„ì „ êµ¬í˜„
âœ… **UR**: ì™„ì „ êµ¬í˜„
âœ… **CCR (ë£° ê¸°ë°˜)**: ì™„ì „ êµ¬í˜„

### 8.2 ë¶€ë¶„ êµ¬í˜„ëœ ì§€í‘œ

âš ï¸ **CCR (LLM Judge)**: êµ¬í˜„ë˜ì–´ ìˆìœ¼ë‚˜ ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”
âš ï¸ **Judge Total Score**: ì„¤ì •ì— ìˆìœ¼ë‚˜ ì‹¤ì œ ê³„ì‚° ì—¬ë¶€ í™•ì¸ í•„ìš”

### 8.3 ë¯¸êµ¬í˜„ ì§€í‘œ (ì„¤ì • íŒŒì¼ì— ì–¸ê¸‰ë¨)

âŒ **Context Precision**: RAGAS ì§€í‘œì´ì§€ë§Œ í˜„ì¬ ê³„ì‚° ì•ˆ í•¨
âŒ **Context Recall**: RAGAS ì§€í‘œì´ì§€ë§Œ í˜„ì¬ ê³„ì‚° ì•ˆ í•¨
âŒ **Context Relevancy**: RAGAS ì§€í‘œì´ì§€ë§Œ í˜„ì¬ ê³„ì‚° ì•ˆ í•¨

---

## 9. ìƒˆë¡œìš´ ë©€í‹°í„´ ìŠ¤í¬ë¦½íŠ¸ ëª¨ë“œì—ì„œì˜ ì§€í‘œ

### 9.1 ì¶”ê°€ëœ ì •ë³´

ë©€í‹°í„´ ìŠ¤í¬ë¦½íŠ¸ ëª¨ë“œì—ì„œëŠ” ë‹¤ìŒ ì •ë³´ê°€ ì´ë²¤íŠ¸ ë¡œê·¸ì— ì¶”ê°€ë©ë‹ˆë‹¤:

```json
{
  "slots_truth": {
    "age": 67,
    "sex": "ë‚¨ì„±",
    "primary_condition": "Type 2 Diabetes Mellitus",
    "comorbidities": ["Hypertension"],
    "key_meds": ["Metformin"],
    "key_vitals": {"bp_systolic": "131mmHg"},
    "key_labs": {"hba1c": "6.24%"},
    "major_procedures": [],
    "chief_symptom": "í”¼ë¡œ"
  }
}
```

### 9.2 í‰ê°€ í™œìš©

`slots_truth`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ í‰ê°€ ì§€í‘œ ê³„ì‚° ê°€ëŠ¥:

1. **SFS (Slot Factuality Score)**: ë‹µë³€ì´ í™˜ì ë°ì´í„°ì™€ ì¼ì¹˜í•˜ëŠ”ì§€
2. **CSP (Contraindication/Safety Penalty)**: ê¸ˆê¸°/ì•ˆì „ ìœ„ë°˜ ê°ì 
3. **CUS ê°œì„ **: `slots_truth`ë¥¼ ground truthë¡œ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•œ í‰ê°€

---

## 10. ì°¸ê³  íŒŒì¼

- `experiments/evaluation/ragas_metrics.py`: RAGAS ì§€í‘œ ê³„ì‚°
- `experiments/evaluation/multiturn_context_metrics.py`: ë©€í‹°í„´ ì»¨í…ìŠ¤íŠ¸ ì§€í‘œ ê³„ì‚°
- `experiments/evaluation/multiturn_metrics.py`: ë©€í‹°í„´ ì§€í‘œ ê³„ì‚° (ë ˆê±°ì‹œ)
- `experiments/evaluation/llm_judge_ccr.py`: LLM Judge êµ¬í˜„
- `experiments/config.yaml`: í‰ê°€ ì„¤ì •
- `experiments/schemas/events_record.schema.json`: ì´ë²¤íŠ¸ ìŠ¤í‚¤ë§ˆ
- `config/eval/required_slots_by_turn.yaml`: í„´ë³„ ìš”êµ¬ ìŠ¬ë¡¯ ì •ì˜
- `config/eval/safety_rules.yaml`: ê¸ˆê¸°/ì•ˆì „ ë£° ì •ì˜

---

## 11. í–¥í›„ í™•ì¥ ê°€ëŠ¥í•œ ì§€í‘œ

### 11.1 ì œì•ˆëœ ì§€í‘œ (ChatGPT/Gemini ì œì•ˆ)

1. **SFS (Slot Factuality Score)**: ìŠ¬ë¡¯ ì‚¬ì‹¤ì„± ì ìˆ˜
2. **CSP (Contraindication/Safety Penalty)**: ê¸ˆê¸°/ì•ˆì „ ê°ì 
3. **MCS (Multi-turn Consistency Score)**: ë©€í‹°í„´ ì¼ê´€ì„± ì ìˆ˜
4. **ASS (Actionability/Specificity Score)**: ì‹¤í–‰ ê°€ëŠ¥ì„± ì ìˆ˜

### 11.2 êµ¬í˜„ ì¤€ë¹„ ìƒíƒœ

- âœ… ì„¤ì • íŒŒì¼ ì¤€ë¹„: `config/eval/required_slots_by_turn.yaml`
- âœ… ì•ˆì „ ë£° ì¤€ë¹„: `config/eval/safety_rules.yaml`
- âœ… ìŠ¬ë¡¯ ì •ë³´ ì €ì¥: `slots_truth` í•„ë“œ
- â³ í‰ê°€ ëª¨ë“ˆ êµ¬í˜„: ì•„ì§ ë¯¸êµ¬í˜„

---

## 12. ìš”ì•½

### í˜„ì¬ í™œì„±í™”ëœ ì§€í‘œ

1. **RAGAS Faithfulness** âœ…
2. **RAGAS Answer Relevance** âœ…
3. **Perplexity** âœ… (ê·¼ì‚¬ ë°©ë²•)
4. **CUS (Context Utilization Score)** âœ…
5. **UR (Update Responsiveness)** âœ…
6. **CCR (Context Contradiction Rate)** âœ… (ë£° ê¸°ë°˜)

### ì„¤ì •ë§Œ ìˆê³  ë¯¸êµ¬í˜„ì¸ ì§€í‘œ

1. **Judge Total Score** âš ï¸
2. **Context Precision** âŒ
3. **Context Recall** âŒ
4. **Context Relevancy** âŒ

### í–¥í›„ í™•ì¥ ê°€ëŠ¥í•œ ì§€í‘œ

1. **SFS (Slot Factuality Score)** ğŸ“‹
2. **CSP (Contraindication/Safety Penalty)** ğŸ“‹
3. **MCS (Multi-turn Consistency Score)** ğŸ“‹
4. **ASS (Actionability/Specificity Score)** ğŸ“‹

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-12-14
**ë¬¸ì„œ ë²„ì „**: 1.0

